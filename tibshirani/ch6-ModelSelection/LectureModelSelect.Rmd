---
title: "ISLR Chapter 6. Lecture ModelSelect"
output:
  html_document: default
  pdf_document: default
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

Model Selection
===================

This is an R Markdown document. Markdown is a simple formatting syntax for authoring HTML, PDF, and MS Word documents. For more details on using R Markdown 

Hitters is a dataset with baseball statisitcs.


```{r hitteres}
library(ISLR)
dim(Hitters)
summary(Hitters)
```

Checking if dta has  missing values. If yes get rid of NAs.
```{r omit}
dim(Hitters)
with(Hitters,sum(is.na(Salary)))  # we have some missing values
Hitters <- na.omit(Hitters)  #remove rows with NA data
with(Hitters,sum(is.na(Salary)))  # check after na removal
dim(Hitters)
```


Best Subset regression
----------------------

We will use the package `leaps`  to evaluation all the best-subset models

```{r bsubs}
library(leaps)
regfit.full<-regsubsets(Salary~.,data=Hitters)
summary(regfit.full)
```
It gives the default beset-subset up to size 8 : lets increase that to 19 i.e. al the variables 
```{r bsubsb}
regfit.full<-regsubsets(Salary~.,data=Hitters,nvmax=19)
reg.summary<-summary(regfit.full)
names(reg.summary)
plot(reg.summary$cp,xlab="Number of Variables", ylab="Cp",main="Cp statistics vs model complexity")
## lets colorcode the curve minimum point
minimum_point_idx<-which.min(reg.summary$cp) # 10
points(minimum_point_idx,reg.summary$cp[minimum_point_idx],pch=20,col="red")
```
There exist a plot method for `regsubsets` object
```{r rsubs plot}
plot(regfit.full,scale="Cp")
coef(regfit.full,10) #coefficients for model indexed 10
```


Forward Stepwise Selection
--------------------------

Here we use `regsubsets` function but specify the `method="forward"` option:
```{r}
regfit.fwd <- regsubsets(Salary~. ,data=Hitters, nvmax=19,method="forward")
summary(regfit.fwd)
plot(regfit.fwd,scale="Cp")
```

Model Selection using a Validation Set
--------------------------------------

Lets make a training and a vlidation set, so that we can choose a good subset model. 
We will do it using a slightly different approach from what was done in the book.
```{r}
dim(Hitters)
set.seed(1)
nrows <- dim(Hitters)[1] #263
sample_size <- floor(2/3 * nrows) + 5  # training sample of size 180
train<-sample(seq(nrows),sample_size,replace=FALSE)
regfit.fwd <- regsubsets(Salary~. ,data=Hitters[train,]
                        ,nvmax=19,method="forward")
```
Now we will make predictions on the observatons not used for training.
We know there are 19 models, so we set up some vectors to record the errors. We hae to do a bit of work here, because there is no predict method for `regsubsets`.
```{r}
val.errors<-rep(NA,19) # 19 is thte max numb of predictors in the Hitters dataset
x.test <- model.matrix(Salary~. , data=Hitters[-train,]) #-train is index for test
for(i in 1:19){
   coefi <- coef(regfit.fwd,id=i)
   pred  <- x.test[,names(coefi)]%*%coefi #varieables * model coefficients
   val.errors[i] <- mean((Hitters$Salary[-train]-pred)^2)
}
plot(sqrt(val.errors), ylab="Root MSE", ylim=c(300,400), pch=19,type="b")
points(sqrt(regfit.fwd$rss[-1]/sample_size), col="blue", pch=19,type="b")
legend("topright", legend=c("Training", "Validation"), col=c("blue","black"), pch=19)
```

As we expect, the training error goes down monotonically as the model gets bigger, but not so for the valiation error. 

Lets put the above code in the function 
```{r}
predict.regsubsets<-function(object,newdata,id,...){
	form<-as.formula(object$call[[2]])
	mat<-model.matrix(form,newdata)
	coefi<-coef(object,id=id)
	mat[,names(coefi)]%*%coefi
}
```
Cross Validation
------------------

