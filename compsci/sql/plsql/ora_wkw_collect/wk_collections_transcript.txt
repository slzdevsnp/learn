

Code School
Working with Collections in Oracle PL/SQL
by Pankaj Jain

In this course, we will take an in-depth look at the collection types available in PL/SQL, namely Associative Arrays, Varrays, and Nested Tables. We'll also talk about the bulk fetch and collect features which greatly enhance the performance our...

Resume CourseBookmarkAdd to ChannelLive mentoring
Table of contents
Description
Transcript
Exercise files
Discussion
Learning Check
Recommended
Need for Collection Types & Their Characteristics

Hello, and welcome to Pluralsight. My name is Pankaj Jain, and welcome to this course on Working with Collections in PL/SQL. When we go shopping, we take our shopping bag along, which enables us to contain and carry all the items in one go, from our car to the house. Worse is having to take them inside one by one. The shopping bag is like a collection structure which enables us to store a collection of data values in a single variable. Worse is having to create several individual variables to hold them. Collection structures are very important in any programming language to increase the efficiency and performance of the code. Being able to reference and manipulate a collection of data values not only helps create optimized applications, but also keeps the code compact, readable, and maintainable. These collection structures are a must to know in order to write practical, performing applications, and to fully harness the power of PL/SQL. Oracle provides a rich set of collection data types. In this course, we will take an in-depth look at these structures. We will also take a look at how to perform bulk fetches from the database, as well as how to perform DML in bulk using these collection structures. These bulk operations can lead to significant performance improvements of your PL/SQL code, often increasing performance by several orders of magnitude. This is a very important topic, and there is a lot of exciting stuff to talk about. So let's get started. This is the first module of this course in which we will introduce collections, talk about some prerequisites to be more successful with this course, and the tools we are going to use in this course. In the next module, we will take an in-depth look at the first collection structure in Oracle PL/SQL, associative arrays. Associative array is a very flexible PL/SQL-only collection type, which is perhaps the most widely used. Having taken a look at the first collection structure, we will introduce collection methods, which allow us to get information about the collection, access collection elements, and manipulate them. Then, we will talk about the next collection type, nested tables. Nested tables can be defined in PL/SQL, as well as can be defined as a database column to hold a collection of values. They have several useful utility operators available against them, and are extremely useful for applications where you want to compare collections, or want to manipulate elements of a collection using SQL. In the next module, we will talk specifically about how to compare nested tables and how to apply operators and the multiset and set operators against it. We will also take a look at the table expression, which allows us to un-nest individual elements from a collection. The table expression also allows us to perform piecewise operations against nested tables, like inserting, deleting, or updating individual elements in a collection. Varrays is a collection type which holds a fixed number of elements. These can be stored and retrieved with SQL also, but their main use is when you want to maintain the order of the elements within a collection, or we want to constrain the collection to have an upper limit of the number of elements it can hold. Next, we will talk about creating multilevel collections and see the use of the cast and collect operators who convert a building collection type into another. Then, we will dive into the bulk features in Oracle which is perhaps the most important performance optimization technique in Oracle PL/SQL. The first of the bulk operations is BULK COLLECT, which is used to fetch data in bulk from the database server. The second bulk operation is the FORALL clause to perform updates, deletes, or inserts in the database in bulk. We will also see demos to illustrate the performance gains you achieve by using bulk operations. Next, let's talk about some of the prerequisites you will need to be more successful with this course, as well as the tools you can use to follow along.

Prerequisites, Audience & Tools

Let us now talk about some prerequisites for getting the most benefit out of this course. You need to have a basic understanding of PL/SQL, Oracle's database programming language. You should have a knowledge of the basic programming constructs and concepts of Oracle PL/SQL programming. Here are some recommended courses on Pluralsight to learn some basic PL/SQL programming concepts. Oracle PL/SQL Fundamentals-Part 1 course, where some of the basic concepts, like anonymous blocks, PL/SQL data types, conditional executions, loops, cursors, exceptions, etc., are discussed. In Oracle PL/SQL Fundamentals-Part 2 course, named program units like stored procedures, functions, and packages are extensively discussed. These named program units help encapsulate business logic and are precompiled and stored in the database. Another good course to check out would be Oracle PL/SQL: Transactions, Dynamic SQL, and Debugging where transactions, dynamic SQL, and debugging methods for PL/SQL are discussed. This course will be useful for Oracle programmers who would like to acquire knowledge of collections in order to write optimized, and better performing code, web developers who like to write SQL-intensive business logic in the database layer instead of a web layer in order to reduce network latency and increase performance, and developers who would like to learn Oracle programming. If you have been following along the recommended courses I mentioned in the slide before, this would be a course to further expand your knowledge of PL/SQL programming in order to be more proficient with it. In this course, we will be talking about basic PL/SQL programming constructs and concepts which would work with most Oracle Database versions. However, I would recommend you to work with the latest version in order to take advantage of the optimizations and efficiencies Oracle builds with each new Oracle Database version. For the tools I will be using Oracle SQL Developer, a free IDE, or development environment which you can download from Oracle's website. You can also use SQL*Plus for running the code samples we will be using in this course. SQL*Plus is a command-line tool for which you can run SQL and PL/SQL code. If you are more familiar with, and have access to other IDEs like Toad and SQL Navigator, just to name a few, feel free to use them. Next, let's talk about why do we need collections, and some of their characteristics.

Need for Collection Types

Before jumping into the need and characteristics of the collections, let's first specifically take a look at what we will be talking about in this module. In this module, we will briefly take an overview of the various collection types available with Oracle, and discuss why you need to know about collections, and what are the unique use cases where they are useful. We will then see the general structure of a collection, and how they are organized and accessed. Lastly, we will talk about the characteristics of the collection types. Collections, like records, are composite data types. A composite data type has internal components. In a collection, all internal components have the same data type, but a record on the other hand can be composed of components of different data types. The collection types available with Oracle are the associative arrays, varrays, and nested tables. We will take a look at each of them in detail in subsequent modules. So what's the need for using collection types? Collection types greatly improve performance. When you select, say 100 rows from the database, inside PL/SQL it has to make 100 network roundtrips. Using BULK COLLECT, you can go and fetch those 100 rows in just one network roundtrip in a collection structure, and thus increase performance immensely. Collection types are useful in dealing with an unknown numbers of variables. The state of the data in the database is generally dynamic with values inserted or deleted every second. If you need to fetch these unknown number of data values in their PL/SQL code, there is no way you can determine the number of variables you will need in advance to hold these values individually. Using a collection structure is an effective way to achieve that. Collection structures provide a means to group related data values together, and efficiently manipulate and query them using SQL. Using collection variables, instead of creating individual variables, also enables compact and readable code, and a more readable code directly translates to a better-managed and accurate code. Your website, managed in in C# or Java, or any other language which supports collection types like sets, trees, arrays, etc., when it interacts with the database, it will need compatible collection structures which can map to its collection types in order to pass data to and fro. Oracle Database collection types provide such compatible data structures.

Notating Collections & Characteristics

Let us see how collection types can be accessed with general syntax for notating and accessing collections, is by calling the collection variable with an index value in parenthesis. It is like a hash table in Java or C# composed of key value pairs stored inside of them. You use the key or the index to get the value stored at that location. A collection variable can be of type associative array, varray, or a nested table. The index provides the key for storing and accessing values at that key inside the collection. So here is the original representation of a collection structure specifying a key or index 1 to the collection variable mycollection, you can access the values stored in it at index 1. Specifying 2, you can access the value stored at index 2, and so on and so forth. Let us talk about the general characteristics of the different type of collection data types. We will talk in detail about them a later modules, but here's a quick overview. The first attribute is Density. A sparse collection is one, but there is a gap in the index value. For instance, after index value 1, the next index value is 3. A dense collection, on the other hand, has no gaps in the index values. Nested tables and associative arrays can be sparse, but varrays that are always dense. You do not need to specify the number of elements in an associative array at declaration. You can keep adding elements to it at runtime. The maximum amount of elements in the collection is the upper limit of the index type. Similarly, you can keep adding elements at runtime to a nested table, however, varrays require the maximum amount of elements to be specified at declaration. Most of the collection data types take integer or varchar2 indexes. Associative arrays are PL/SQL-only data types, while nested tables and varrays can be defined at the schema level also. The collection methods are subprograms like procedures or functions, which you can apply against a collection variable. The collection methods allow us to manipulate the contents of a collection, or provide information about the collection. Let us see how the composite data types in other languages translate to PL/SQL data types. The hash table in other languages will translate to associative arrays in PL/SQL. Unordered table also will translate to an associative array. Sets will map with nested tables. A bag will translate to a nested table. And, an array will map to a VARRAY. Before we dive into associative arrays in the next module, let us quickly take a look at the tables we'll be using in this course. Let us say we are an online store and we have the ITEMS table containing items on sale. Having ITEM_ID and NUMBER, ITEM_NAME and VARCHAR2, and its VALUE, a NUMBER with position 5 and scale 2. ITEM_ID is the primary key of the table. Next, is the CUSTOMERS table containing CUST_ID, NAME, and LOCATION. CUST_ID is the primary key. The customers can have accounts. The ACCOUNTS table has ACT_ID, the primary key, ACT_CUST_ID, the customer ID holding the account, this being a foreign key linking to the CUST_ID of the CUSTOMERS table, and the ACT_BAL. Finally, we have the ORDERS table containing the orders placed consisting of ORDER_ID, a NUMBER, and also the primary key of the table, ORDER_ITEM_ID, has a foreign key to the ITEM_ID of the ITEMS table, and ORDER_ACT_ID having a foreign key to the ACT_ID of the ACCOUNTS table. We have reached to an end of this module. Let's summarize what we talked about.

Summary

In this module, we talked about why collection types are needed and what are the benefits of using them. The collection types help improve performance, as well as also allow handling an unknown number of data values say fetched from a database table. Associative arrays, nested tables, and varrays are the collection types in Oracle we will be talking about in this course. The collection types follow a general syntax for accessing values. They have a collection of elements inside them. You pass in the index or the key to get the value stored out of that index. Finally, we talked about some of the common characteristics of a collection type, like density, maximum number of elements they can hold, etc. We also took a look at the tables we'll be using throughout this course. In the next module, we will take a look at associative arrays, one of the most common collection types used in Oracle PL/SQL. So, stay tuned.

Associative Arrays

Module Overview

Hello, and welcome to Pluralsight. My name is Pankaj Jain and welcome to this module on Associative Arrays. In this module, we will talk about associative arrays, the most commonly used array type in PL/SQL. We will start by talking about what is an associative array. We will see how to define, initialize, and use associative arrays. We will discuss the key, or the index of the associative array, and see how its data type can affect the sort order of the elements stored inside the collection. We will talk about the places where they can be declared, as well as how we will declare them affects their system visibility and their ability to provide session persistence. Finally, we will conclude by some usage guidelines for associative arrays.

Defining Associative Arrays

We talked about the general characteristics of collections in the last module. An associative array is also known as a PL/SQL table or an index-by table. So if you come across those terms, they're referring to associative arrays. An associative array is a collection of key-value pairs, key being the index, and the value being the data stored at that index. The key, or the index, can be a string type like VARCHAR, VARCHAR2, String, or Long. It can also be numeric, either BINARY_INTEGER or PLS_INTEGER type. An associative array is a PL/SQL-only data type. It can be declared in an anonymous blocks or stored program units like procedures, functions, packages. Think of an associative array as an in-memory table of key-value pairs. As I mentioned earlier, this is probably the most commonly used collection structure you'll be using in PL/SQL programming. The bigger the size of the PL/SQL table, the more memory the session will consume, so we need to be cognizant of that fact when working with associative arrays. Here is the syntax for defining an associative array. The declaration starts with the TYPE keyword, followed by any name you want to give to the type. This is followed by IS TABLE OF <element_type>. IS TABLE indicates that it is a collection. The element_type can be numbers, varchar2, date, records, user-defined types, etc. If you specify the optional NOT NULL constraint, it will ensure that you cannot have NULL as a value at any index. The INDEX BY clause is used to specify the data type used for indexing, like BINARY_INTEGER, PLS_INTEGER, or VARCHAR2 with a size_limit. The INDEX BY keyword helps distinguish an associated array from other collection types. And here are some examples of declaring associative arrays. TYPE mytype_aa IS TABLE OF NUMBER INDEX BY BINARY_INTEGER declares an associative array of type NUMBER. I generally like to follow a naming convention to easily identify my variable type. So I like to put the aa's effects in order to quickly identify it as an associative array. You can choose another naming convention you like, but it is a good practice to have a naming convention in place to help readability and maintainability of the code. TYPE mytype_aa IS TABLE OF VARCHAR2(60)INDEX BY BINARY_INTEGER declares an associative array of VARCHAR2(60) and TYPE mytype_aa IS TABLE OF emp%ROWTYPE INDEX BY BINARY_INTEGER declares an array, each component of which is a record of type EMPLOYEE, and which is indexed by the BINARY_INTEGER index value. In order to work with associative arrays, we have to first declare the type, and then declare a variable using that type. You cannot use the type directly. The type declaration makes it available to the program unit as any other data type against which you can declare a variable. So here is an anonymous block where we have declared an associative array as TYPE items_aa IS TABLE OF VARCHAR2(60) INDEX BY BINARY_INTERGER. So this array will hold internal components, each one of which is of type VARCHAR2(60), and they will be sorted by the value of the index, which is a BINARY_INTEGER. After the type is created, now we can create a local variable to work with this type. You cannot use the type directly. A type is like another data type at this point, against which you can declare variables. So, l_items_aa is of type items_aa. Now we can work with the variable l_items_aa from this point on. There is no explicit initialization of associative arrays. If not initialized, the collection is empty, but not null, and trying to access it by applying a collection method to it would not raise not null exception. Let us see how to set and get values from associative arrays next.

Assigning Values to Associative Arrays

Let us look at an example to understand how to assign values to an associative array. There is no explicit constructor for the associative array, so in this code section, we start by declaring TYPE items_aa IS TABLE of VARCHAR2(60) INDEX BY BINARY_INTEGER, and then we declare l_items_aa as of type items_aa. Since there is no constructor for the associative array, in the execution section we can start using it directly. So l_items_aa with a key of 1 is assigned a value of Treadmill at that key. The key, or next value of 2, is assigned a value of Bike. An index of 3 is assigned a value of Elliptical. We can now get to the values by passing in the key to the variable. So using dbms_output, we print the value at index 2 by using l_items_aa, passing in an index value of 2. The other way to assign values to an associative array, is to assign it another associative array of the same type. So in this code snippet, we have declared another associative array, l_copy_aa, which is of type items_aa. Here again, we assign the values at index 1, 2, and 3 to l_items_aa. Now, if we want, we can assign l_items_aa to l_copy_aa, which will make it have the same internal components as l_items_aa, so after the assignment, printing the value of l_copy_aa at index 2 will give us the same result. Another thing to note is that you can assign one collection to another only when they're of the same type. So here we have declared two types: TYPE items_aa IS TABLE OF VARCHAR2(6)INDEX BY BINARY_INTEGER and TYPE dup_aa IS TABLE OF VARCHAR2(60) INDEX BY BINARY_INTEGER. So both of them are comprised of the same internal component type which is VARCHAR2(60), and have the same index which is BINARY_INTEGER. However, since they have different names, they are considered different types. Now we declare l_items_aa of type items_aa and l_dup_aa of type dup_aa. Again we assign values at index counter 1, 2, and 3 to l_items_aa. Now when we try and assign l_items_aa to l_dup_aa, it will fail as even though they are comprised of the same internal data type, however, they have different type names. We can use the assignment of an empty array of the same type to initialize the array back to an empty array. So here, we have declared another associative array, l_empty_aa, which is an empty array of the same type items_aa. This can be used to initialize an array of type items_aa. So after assigning value to the index counters 1, 2, and 3 to l_items_aa, when we assign l_empty_aa to l_items_aa we wipe away all its elements and make it an empty collection again. This is a handy way to reinitialize an array back to an empty array say at the beginning of a loop processing. BEGIN also will be initialized using BULK COLLECT clause. So fetching using a BULK COLLECT query will wipe away values assigned earlier to an associative array, and load it with the new values obtained during the fetch. We will take a look at BULK COLLECT in a later module. Now, let us do a quick demo to demonstrate the concepts we have spoken about so far.

Demo: Assigning Values & Cursor Fetch to Associative Arrays

In this demo, we will see how we can declare associative arrays, assign values to them, and initialize them back to an empty array. So here in an anonymous block where we have declared an associative array as type items_aa is table of varchar2(60) INDEX BY BINARY_INTEGER. Now items_aa is like any other data type against which we can declare variables from this point on. Next, we declare a local variable l_items_aa of type items_aa. We declare l_itemscopy_aa and l_empty_aa also as of type items_aa. Next in the execution section, we assign at index 1 a value of Treadmill to l_items_aa array, and at index 2 a value of Bike, and at index 3 a value of Elliptical. We access the value at index counter 2, and add items_aa and print it using the DBMS_OUTPUT.PUT_LINE statement to the console. Next, we print Copying l_items_aa array to l_itemscopy_aa array, and copy l_items_aa to l_itemscopy_aa. At this point, l_itemscopy_aa has identical elements to l_items_aa, which we confirm by printing the values stored in it at index counter 2. It is a copy by value and not by reference, and any assignments or deletions to l_items_aa would not affect elements in l_itemscopy_aa. Next, we initialize l_items_aa to an empty array by assigning l_empty_aa to it. Let's execute this block. From the DBMS_OUTPUT statements, we see that the value at index counter 2 in l_items_aa array is Bike. We then copy the array to l_itemscopy_aa and then confirm that the value stored in it at index counter 2 is also Bike. Finally, we initialize l_items_aa. Next, let's take a look to see how we can fetch values into associative arrays when we are working with cursors. In this demo, we will see a more real world example of fetching dynamic number of values into an associative array. Let us first observe the items table. It currently has 3 items: 1, 2, and 3. Next is an anonymous block where we DECLARE an associative array, items_aa, which is a table of items%ROWTYPE INDEX BY BINARY_INTEGER. This is an example of creating an associative array of a record type. We declare l_items_aa of type items_aa and a variable counter of type NUMBER, initialized to 0. Next we declare a CURSOR get_items_cur to SELECT * FROM items table, ORDER BY item_id. In the execution section, we open cursor FOR loop, fetching get_items_cur in get_items_var variable. If we need to refresh your knowledge about cursor for loops, please refer to the PL/SQL Fundamentals Part 1 course on Pluralsight. You first increment the counter by 1, bringing its value to 1. L_items_aa, with an index of 1, will now give us access to the items row type record, which internally has 3 elements, we assign item_id a value of get_items_var.item_id. Item_name, the item name, and item_value, the item value fetched from the cursor. Please note that it is not required to assign values to all record elements. We can assign values to only the internal record elements we want to. We do this in a loop, incrementing the counter every time. After the loop is over, we print the values stored at l_items_aa at counters 1, 2, and access the item_id and item_name over there. Let's run this. As expected, the values were fetched successfully in our associative array of records, and we were able to access them using the index counter. Let us next examine the associative array index in more detail and see how it affects the internal sorting of collection elements.

Associative Array Index

As we had discussed earlier, associative array index can be a string type which can be VARCHAR, VARCHAR2, String, or Long, or it can be a numeric type like PLS_INTEGER or BINARY_INTEGER. Choosing the array index type has implications on how sorting is done internally as you will see shortly. You do not have to specify the maximum number of elements you want to hold in the array while declaring the associative array variable. So for index of type BINARY_INTEGER, the array can hold values within the binary integer range. So here in this code snippet, we declare TYPE items_aa IS TABLE of VARCHAR2(60) INDEX BY BINARY_INTEGER. Next, we declare l_items_aa of type items_aa. So now l_items_aa can accept index values up to the binary integer range, and you can keep adding elements to it and its size can keep increasing up to the limit of BINARY_INTEGER. The associative array can also hold negative values; so here, you can have negative index values also, as shown in this code snippet, where l_items_aa(-10) index holds a value Treadmill. The associative arrays can be sparse. Associative arrays need not have consecutive index values. So here, after the index value of -10, the next index value we are reporting is for index value 20 with obviously a lot of gap in between these index values. The index values need not be consecutive as evident from this code snippet, where we put a valued index counter -10 first, 20 next, and then add index counter value 3. When we reassign the value at an index counter, it overrides the previous values stored at that counter. For instance, if we reassign the value at index 20 and make it Elliptical, then it will override the previous assignment of Bike, printing the value of l_items_aa(20) at this point will give us a value of Elliptical. You can add values at the index counters in nonconsecutive random order, but they will be sorted internally by the integer values. We'll talk about sort order shortly. First, let us take a look at a demo to understand associative array indexes and their assignments.

Demo: Associative Array Index

In this demo, we will see how assignments can be done to associative arrays using negative, non-consecutive index values. So here in the anonymous block, you first declare the TYPE items_aa is table of varchar2(60) INDEX BY BINARY_INTEGER. Next, we declare l_items_aa of type items_aa. We start off assigning our index counter -10 and negative index counter a value of Treadmill. At index 20, we assign a value of Bike and print it. And then again, at a non-consecutive index value of 3, we assign Elliptical. We can override the previous assignment as index 20 with the value of Elliptical and print it again. Let's run it. As expected, the value at index counter 20 initially is Bike, and later has overwritten to Elliptical, so it is possible to assign negative, non-consecutive index counters to associative arrays, and reassigning at an index counter overwrites the previous assignment. Next, we will take a look at some of the possible exceptions we can encounter while working with associative arrays.

Exceptions with Associative Arrays

Let us now take a look at some of the possible exceptions you may encounter while working with associative arrays. You may encounter an exception if you try and assign a null value to an associative array declared with a not null constraint. For example, in this code snippet, items_aa is declared as TYPE items_aa IS TABLE OF VARCHAR2(60) NOT NULL INDEX BY BINARY_INTEGER. The NOT NULL keyword would not allow a NULL value assignment. So we declare l_items_aa of TYPE items_aa, and if you try and assign a value of null at index 1, you will get an exception PLS-00382: expression is of wrong type. Another exception you may encounter is the value error, which you will get if we assign the new length exceeds the declared length, or if the value cannot be converted to the type declared. So for example, here items_aa IS TABLE OF VARCHAR2, with a maximum length of 4. Later, when we try and assign a value of Treadmill, we will receive the ORA-6502 error, or a numeric or value error. You can use the predefined VALUE_ERROR exception to cast this. One common exception you might encounter is the no data found exception when you are trying to access the value at an index counter which does not exist. So in this code snippet, since we have assigned values only at index counter 1, trying to access value at a non-existent counter of 2 will give ORA-01403, or no data found exception. We'll see how to check for non-existent indexes to prevent this error when we talk about collection methods in the next module. Another error you may encounter is the numeric overflow if we try and assign an index value outside the range of the index data type. For instance, here we have declared the associative array INDEX BY BINARY_INTEGER. BINARY_INTEGER has a range of values, and if you try and assign an index counter outside this range, you will get ORA-01426, or numeric overflow error. Let us now see a demo to understand these exceptions better.

Demo: Exceptions

In this demo, we will take a look at some of the common mistakes which may lead to exceptions when working with associative arrays. We have declared TYPE items_aa IS TABLE OF VARCHAR2(4) NOT NULL INDEX BY BINARY_INTEGER, and we declare a local variable, l_items_aa of type items_aa. L_items_aa is a not null array, and we try to assign a NULL value to it at index counter 1. Let us run this block to see what happens. We get the PLS-00382, or expression is of a wrong type error. Next, let us try and assign it a value larger than 4 characters, as that is the maximum size of VARCHAR2 string for the array value. Let us run it again. This time, we get ORA-06502, or numeric or value error. Let us now increase the VARCHAR2 size from 4 to 10. Using dbms_output.put_line, we are now trying to access the value at index counter 2, which does not exist. Let's run it. As expected, we get a no data found exception. Let us next look at the First and Next collection methods to understand how index data types affect internal sorting of elements.

FIRST & NEXT Collection Methods

At this time, let me introduce you to two collection methods, First and Next, which will help us understand sorting an associative array. Collection methods are called on the collection_variable using the dot notation, followed by the method name. Method FIRST will run the first index counter in the collection, and method NEXT will get a next index counter in the collection, the one next to index counter passed on to it. Note these methods that are done on the index counters and not the values stored in the collection handles and next counters. Associative array sorting happens automatically based on the index data type. When it is numeric, it is ordered based on integer values. In case of VARCHAR2, it is ordered based on the character string. You may add values at index counters in any order, but an associative array will automatically sort it based on the index data type. So here is the code snippet we saw earlier where we declare a TYPE items_aa IS TABLE OF VARCHAR2(60) indexed BY BINARY_INTEGER. We declare l_items_aa as of type items_aa, l_index as BINARY_INTEGER, and l_value as VARCHAR2(60). In the execution section, we assign values at index counters -10, 20, and 3. The function FIRST applied against a collection variable l_items_aa will return -10, as it comes first in the numeric order. If it is an empty collection, then it will return a NULL value. The WHILE loop is one way to iterate to a collection. We will talk about the other methods to iterate to a collection in the next module. In the WHILE loop, we check on the l_index value. In our example, it is -10. Since it IS NOT NULL, we enter the LOOP. We get the value of that index counter in l_value variable. We can print the index counter and the value at that counter, which at this point is -10 and Treadmill. Then, we call the NEXT method against the l_items_aa collection variable, passing in l_index, which will give us the next index counter after l_index. So in the sorted order, after -10 will come 3, which will be fetched in l_index. Since it is NOT NULL again, we continue in the LOOP, and get the value at index counter 3 in l_value, and print them giving us 3 in Weights. We call the NEXT method again; this time we will get 20, which is last according to the index sort order. Again we enter the WHILE loop, get the values at index counter 20 in l_value, and print the values 20 and Bike. Calling NEXT now will result in NULL, as there are no more elements after this, so the LOOP will terminate. So even though the values were assigned in a different order, they were sorted automatically based on the BINARY_INTEGER value. In this code snippet, let us see how they will be ordered if the index counter is of type VARCHAR2. We are declaring an associative array days_aa IS TABLE OF NUMBER INDEX BY VARCHAR2(20). Then we create a local variable l_days_aa of type days_aa, l_index is of type VARCHAR2. In the execution section, we assign l_days_aa, passing in the index value Sunday, and give it a value of 1. For index counter Monday, we give it a value of 2. And index counter Tuesday, we give it a value of 3. Now, this array will be ordered by the character string, so calling FIRST on l_days_aa collection variable will result in the index counter of Monday. Calling NEXT will lead to Sunday, and calling NEXT again in the loop will result in Tuesday. Finally, calling it again will come back with a NULL, at which point the loop with terminate. For a VARCHAR2 index data type, the sort order is affected by NLS_SORT and NLS_COMP parameter settings in the database session. These parameters determine how the database sorts the collectors internally. If you change these parameter settings in your session after populating your collection, then calling FIRST or NEXT may lead to an unexpected results. Generally these parameters are not changed frequently, and so you should not have this problem. Let us now take a look at a demo to understand sorting better.

Demo: Associative Array Sorting

In this demo, we will see how the associative array index can affect the internal sorting. We have declared items_aa IS TABLE OF VARCHAR2(60) INDEX BY BINARY_INTEGER. L_items_aa is of type items_aa, l_index is a BINARY_INTEGER, and l_value of VARCHAR2. We start on the execution section by assigning at index counter -10 a value of Treadmill, index counter 20 a value of Bike, and at index counter 3 a value of Weights. Now using the collection method FIRST against l_items_aa will give the first index in the array. While this is NOT NULL, we enter the LOOP, get the value of that index in l_value variable, print the l_index and the l_value at that index, and then, call the next index in the array by calling the NEXT method, passing in the current value of l_index and fetching the run value in l_index again. This loop will continue until l_index is NULL, or there is nothing more to fetch. Let us run this. So despite assigning values in irregular order, they are sorted internally and come out as -10, 3, and 20. Now let us see how a character data type for the index affects sorting. Here, we have declared days_aa IS TABLE OF NUMBER INDEX BY VARCHAR2(20). L_days_aa is of type days_aa; L_index is of type VARCHAR2(20). Now we assign at index Sunday a value of 1, index Monday a value of 2, and index Tuesday a value of 3. Again we apply the method FIRST to l_days_aa collection variable to get the first index value. While it is NOT NULL we enter the LOOP, print the index value, and get the next one by calling the NEXT method, passing in l_index and getting the next one in l_index again. This continues on until NEXT returns NULL, or no more data. Let us run this. We get Monday, Sunday, and Tuesday as the order in which they are sorted and stored internally based on the character string value. Now let us talk about where we can declare associative arrays, and how that comes into play with session persistence and visibility.

Visibility & Session Persistence

As we saw in the previous example, associative arrays can be declared in the anonymous block. They can also be declared in stored program units, like procedures, functions, packages, triggers, etc. Declaring them locally in an anonymous block, or locally in the declaration section of a program unit, makes them have a local visibility. So here, declaring items_aa inside a function makes the type available only to the function, and no other program unit outside this function can see it or use it. However, the TYPE declaration in the packet specification makes the associative array visible to all the other program units in the system. This follows the scope and visibility rules of variables we discussed in the module on packages in the Oracle PL/SQL Fundamentals-Part 1 course. So here, declaring it in a package called globals, make this type available to other program units in the system. So now the function, instead of declaring the type again, simply can declare a variable of TYPE globals.items_aa. This helps centralize associative array definitions and consistent reuse across program units. This also allows making changes easier, as it has to be done at one place, and it reflects immediately across all consuming clients. Declaring it in a package specification also provides associative arrays session persistence. So here in the package globals, we define TYPE items_aa IS TABLE OF VARCHAR2(60) INDEX BY PLS_INTEGER. Then we declare g_items_aa of type items_aa. Now, g_items_aa can serve as a place for your variable for session data persistence. It can be assigned values in any program unit in the system, say the set_items PROCEDURE where we can assign it values. We use the globals prefix to refer to the variable declared in the globals package specification. Now, the items data is available to other program units in the system. So for instance, the get_items procedure can now work with this data inside it and fetch values from it. This can be useful for small lookup tables, or data which can be populated once in the system and used at several places without the need to re-fetch. Declaring it as a part of packet specification also allows us to use an associative array as a RETURN data type for other program units, and can help facilitate easy data exchange. So here in the package globals we have declared the type items_aa. Now, it is a type which is the RETURN data type of the function in it, which returns globals.items_aa. Inside the function we declare a variable l_items_aa of type globals.items_aa, and later in the body, fill it with values and return it. Now later, in another program unit or an anonymous block, we can declare a variable l_items_aa of type globals.items_aa, and initialize it by assigning it the return data from the function in it. Let us look at a demo now to illustrate returning collection data from a program unit and using collection variables to persist session data.

Demo: Session Persistence

In this demo, we will declare some global collection types, and then, use them to persist session data for the item IDs. Later, we will use the item IDs in a function getOurAccount to return a collection containing the count of orders for each item ID. So we start off creating a PACKAGE globals inside which we have declared an associative array as TYPE items_aa IS TABLE OF NUMBER INDEX BY PLS_INTEGER. Then we declare a global variable g_items_aa of type items_aa. I like to prefix it with a g to indicate to me that it is a packet specification variable, and thus is global in scope. We then declare a record order_count_rec as type order_count_rec IS RECORD comprising of items, item_id of type NUMBER, and our account of that number. Then we create an associative array order_count_aa IS TABLE OF order_count_rec INDEX BY PLS_INTEGER. Let's compile this. Next is a PROCEDURE set_items where we store the items data in the g_items_aa global variable we declared earlier. We start off with the CURSOR items_cur IS SELECT item_id from items. We declare l_counter of type NUMBER initialized to a value of 0. We begin the execution section running a cursor FOR loop for items_var and items_cur LOOP, fetching the items_cur and items_var variable. We increment the counter, and then assign the item ID fetched at index counter l_counter in global.g_items_aa variable. Being declared in the packet specification, we can refer to it by prefixing the package name. After the loop is over, we have the data stored in the globals.g_items_aa array. Let's compile this procedure. Next is the function get_order_count, which returns back to the calling client the associative array type we declared in the specification globals.order_count_aa. It has a CURSOR inside order_count_cur, which takes in an item ID. P_item_id of type items.item_id%TYPE. The cursor selects count(*) FROM orders WHERE order_item_id is equal to p_item_id. It then declares a local variable l_order_count_aa as of type globals.order_count_aa. L_index, l_item_id, and l_counter are declared as NUMBERs. We begin the execution section and get the first index counter from the globals.g_items_aa array and hold it in l_index. This associative array variable would be populated in the set_items procedure, and this function can see the data inside it and work with it. We run the WHILE LOOP, checking if l_index is NOT NULL. Inside, we get the item_id stored in the global array and that index into l_item_id variable. We increment the l_counter and use it as an index counter to store values in l_order_count_aa array. L_order_count_aa, with l_counter_index passed in, gives us access to the record at that position where we assign l_item_id to the item_id element of the record. We then open the order_count_cur, passing in l_item_id. We fetch the cursor into l_order_count_aa array, now setting the other element, order_count of the record, at counter l_counter. We CLOSE the cursor. We FETCH the next index value from the global items array, passing in l_index, and then continue on with the loop. This way, fetching item_id and order_count for the item IDs in l_order_account_aa array. When there is no more data to fetch from the items array, the NEXT method called will return NULL and the loop will terminate. The function finally returns the table of records, pulling the item_id and the corresponding order_counts. Let's compile this function. Finally, here is an anonymous block, which is of a reclined called where we call these program units in order. We declare l_order_aa of type globals.order_count_aa. L_index is a NUMBER. Inside the execution section, we first populate the global_items table by calling the set_items procedure. Now we call get_order_count function and hold the return collection in l_order_aa variable. We invoke the FIRST method on this collection to get the first index counter, and then use the WHILE loop we direct through it, or putting the item_id and the corresponding order_count. Then, we invoke the NEXT method against the l_order_aa variable, passing in l_index, to get the next index counter. The loop continues until there is no more data to fetch and the next method returns a NULL. Let us run this anonymous block. We see in the output that in the set_items procedure, it was able to set 3 items in the global items array. Since the data is session-persistent, the procedure get_order_count was able to work with it and returns the order_count array with Item Id: 1 having an Order Count of 1, Item Id: 2 having an Order Count of 2, and Item Id: 3 with an Order Count of 3. So this is how associative arrays declared in packet specification can be used for session persistence of data, and how associative arrays can be passed to and fro from param units to pass collection of data. Next, let us take a look at some of the Oracle-supplied associative arrays, and discuss some usage guidelines for associative arrays.

Oracle Supplied Associative Arrays

DBMS_UTILITY and DBMS_SQL packages have some predefined arrays that you can use in your PL/SQL code. For instance, DBMS_UTILITY has DBMS_UTILITY.NAME_ARRAY, which is an associative array of VARCHAR2(30) INDEX BY BINARY_INTEGER. NUMBER_ARRAY IS TABLE OF NUMBER INDEX BY BINARY_INTEGER. DBMS_SQL has varchar2a table TYPE, which IS TABLE OF VARCHAR2(32767) INDEX BY BINARY_INTEGER. Date_table type is TABLE OF DATE INDEX BY BINARY_INTEGER. These are just some of the predefined arrays. There are many more, but these are essentially arrays you an easily define on their own, or if you choose to, you can use the ones which are predefined. Inside your PL/SQL code, you will use them as you would use arrays defined by you. For instance, l_numbers_aa is of type dbms_utility.number_array, and l_date_aa is of type dbms_sql.date_table. Then you can assign values to them normally. For instance, we assign SYSDATE at index 1 to l_date_aa variable.

Comparing Associative Arrays

You cannot directly compare the associative arrays, or compare them to the NULL keyword. So if you had two associative arrays, l_items_first_aa and l_items_second_aa, and you tried to directly compare them, you would get an error. The only way to compare two associative arrays is to first check if their counts are the same, and if so, then iterate over the first array in the loop, and for each item of the first array, iterate over the second array in an inner loop to see if that item exists over there. This is obviously a tedious way of doing this, but a direct comparison for associative arrays does not exist. That is where nested tables are useful, as they can be directly compared. Now let's talk about some of the usage guidelines for associative arrays.

Usage Guidelines

Let us now talk about some of the usage guidelines for associative arrays. As we had mentioned earlier, associative arrays are in-memory tables, so their use is appropriate for small lookup tables, or small number of data values. I generally like to keep the size limited to a few hundred rows in it, but of course it depends on how much memory is available to your instance, and you may have to adjust the number higher or lower based on that. It is useful to pass collection of data to and from a database server. With OCI, or Oracle Call Interface, you can pass the host array as an actual parameter to a subprogram which has an associative array as a formal parameter.

Summary

We covered a lot of concepts in this module. Let us summarize. We talked about what is an associative array, that it is an in-memory table of key-value pairs. We learned how to declare associative arrays, assign values to them, as well as retrieve values from them. We examined the associative array index, and how choosing the index data type can affect the internal sorting of collection elements. We saw that the associative arrays can be declared in anonymous blocks, as well as stored subprograms, and that declaring them as a part of packet specification gives them global visibility and the ability to persist data. Finally, we spoke about some usage guidelines for associative arrays, that they are good as small lookup tables in code to store and pass data between programs. We talked about the First and Next collection methods, but in the next module we will take a closer look at some of the collection methods, as well as examine the ways we can iterate over the collections.

Collection Methods

Module Overview

Hello, and welcome to Pluralsight. My name is Pankaj Jain and welcome to this module on Collection Methods. The collection methods provide an easy and powerful way to get more information about a collection, or manipulate a collection. In order to work effectively with collections, it is vital to have a good understanding of the collection methods. We have discussed the FIRST and NEXT collection methods in the previous module. In this module, we will go over in detail on some of the other useful collection methods. We will discuss these collection methods in the context of the associative arrays, since that is what we have covered so far, but the usage should be similar with other collection types. Most of the collection methods can be applied against all collection types except a few, like the TRIM and the EXTEND methods, which cannot be used with associative arrays. In this module, we will take a look at the LAST method, which gives us the reference to the last index pointer in the collection. The EXISTS method runs a check for the existence of an index counter and is a very useful method to avoid no data found exceptions. We will talk about the DELETE method and its various _____, the COUNT method, which is used to get the collection count, the PRIOR method, which can be used to iterate or a loop in reverse, the TRIM method which is used to trim a collection. We will take a look at the syntax of the EXTEND method, which is applicable against nested tables and varrays. I want to discuss it here in the context of collection methods, but we will see the detailed usage of the EXTEND method in the next module when we talk about nested tables. We have seen one way to iterate over a collection, that is using the WHILE Loop. Now, we will examine some other effective ways to iterate over a collection. There is a lot of exciting stuff to talk about. So let's get started.

LAST, EXISTS, DELETE & PRIOR Methods

The collection_method, as we had discussed earlier, can be invoked against a collection_variable by putting a dot at the end, followed by the method name. This should sound familiar to those coming from Java or C# background where we use dot notation to invoke methods on objects. The LAST method returns the last index counter in the collection, so in this code snippet, we have declared and associative array as TYPE items_aa IS TABLE OF VARCHAR2(60) INDEX BY BINARY_INTEGER. L_items_aa is of type items_aa, and l_last_index is a BINARY_INTEGER. We assign values to l_items_aa in irregular order at index counters -10, 20, and 3. Calling LAST against l_items_aa will give us back 20, the last index counter based on the numeric sort. The EXISTS method takes in the parameter n, which is the index counter you want to check for existence in the collection. It returns a Boolean value, true if the index n exists, and false otherwise. You will use this to iterate through a sparse collection. If you try and access a nonexistent element at index n, you will normally get an exception, but the EXISTS method provides us a means to check for that situation and hence, avoid exceptions. So here in this code snippet, if you try and access a nonexistent index counter of 1, it will return a FALSE. So first, using the IF check, we make sure that the index counter exists and only then we try and access the value of that index. Otherwise, if you try and access a nonexistent index, it will raise ORA-01403, or no data found exception. The COUNT method returns the count of the elements present in a collection. Since the varrays do not allow a sparse collection, the value returned by the COUNT function is the same as the index value returned by the last function for varrays. However, since associative arrays and nested tables do allow for a sparse collection, the value returned by the COUNT method may be lower than the value returned by the LAST method in case elements are deleted, or index values are missing from the middle. So for example, in this code snippet in our sparse associative array, which contains 3 elements at index values -10, 20, and 3, the COUNT function returns 3 and the LAST function ordered on the last index value of 20. The DELETE method has several _____ forms. In the simplest form, issuing DELETE without any parameter removes all the elements of a collection. So as shown in this code snippet, after calling DELETE, all the elements are removed and it becomes an empty collection. So if you call the COUNT function on the l_items_aa array, it will return a 0, and this is the only form of the DELETE method which can be applied against varrays. If the DELETE method is called with an index counter parameter of n, it deletes the element at index n from the associative array or the nested table. If n has a value of null, DELETE(n) does nothing. So calling DELETE with a parameter of 20 in this code snippet would remove the element at index 20. Calling the EXISTS method for index value of 20 will return a FALSE, and the DBMS_OUTPUT statement would never get called. The delete method with two integer parameters, m and n, removes all elements from m to n, m and n inclusive, from an associative array or a nested table. If m is larger than n, or if m or n is null, DELETE(m,n) does nothing. For example in this code snippet, we assign values at index counters -10, 20, 25, and 27. Executing the DELETE method against l_items_aa, passing in index counters 20 and 27, will delete index counters 20, 25, and 27, so everything between 20 and 27 will get deleted, including 20 and 27. Calling the COUNT method against l_items_aa will now result in a value of 1. The method PRIOR, as its name suggests, get the prior index counter in the collection, the one prior to the index counter n passed in. So in this code snippet, we have again the items_aa IS A TABLE of VARCHAR2(60) INDEX BY BINARY_INTEGER. L_items_aa is of type items_aa. L_prior_index is of type BINARY_INTEGER. We assign values at index counters -10, 20, 25, and 27, so calling PRIOR method on l_items_aa passing in an index counter of 25 will return back 20, as it is the index counter just before 25 in the collection. As we saw earlier, the NEXT method can be used in a WHILE loop to iterate over a collection in the forward direction. PRIOR can help iterate a collection in the reverse order. We will take a look at that shortly when we talk about iterating over collections. Let us now take a look at a demo to understand these collection methods better.

Demo: Last, Exists, Delete & Prior Methods

In this demo we will take a look at the collection methods in action. We start off by declaring TYPE items_aa IS TABLE of VARCHAR2(60) INDEX BY BINARY_INTEGER. L_items_aa is of type items_aa. In the execution section, we assign values at index counters -10, 10, 20, 25, and 27. Using DBMS_OUTPUT, you print the initial count by applying the COUNT method against l_items_aa, which will return us a value of 5, and the initial last index counter by using the LAST method against l_items_aa, which would give us back 27. We then print the value prior to the last index counter by invoking the PRIOR method against l_items_aa. We pass in the l_item_aa.LAST method to return value to it, which would be 27. This should return us an index counter of 25. Next, we call the DELETE method against l_items_aa, passing in 20 and 27, so it will delete everything between those counters, including next counters 20 and 27. We print the new count, which would be 2, and the new last index counter, which would be 10. We call the EXISTS method against l_items_aa, passing in the index counter of 25, which we just deleted. Using the NOT operator we are saying that if index counter 25 does not exist, print using DBMS_OUTPUT that Index 25 does not exist. Finally, we call the DELETE method without any arguments against l_items_aa. This should delete all of the elements in the collection and calling the collection method against l_items_aa will return a count of 0, and the last method will return us null. Let's run it. As expected, initial count is 5 and the initial last index counter returns as a value of 27. The PRIOR method returns us 25. After deleting index counters, the new count is 2, and new last index counter 10. The EXISTS method tells us that the index counter 25 does not exist. And finally, calling DELETE against l_items_aa results in 0 count and null being returned as the last index counter. Let us now talk about some of the remaining methods, like TRIM and EXTEND, which are applicable only against nested tables and varrays.

TRIM & EXTEND methods

Let me briefly talk about some collection methods like TRIM and EXTEND, which are applicable only for nested tables and varrays. We will see examples of them in the modules on nested tables and varrays later on. The TRIM method without any argument, removes one element from the end of the collection. TRIM, with an argument of n, removes n elements from the end. If you try and trim more elements than there are in the collection, you will receive a subscript beyond count exception. EXTEND is another method you cannot use with associative arrays. You can use it only with nested tables and varrays. I want to introduce you to it now, and we will take a look at some examples when we talk about nested tables in a later module. It has three formats, EXTEND with no argument will just add a null element to the end of the collection. It takes into account deleted elements. So if a collection has 10 elements and if we delete the element at index counter 10, calling the EXTEND method will add a null element to the 11th position, keeping the deleted spot intact. EXTEND, with a parameter of n, will append n null elements to the end of the collection. EXTEND, with parameters n and i, appends n elements to the end of the collection, copying the value of the element at index counter i to them. Having taken a look at the collection methods, let us now try and understand how we can iterate over the collections, both in the forward and reverse direction.

Iterating Over Collections

Having fetched a bunch of values in a collection variable, oftentimes you will have a need to iterate through the collection. There are two main ways to iterate a collection, the FOR loop and the WHILE loop. Again, this discussion applies to all the collection types. We took a look at iterating over a collection using the WHILE loop in an earlier module. We will quickly review it over here, along with seeing how to iterate in reverse order. The first way to iterate is by using the numeric FOR loop. You will use this loop generally when the collection is dense, and you want to iterate through all the elements of a collection. This would be the simplest way to iterate through a dense collection. So in this code snippet, we again have our type items_aa, which is a table of VARCHAR2(60) INDEX BY BINARY_INTEGER and we have declared l_items_aa of type items_aa. We assign values at index counters 4, 5, and 6. Now using a LOOP, we iterate from the value returned by l_items_aa.FIRST, which will return a 4, to l_items_aa.LAST, which will return 6. So we iterate from index values 4 to 6, and inside the loop we print the values at those index counters, Treadmill, Bike, and Elliptical. You can also use this method for iterating through a sparse collection, but then you will have to check for the existence of the index counter using the EXISTS operator. So here, say the assigned value is at index counters 4, 6, and 8. Now again, we iterate from the first value which is 4, and last value which is 8, but then, inside the loop we have an IF condition checking for the existence of index counter i, and only if it exists, do we try and access its value. So the IF will be true for i values of 4, 6, and 8. Without the EXISTS check, say if you had tried to access the value at index 5, it would have raised ORA-01403, no data found exception. A better way to iterate through a sparse collection is by using the WHILE loop. This way of looping is also useful if you want to exit, based on a certain condition before the entire iteration is complete. We had talked about iterating a collection using the WHILE loop earlier, so here, let us quickly review it. So here, we have assigned values at index counters 4, 6, and 8 again. Using the FIRST method we get index counter 4. Then in the WHILE loop we check if l_index returned by the FIRST function IS NOT NULL. In that case, we give the value at that index, and later at the next index counter using the NEXT method against the collection variable l_items_aa. So the FIRST method will result in an index counter of 4. Inside the loop the NEXT method will return 6, and then 8, and then finally NULL, indicating no more elements, at which point the WHILE evaluation becomes false and we exit the loop. This method, of course, would also work for looping through a dense collection. You can loop in the reverse order using the WHILE loop, using the LAST and PRIOR methods. So here, values are assigned at index counters 4, 5, and 6; using the LAST method, we get the last index value at 6, and then we start iterating with that. Then in the loop, we call the PRIOR method to get the prior index value, which will return 5 in the first loop iteration, 4 in the next, and finally null, at which point we exit the loop. Looping in reverse can also be done with a numeric FOR loop using the REVERSE keyword as shown in this code snippet. So here, assignments are done at index counter 4, 5, and 6. The REVERSE keyword will loop in reverse between the values returned by the FIRST method, which is 4, and the LAST method which is 6. So inside the index, values will appear in the order 6, 5, and 4.

Demo: Iterating Over Collections

In this demo, we will see different ways to iterate over a collection both in the forward, as well as the reverse direction. We start off by declaring TYPE items_aa IS TABLE OF VARCHAR2(6) INDEX BY BINARY_INTEGER. L_items_aa is of type items_aa. In the execution section, we assign values at index counters 4, 6, and 8. Now using the FOR loop, we iterate from l_items_aa.FIRST, which should get us back 4, to l_items_aa.LAST, which should return a value of 8. We'll fetch the LOOP counter in the variable i. If you want to know more about loops and its constructs, please refer to Oracle PL/SQL Fundamentals-Part 1 course on Pluralsight. Inside the LOOP we'll print the counter i. We check for the existence of the index counter using the EXISTS function, and if it exists, we'll print Counter i exists and get its value. Note, since this is a sparse associative array, if you would not have used the EXISTS operator, you would have got the no data found exception. Let's run this block. As expected, the FOR loop goes from 4, the first value, to 8, the last value. The EXISTS method against counter 4 returns true, and we get its value. Counter 5 does not exist. Counter 6 exists and we get its value. Counter 7 does not exist. And counter 8 exists and we get its value. Let us now see how we can traverse this loop in reverse. We have to make a small change and report the REVERSE keyword in FOR loop. Let us run this block again. Now the loop traverses in reverse, going from index counter 8 to index counter 4. Next, let us take a look at using the WHILE loop to iterate over the collection. Here we have the same array, which has been filled at index counters 4, 6, and 8. We first obtain the first index counter by applying the FIRST method against l_items_aa. This should give us back a value of 4. Now we start a WHILE loop checking if l_index is NOT NULL. We get the value at l_index and l_value. We print the current index and its value. We then call the NEXT method, passing in the current index, to get the next index counter, again in l_index variable. This should give us 6. We'll print the next index and continue with the loop as long as it is NOT NULL. The loop will continue giving us the next value at 8, and then null, at which point we will finally exit. Let's run the block to confirm. We get the first index at 4 with the value of Treadmill, and the next index counter comes at 6. With 6 the value is Bike, and the next index counter after it is 8. With 8 the value is Elliptical, and the next index counter is null at which point loop will terminate. So using the WHILE loop is more compact and efficient for sparse collections. Let us now take a look to see how we can traverse the WHILE loop in reverse. We have to make a change to start off with the LAST element, and then, inside the loop we get the previous index counter using the PROIR method. Let's run it again. As expected, we get 8, 6, 4, and finally, null index counter going in reverse.

Summary

In this module, we looked at collection methods, which allow us to manipulate the collection as a whole, or provide more information about a collection. We talked about collection methods, like LAST, EXISTS, COUNT, DELETE, and PRIOR. The methods TRIM and EXTEND can only be applied against nested tables and varrays. We looked at ways to iterate over a collection using the FOR loop, which is a good way to iterate a dense collection and when we want to access all the elements of the collection. The WHILE loop allows us to iterate a sparse collection more effectively. We have also seen how to iterate in reverse using the LAST and PRIOR methods and the WHILE loop and REVERSE keyword in the FOR loop. In the next module, we will take a look at nested tables, which is another collection type available in PL/SQL. The nested table has some unique operators, and the multiset and the set operator, which allows us to perform union and intersection of two nested tables, as well as the table expression which makes querying and manipulating nested tables so much more easier. Let us now take a look at nested tables in detail.

Nested Tables

Module Overview

Hello, and welcome to Pluralsight. My name is Pankaj Jain and welcome to this module on Nested Tables. In this module and the next, we will take a look at nested tables, another collection type available in Oracle. In Oracle PL/SQL, associative arrays is the most commonly used collection type, but nested tables have some unique advantages in terms of the table expressions and multiset operator, which can make PL/SQL programming compact and simple. Let us take a closer look at this powerful collection type. In this module, we will talk about how we can define, initialize, and use nested tables. We will see how we can add and remove elements using methods like EXTEND, TRIM, and DELETE. We will talk about some of the exceptions we can encounter while working with nested tables so that we can program appropriately to avoid them. Finally, we will see how to define nested tables at the schema level, and interact with them in PL/SQL, how we can INSERT, DELETE, UPDATE, and SELECT from the nested table columns defined in database tables. In the next module, we will continue with our discussion on nested tables, and see the use of the powerful table expression, which can be used to un-nest nested table elements, and do piecewise insert, update, and delete operations on them. We will see the use of operators like multiset, set, submultiset, as well as see how we can compare nested tables. But first, let us talk about the fundamental concepts of working with nested tables in this module. Let's get started.

Declare & Initialize Nested Tables

Nested tables can be declared in PL/SQL blocks, like anonymous blocks, and stored subprograms like procedure, functions, triggers, packages, etc. They can also be declared at the database schema level and used as columns of database tables. We'll talk about how we can declare them at the database schema level, along with focusing on the PL/SQL definition and usage aspects of nested tables. The syntax for defining nested tables in PL/SQL is TYPE<type_name>IS TABLE OF <element_type> with an optional NOT NULL constraint. The type_name is a user-defined name. IS TABLE OF is followed by element_type. For PL/SQL declaration, the element type can be any PL/SQL datatype, like number, date, character, records, etc., except ref cursors. The optional NOT NULL keyword imposes a constraint on a nested table not to have a null value at any index. So as you might have noticed, the nested table definition has no INDEX BY keyword as for the associative arrays. This is what distinguishes its declaration from PL/SQL tables or associative arrays. So for example, here we declare a nested table TYPE mytype_nt IS TABLE OF NUMBER. Again I like to put the nt effect to easily distinguish nested tables in the code and increase readability. TYPE mytype_nt IS TABLE OF VARCHAR2(60) NOT NULL declares a nested table of type VARCHAR2(60) with an additional NOT NULL constraint. TYPE mytype_nt IS TABLE of customers%ROWTYPE declares a nested table, each element of which is a record containing the columns of the customers table. In SQL the definition is similar, just that we use the CREATE(OR REPLACE)TYPE keyword, followed by the <type_name> IS/AS TABLE of <element_type> with an optional NOT NULL constraint. Create or replace replaces any existing definition, so CREATE OR REPLACE TYPE mytype_nt IS TABLE OF NUMBER creates a nested TABLE OF NUMBER at the schema level. CREATE OR REPLACE TYPE mytype_nt IS TABLE OF VARCHAR2(60), NOT NULL creates a nested table, which will not accept null values. Again like associative arrays, you cannot work with these nested tables directly. These definitions establish nested table types, which can now be used to declare variables with which we can work. So l_items_nt is defined as of type items_nt, and we can now work with it. If we had declared the nested table at a schema level, we can very well refer to it in the PL/SQL block as an available type. L_items_nt table at this point of time is atomically null. As it stands right now, l_items_nt is atomically null. If you try and access l_items_nt and maybe invoke the COUNT function on it, you will get the error ORA-06531 Reference to uninitialized collection. One way to initialize the nested tables is to use a constructor. You need to use a constructor to initialize nested tables. So in this code snippet, we use a constructor which is the name of the type, followed by parenthesis. Inside the parenthesis we are passed some arguments which are the elements of the collection. So as of now, it has 2 elements, and invoking the COUNT function will result in 2. You can also call the constructor at the time of declaring the variable, as shown over here. Using the constructor without any arguments will result in initializing the nested table variable as an empty collection. However, it will not be atomically null at this point of time. Calling COUNT on it will not error out, and now it will return a value of 0. Let us now do a quick demo to see these concepts in action.


Demo: Initialization

In this demo we will demonstrate that an uninitialized nested table is atomically null, and we will also show the various ways to initialize it using constructors. So here in this anonymous block, we have declared TYPE items_nt IS TABLE of VARCHAR2(60). L_items_nt is of type items_nt. At this point, l_items_nt is atomically null, and invoking the COUNT method against it will result in an error. Let us run it to confirm. We get an error ORA-06531, Reference to uninitialized collection. Let us now initialize a variable using the default constructor with no arguments. Let us run it again. This time we do not get an error, and the COUNT method returns a value of 0. Now let us use the constructor, which takes in arguments. Now the constructor takes in two elements, Bike and Treadmill. Running the block now will give us a count of 2.

Adding Elements

Before we talk about adding elements to a nested table, let us talk about its index counter. An index counter can be an integer or an expression which results in an integer. It does not allow string indexes. The index starts with a value of 1, and its upper limit is the upper limit of PLS_INTEGER. Let us see how we can add elements to the nested table now. After you have initialized the nested table, either with the empty constructor, or with the constructor with some initial elements, you can add more elements using the EXTEND method. We had spoken about the EXTEND method in the last module, but let us understand it better with some examples in this module. In the first format, the EXTEND method with no arguments will add a null element at the end of the collection. This is the format most often used to add elements to a nested table. So here in this code snippet, we have initialized it at an empty nested table, calling EXTEND on l_items_nt will add an element at the end of the collection. If for example we had used the constructor with two elements for initialization, it would have added a third element at the end with a null value. In this example, since we have no elements in the collection, it will add the first element at the end. Now, you can assign a value at a newly added element by using l_items_nt, and using the index value returned by the LAST method called on the l_items_nt collection variable. You could have as well passed in here a value of 1, but generally it's rough keeping track of the number of times you have called EXTEND. It is often easier to use the LAST function to get the last in an element index counter. So here, after the first call to EXTEND, we add Bike at index 1; we call EXTEND again to add the second element, and add Treadmill over there. Calling the COUNT method on l_items_nt at this point of time will give us a value of 2. Let me also show you how to initialize and add elements to a nested table composed of a more complex type, say a record. So here, we have defined a record, items_rec, consisting of two elements, item_name of items.item_name%TYPE, and count of type NUMBER. We can declare a nested table items_nt as TYPE items_nt IS TABLE of items_rec. We then declare l_items_nt of type items_nt and initialize it. Then, we extend it to add an element. Now using l_items_nt, passing in an index of l_items_nt.LAST, we access the record element added at that point, and then using the dot notation, we access the inner item name and assign it a value. We similarly access the count element of the last error record, and assign it a value. We can similarly add more elements by using the EXTEND method. We can access the inner element by using l_items_nt, passing in the index counter of 1 will then give us access to the record at that index counter. By using the .item_name we can get the item name of the record. So here is how you might practically see yourself adding elements to a collection, dynamically using a cursor fetch. So in this code snippet, you have again declared our items_nt nested table of VARCHAR2(60), and l_items_nt of type items_nt initialized using an empty constructor. We then have a CURSOR get_items in which we are fetching * from the items table. Now in the execution section, using a cursor FOR loop, we fetch from the items table and get it in the get_items_var variable. We now call the EXTEND method to extend a nested table, and then add the fetched item_name in the cursor at the LAST error index. So this extending and adding goes on in the loop until all items are added. This is a simple illustration to show you how you might be finding yourself using it most of the time. The other format of the EXTEND method is extend, with a parameter of (n) when you already know the elements in advance you need to add. So here in this code snippet, I have called the EXTEND method with an argument of 2 since I want to add 2 elements. And then, I add the 2 elements at index counters 1 and 2. The last format of the EXTEND method is extend with arguments n and i where we want to add n elements at the end of the collection, copying the value of the element at index i to each of those. So here in this code snippet, I have called the EXTEND method with an argument of 2, and added 2 elements at index counters 1 and 2. Then we call the EXTEND method, adding two more elements, copying the element value at index 1. This will make the count of the elements as 4, so printing the values at index counters 3 and 4 will result in Bike. Let us see some other ways to assign values to nested variables next.

Removing Elements

A nested table can be sparse like an associative array. We can use the DELETE method or delete elements from a nested table. The DELETE method with an argument of n will delete the element at index n, and DELETE method with no arguments will remove all the elements of the collection. So here in this code snippet, we have a nested variable l_items_nt to which we are assigning values at indexes 1, 2, and 3, and then using the DELETE collection method, passing in an argument of 2, would delete the element at index 2; this will result in a sparse collection. Doing a count against the l_items_nt nested table variable at this point of time, will result in a value of 2. Next, we call the DELETE method with no arguments and that should delete all the elements of the nested table variable, and doing a COUNT now will result in a value of 0. Another thing to note is that reassigning overwrites the previous value at that index counter. So here at index 1 we initially assign a value of Bike, and later reassigning a value of Elliptical at index 1 again, will override that value. Printing at index 1 will give us Elliptical. Let us now take a look at some other ways to assign values with nested table variables.

Nested Table Assignments

We can assign a nested table to another nested table of the same type. So here, we declare l_items_nt and l_copy_nt, both of type items_nt. We initialize l_items_nt, we EXTEND l_items_nt by 3 elements and add the elements at counters 1, 2, and 3, then, we copy l_items_nt to l_copy_nt. This initializes, as well as adds the elements to the nested table l_copy_nt. If we print the value at index 2 for instance, for l_copy_nt, we will get the value of Bike. Like associative arrays, you can assign a nested table to another one if they are of the same type. So here, even though items_nt and dup_nt are composed of VARCHAR2(60), but since they are different type names, you cannot assign l_items_nt which is of type items_nt, to l_dup_nt which is of type dup_nt. We can assign an empty nested table l_copy_nt to l_items_nt to make it an empty nested table also. This is useful in loop processing, for example, to flush out a nested table at the beginning of a loop. Let us now take a look at a demo to understand these concepts better.

Demo: Nested Table Assignments

In this demo we will see how to use the various forms of the EXTEND method to add elements and increase the size of a nested table. We will also see the use of the DELETE method, and how arrays can be reinitialized using empty array variables. We will finally look at a cursor fetch, and how you would use the EXTEND method inside it to store an unknown number of fetched items from a database table. So here in this code snippet, we have declared a record, items_rec, which consists of two elements, item_name of type items.item_name%TYPE and count of type NUMBER. Next we declare a nested table, items_nt, as table of items_rec. Then we declare a variable l_items_nt of type items_nt nested table, and initialize it using the nt constructor. We start off using the first form of the EXTEND method, which does not take any arguments, to extend the nested table with one element at the end. Now we assign value to l_items_nt with the counter at the index value return from l_items_nt.LAST method, which would be 1 at this point. This exposes the record at that counter, the item name of which is assigned a value of Bike, and the count a value of 1. We again extend the l_items_nt array, and again using the index counter returned by the LAST method, which will return a 2 in this case, assign Treadmill to the name, and a count of 2. We print the COUNT and item_name at index 1. Let's run it. As expected, the count is 2, and the item name is Bike. Now we have made a slight change; instead of extending the nested table twice, we have used the second form of the EXTEND method, which takes in the number of elements to extend, and we have extended a nested table variable by two elements. This time, we use the counters 1 and 2, as using the LAST method would have returned us a value of 2 in both the cases. Let us run it again. We get the same result. Next, let us add to this code the third form of the EXTEND method where we say extended by 2 elements, copying the value of the element at item 1. We again print the COUNT, which will return us a value of 4 now, and now let us print the item at the index counter 3, which will return us Bike, as we copied it from item 1. Let's run it to confirm. The count is indeed 4, and the item name at index 3 is Bike. Let us now add a DELETE, deleting the element at index counter 2. This should leave us with a count of 3. It will be a sparse collection with a gap at index counter 2, but the item at index 3 should still be Bike. Let's run it to confirm. The count is indeed 3, and the item name is Bike at index 3. Finally, let us take a look as to how to do a cursor fetch into a nested table variable and extend it dynamically to accept and unknown number of elements. Let us do a SELECT against the items tables first. We've got three items over there. Next, we have an anonymous block where we are declaring TYPE items_nt as a TABLE of VARCHAR2(60), l_items_nt is of type items_nt, initialized to an empty nested table. We have our CURSOR get_items, which does a SELECT * from items table. Inside we have a cursor FOR loop fetching the get_items_ cursor and get_items_var. We extend the l_items_nt variable. We then assign value to l_items_nt at the index counter of the last error element, the value of the item_name fetched from the cursor. So in the loop, we keep extending and adding the elements until the loop terminates. At the end, we check the count and then iterate over our nested table variable using the FIRST and LAST methods to see the items stored in it by the cursor fetch. Let's run it. As expected, three items were fetched and iterating over the nested table variable, we see their values as Bike, Treadmill, and Elliptical. Let us next talk about some of the possible exceptions you can encounter while working with nested tables.

Exceptions

Let us talk about some of the possible exceptions you may come across while working with nested tables. The NOT NULL constraint imposes a restriction on the nested table variable that it cannot have a null value at any index counter. So as in this code snippet, if you have defined in a set table with a NOT NULL constraint, and if you accidentally assign a NULL value to any index, you will get PLS-00382: Expression is of wrong type error. As we had talked about earlier, working with uninitialized collections will raise errors. So here in this code snippet, we haven't initialized the variable l_items_nt, and if we try and assign it a value at that point of time, we will receive an error Reference to uninitialized collection. So if we do initialize the collection, but then we try and assign a value without extending it, as in the code over here, then we will get Subscript beyond count exception. This is because the subscript does not exist yet. It can be caught using SUBSCRIPT_BEYOND_COUNT predefined exception. If you try and access an element at an index which has been deleted, you will get a No data found exception. So in this code snippet, we first EXTEND a nested table, assign value at index 1, and then DELETE it. So now, trying to access the value at index 1 will raise a No data found exception. It can be caught in the EXCEPTION block using the predefined NO_DATA_FOUND exception. Like associative arrays, if you try and assign a value larger than the length of the datatype which the nested table can hold, you will receive a value error. For instance, in this code snippet, items_nt can hold a VARCHAR2 string up to 4 characters long. When we try and assign a longer string, Treadmill, to it, we will get the value error ORA-6502 numeric or value error. It can be trapped by the predefined exception VALUE_ERROR in the EXCEPTION block. You can also get the value error if you try and assign an index which is not an integer. For instance, here a string at row A. You will get a subscript outside limit error if you try and assign an index value beyond the range of values a nested index type supports. So for instance, if you try and assign an index value of 0, it will raise ORA-6532 subscript outside limit error, which you can catch using the predefined exception SUBSCRIPT_OUTSIDE_LIMIT. We had talked about the TRIM method in the module on collection methods, let us take a closer look at that method next.

Trim Method

We had talked about the TRIM method earlier, but let us now see how it can be used to reduce the size of a collection. It is applicable only for nested tables and varrays. The TRIM method without any argument will remove one element from the end of the collection. So in this code snippet, we add elements at index counters 1 and 2, making the size 2. Then we apply the TRIM method on the collection, making its size to 1, as evident from the DBMS_OUTPUT statement. The TRIM method works on internal collection size, so even if you delete and element from a nested table, say in this code snippet, it will delete the element at index counter 2. Oracle still maintains a placeholder for index 2 where a value can be assigned later on. So calling TRIM over here would acknowledge the internal size of 2, and would remove the placeholder at index counter 2, bringing down the size to 1. Calling the TRIM method with an argument of n would trim n elements from the end of the collection. So here in this code snippet, we have extended the nested table twice and added elements at index counters 1 and 2. But now, calling TRIM with an argument of 2 will remove all the elements; invoking COUNT on the variable will now result in a value of 0. If you try and trim more elements than there are in the collection, it can raise Subscript beyond count exception. So here, we have added two elements to the nested table. Trying to call TRIM with an argument of 3 would raise Subscript beyond count exception. Let us now see a demo to see these concepts in action.

Demo: Trim Method

In this demo, we will see the various exceptions we can encounter while working with nested tables. Having this awareness, we can code appropriately to avoid them. We will also take a look at the TRIM method usage. First, we have a simple anonymous block where we have declared TYPE items_nt IS TABLE of VARCHAR2(60) NOT NULL. Then we declare l_items_nt of type items_nt. In the execution section, we try and assign value at index 1. Let's run it. We get the error ORA-06531 Reference to uninitialized collection, as we have not initialized the nested table variable, and it is atomically null at this point. Let us now initialize it using an empty constructor and run it again. This time we get the error ORA-06533 Subscript beyond count, and even though it is not null, we have not extended the variable yet to make space for the addition, and so subscript 1 does not exist and Oracle reports it as beyond count. Let us now extend the variable, but this time we're adding a NULL value to it. Let's run it. This time we get an error PLS-00382 Expression is of wrong type, as we have constrained the variable to be NOT NULL and we are trying to add a null value to it. Let us now extend it, add Bike at index 1, then delete what we had added at that index, and then try to access it. This time we get ORA-01403: no data found, and even though we did extend the variable, we deleted an element at index 1 and then tried to access it. Let us now remove the delete, make the length of the items_nt type as 2. We are assigning a 4-character length value Bike to it. Let's run it now. This time we will get ORA-06502 numeric or value error. That is because we are a trying to assign a value whose length is larger than what the type can hold. Now instead of the integer index, let's try and assign a character index; this time we will get value error again as only PLS_INTEGER indexes are allowed. Let's run to confirm it. We get ORA-06502 numeric or value error. Let's now change the index counter. We have made it 0, which is not allowed as it is outside the PLS_INTEGER range. Let's run it again. We get ORA-06532 Subscript outside of limit exception. Finally, let us see the use of the trim method. We first EXTEND the array by 3 elements, add values at index counters 1, 2, and 3, we print the count before the trim which should give us back 3, then we call the TRIM method, which will remove one element from the end. Calling count again should now give us a value of 2. Let's run it to confirm. As expected, count before calling the TRIM method is 3, and count after calling the TRIM method is 2. Next, let's call the trim with an argument of 2, and then do a count again. Calling trim with an argument of 2 removed the remaining 2 elements and the count now results in the value of 0. Next, let's see how we can create nested tables at the schema level and interact with them in PL/SQL.

Schema Level Nested Tables

We can create nested tables of at the schema level. These can then also become part of our database table. Some of the advantages for creating schema-level nested tables is that once defined, they're now available to be consumed across the entire system. You need not redefine the types in your PL/SQL code, and use the schema types as any other type available in the database to work on, with consistent definition across all consuming clients. They can be made columns of a database table, which allows you to store a collection of data in a single column of a database row. For instance, you can have a row for each student and a nested table collection column to hold all the subjects the student is enrolled in. Doing it this way can sometimes be more efficient in terms of storing all the information in one place, and retrieving them without having to join multiple tables. Let us see how we can create nested tables of a schema level. CREATE OR REPLACE TYPE items_nt AS TABLE OF VARCHAR2(60) will create a nested table type at the schema level. The CREATE OR REPLACE keyword will either create a new type, or will replace a type definition if one already exists. If you want to hold multiple elements within each type at the PL/SQL level, you can create a record and then create a nested table type of that record. The way to do it at the schema level would be to create an object and create a nested table type comprising of that object type. Oracle Database is an object-oriented database, and allows for inheritance, object methods and attributes, concepts familiar to programmers coming from languages like C# or Java. We will not be discussing Oracle objects in this course, but to create an object, you would simply issue the command CREATE TYPE orders_ot AS OBJECT, and define the attributes you want that object to hold. So in this case, we are storing order_id of type NUMBER and order_item_id, which is of type NUMBER again. Now we can define a nested table as CREATE OR REPLACE TYPE orders_nt IS TABLE OF orders_ot. Now each row of the nested table type will have the orders_ot object with its two columns. Now we can use these to define columns in the database table. For instance, here we have a database table, account_orders, which has the act_id, and for a given act_month, the list of distinct items requested by that account in the columns itemslist, which is of type items_nt. Just like with other column types, you can optionally supply a default value to that column. Here, I have assigned no argument constructor items_nt with empty parenthesis. This way the column is no longer null, and I like to do it this way so that in my PL/SQL code, I can directly start extending and working with it. I have another column, orderslist of type orders_nt, with a DEFAULT assignment of orders_nt empty constructor. You can have multiple nested tables within a database table, and for each, you have to supply a storage clause with STORE AS, and can give it any name. You do not have to worry about this name and you will refer to the column name when working with the column. It is an Oracle internal storage name for this nested table type. So, NESTED TABLE itemslist is stored internally AS itemslist_store and NESTED TABLE orderslist as stored internally as orderslist_store. So the orderslist will store a list of all the orders placed by the act_id for a given month. You can drop a type by simply issuing the command DROP TYPE <type_name>, followed by the optional FORCE or VALIDATE keywords. So issuing DROP TYPE mytype_nt will drop this type, however, if the type mytype_nt has dependents, then trying to drop it will raise an error ORA-2303, cannot drop or replace a type with type or table dependents. Using FORCE will drop the type even if it has dependent database objects. However, this option is not generally recommended as it is irrevocable and will make the data in the dependent tables or columns to be inaccessible. Unless you specify a FORCE, you can drop only object types, nested tables or varray types, that are standalone schema objects with no dependencies. This is the default behavior. If using the VALIDATE option when dropping a type, Oracle Database checks for stored instances of this type within substitutable columns of any of its super-types. If no such instances are found, then the database completes the DROP operation. This option is meaningful only for subtypes. Let us briefly see how we can change the size of the nested table element after creating it, as sometimes you might have a need to increase the column size to accommodate new data value requirements. The command is ALTER TYPE <NESTED_TABLE> name, MODIFY ELEMENT TYPE <new_datatype_size> with optional CASCADE or INVALIDATE keywords. The INVALIDATE keyword will invalidate all dependent objects and CASCADE will propagate the changes to its type and table dependents. Oracle allows you to only increase the size, so for numeric datatypes you can increase the position, and for VARCHAR2 or all element types, you can increase the size of the variable character. So here, we have created our type, items_nt, as table of VARCHAR2(60). We can increase the size to VARCHAR to 100 by issuing ALTER TYPE items_nt MODIFY ELEMENT TYPE VARCHAR2(100) CASCADE. You cannot reduce the size. For instance, here if you try and reduce the size to VARCHAR2(10), Oracle will give you an error PLS-00729, only widening of the collection element type is allowed. Let us now see how we can insert, update, delete, and select from nested tables, both in PL/SQL and SQL.

DML on Nested Table Columns

Let us now see how we can insert into a nested table column. So here is a table for reference. Say we want to insert a row in the table for the month of January. In PL/SQL, you will declare l_items_nt of type items_nt, and initialize it. We create l_orders_nt and initialize it too. We create a variable l_orders_ot of the object type orders_nt, and initialize it, passing in the order_id of 1 and order item_id of 1. We start off the execution section extending the l_items_nt table by 2 elements, and then add at index counter 1 a value of Bike, and at index counter 2 a value of Treadmill. Similarly, we extend the l_orders_nt with two elements. At index 1 you can assign the l_orders_ot variable we had created earlier and assigned values to. And at index counter 2, we assign a value directly by calling the orders_ot constructor and passing in values of 2 and 2. I wanted to show you both ways of passing objects, creating an object variable, as well as default assignment using the object type constructor. Next, we insert in the account_orders table the 4 columns with values of 1 for act_id, JANUARY for act_month, l_items_nt variable for itemslist, and l_orders_nt for orderslist column. Doing it in SQL is the same syntax, just that we are using the constructor to create elements and pass them in the values clause. Items_nt constructor with 2 elements of Bike and Treadmill, will go in the itemslist column, and orders_nt constructor, which takes in 2 orders_ot objects, one with values 1 and 1, and the other 2 and 2 will go in the orderslist column. Let us see how we can update nested tables stored as database columns. So now PL/SQL code, let us say we modify the l_items_nt variable to now just hold one element, Elliptical, and the l_orders_nt to have 2 orders_ot elements with values 1,1 and 3,3. UPDATE accounts SET itemslist = l_items_nt, orderslist = l_orders_nt will update these column values for the row where act_month is equal to JANUARY. In SQL, the statement is pretty much similar where with update we set values passing in the new values with the items_nt constructor and orders_nt constructor. Here, we are swapping the nested table column totally. But what if we wanted to modify just one sub-element within the nested table collection? We will take a look at doing piecewise updates later in the next module. Deleting is pretty simple, where in PL/SQL you would issue a normal DELETE to get rid of the entire row as usual. You can also set the values to NULL using an UPDATE, which will in effect flush the values inside the nested table columns, and you can run the same statement through SQL with no modifications. You can select a nested table column in a local variable of the same type inside of PL/SQL code and work with it as you would work with it normally. So for instance, here in our PL/SQL code snippet we have declared l_items_nt is of type items_nt, and l_orders_nt as of type orders_nt, initialized with empty constructors. Then using a CURSOR, we SELECT itemslist and orderslist from the account_orders table for act_id of 1 and act_month of JANUARY. Inside the execution section, we open the cursor and fetch these two into l_items_nt and l_orders_nt variables. From this point on, we can iterate over them using the FOR loop, applying the FIRST and LAST methods against them as we have seen earlier. If you issue a SELECT from this table, you will get the nested column type output as shown. So here it shows DEMO.ITEMS_NT with two items in it, Bike and Treadmill. And here is the output for the orderslist column which shows the ORDERS_NT type within which is the ORDERS_OT object types within which are the elements for order_id and orderitem_id, which are 1 and 1 and 2 and 2. But what if you wanted to get the output in the un-nested form? Say you wanted to query for the order_id from within the nested type. That is where the TABLE expression comes in handy. We will take a look at it in the next module. Let us now dive into a demo to understand these concepts better.

Demo: DML on Nested Table Columns

In this demo we will see how to create a nested table column in the database to hold a collection of values. We will see then how to work with these nested table columns in our PL/SQL code, as well as how to perform DML on them using SQL. We have created a nested table type items_nt before. Let's describe it. Items_nt is a table of VARCHAR2(60). Next, let us create an object, orders_ot as object consisting of two elements: order_id of type NUMBER, and order_item_id of type NUMBER again. So this object contains the order information. Next, let us create a nested table, orders_nt, as table of orders_ot. This creates a nested table, which is a collection of order objects. Let us now create a database table, account_orders, containing information about act_ids, the act_month, and for each row for act_id, a collection of items ids for which it places orders as itemslist of type items_nt, and a collection of all the orders, orderslist of type orders_nt. We didn't specify the nested tables stored as class, NESTED TABLE itemslist STORE as itemlist _store, and orderslist store as orderslist_store. Let's create this table. Let us see how we can insert in this table from PL/SQL. We have an anonymous block where we declare l_items_nt of type items_nt, and initialize it. L_orders_nt is of type orders_nt, initialized with an empty constructor. L_orders_ot is an object of type orders_ot, and initialized with values of order_id 1 and orderitem_id of 1. In the execution section, we extend the l_items_nt variable by two and add Bike and Treadmill to it. We extend l_orders_nt by 2 and add l_orders_ot, which we had created earlier at index 1, and at index 2 assign an object orders_ot with order_id 2, and order_item_id 2. We then insert into the account_orders table for act_id 1, month JANUARY, l_items_nt for itemslist, l_orders_nt for orderslist, and then COMMIT. Let's run this block. Let us now do a SELECT against the account_orders table. Indeed, the _____ inserted successfully. We see the nested representation of ITEMS_NT with the two elements, and ORDERS_NT which has two nested ORDERS_OT objects inside it. You can also perform an INSERT from SQL as shown. Here using data constructors, we are passing in values for act_id 2, act_month MARCH, and items_nt with Weights, and orders_nt with 2 objects with values 5,5 and 6,6. Let's run this. Let us select again from the table. Now we see two rows for JANUARY and MARCH. Let us see now how we can update these columns. In this anonymous block, we are extending the l_items_nt and adding Elliptical to it. L_orders_nt is now having two objects. With the UPDATE, we set the itemslist to l_items_nt, and orderslist to l_orders_nt, replacing the earlier nested tables stored at these columns for act_id 1, for the month of JANUARY. Let's run this block. Let's run the SELECT again. Indeed, the nested columns are swapped for the new values. Doing a DELETE is pretty simple, where we delete for act_id 1, and month JANUARY. Let's run it. Now let's SELECT from the account_orders table. We see that there is just 1 row for act_id 2, and month MARCH. So we can interact with the nested table columns of a database table both from PL/SQL and SQL with extreme ease. We have come to an end of this module. Let's summarize what we talked about.

Summary

In this module, we covered some of the fundamental concepts involving working with nested tables. We saw how to declare and initialize nested tables. Without a constructor, a nested table variable is atomically null. We have to initialize a nested table variable to work with it. We can initialize it using either an empty constructor, or the one with elements. We saw how we can add elements using the various forms of the EXTEND method, as well as how we can remove elements using the DELETE or the TRIM methods. We saw some of the exceptions, for example, no data found or value error, you can encounter if you are not careful working with nested tables. We then saw how to define nested table types at the schema level, and how they can be made as nested table columns in the database table to store a collection of related values with each row. We saw how we can perform DML on these nested table columns, using both PL/SQL and SQL. Next, let us further explore nested tables and see how we can un-nest the individual elements from a nested table column using the table expression. We will see how we can compare nested tables and talk about a lot of useful operators like the multiset operator.

Nested Tables: Comparison, TABLE & MULTISET Operators

Module Overview

Hello and welcome to Pluralsight. My name is Pankaj Jain and welcome to the second module on nested tables where we'll talk about the Nested Tables: Comparison, TABLE and MULTISET Operators. In this module we will continue our discussion on nested tables and cover some important operators. We will start off with the TABLE Expression, which is a very easy and powerful way to unnest individual elements from out of the nested tables. The TABLE Expression also allows us to do piecewise DML and selects against nested table columns. We will take a look at examples of doing this. We will then talk about the MULTISET operator, the MULTISET union distinct and accept operators which allow us to do set operations against two nested tables. One of the advantages of working with nested tables is that they allow direct comparison of two nested tables. We will see how to do that. We will then complete our module by talking about some of the other useful operators like the SET, SUB MULTISET, CARDINALITY and MEMBER OF operators. These make working with nested tables very easy and provide a lot of useful utility functions. So let's get started.

Table Expression

In the last module we were working with the account orders table, which had two nested table columns, itemslist, and orderlist. We saw how running a select against the table displays data in the nested format inside the underlying types. For instance, elements bike and treadmill show up inside ITEMS_NTBike and ORDERS_OT type appears within the nested table type ORDERS_NT. What if we wanted to extract the nested elements out from the nested columns directly in our queries? This unnesting can be performed using the TABLE Expression. The TABLE Expression can take in a collection column like a nested table column on a _____ column in its first form. It is not applicable for associative arrays. In this form it allows us to work for the collection table as if it's a table. The rows and columns on the collection can be used in the from class of the select statement. So for instance, here we have a select statement, SELECT a.act_id, b.COLUMN_VALUE FROM account_orders aliased as a TABLE a.itemslist aliased as b WHERE a.act_id is = to 1. So here account orders, the parent table is aliased as a. The table operator takes in the nested column a.itemslist and it is given the alias of b. Oracle will automatically join this table with the corresponding row of the parent. Now we can query the inner element as b.COLUMN_VALUE. COLUMN_VALUE is a special keyword you use in the select statement to get the value from a single element collection type. In this case it's gonna give us back the item id. Along with it we are also selecting a.act_id from the parent row of the account orders table. The output will be as shown, since there are two rows in the nested table, the account id in the join will show up twice, as you would expect in a normal join. Next, let us see how we can fetch from the orders list nested table, which is internally comprised of the object containing two elements. Again, the alias account orders and alias of a, the table operator takes an a.orderlist and is given an alias of b. Now we select a.act_id, b.order_id, b.order_itemid from the table of orders list. Since it has multiple elements, you can get to the internal elements by their name. The alias of b exposes the object in the nested table and you get the inner element by using the dot notation and the internal element name. So the output will be as shown over here. Here is a pictorial presentation of the rows in the table. There are currently two rows for the months of January and March. For the month of March, the itemslist and orderlist columns are not having any values. If you execute in the select statement as shown, joining account orders tables a with the table a.itemslist, then you just get back the row for ACT_ID 1, but not for ACT_ID 2. As they joined you don't have a match in the nested table column for ACT_ID 2. So just like a regular table join, if you want to get back the account id information from the account orders table, you will have to make an outer join. So here you make an outer join by putting a plus sign against the table operator, which says that even if there is no matching column values, still return the column from the order table. And now the output will be as shown with ACT_ID 2 and null column value. And here again is the same example with the multicolumn nested table column orderslist, which is empty for the month of March. Running the query as shown will not return ACT_ID 2. Making an outer join by putting a plus sign against the table operator will bring back the value from the appearing table for ACT_ID 2. In the previous module we saw how we can insert, upgrade, and delete nested table values as a whole. Now let us take a look at how we can do piecewise DML operations against nested tables. Before we go there, let us first do a demo to see the TABLE Expression in action.

Demo: Table Expression

In this demo we will see how to use the TABLE Expression to unnest the elements out of the nested table columns. Let's first select from the account orders table. There are currently two rows in there for account id 1 and account id 2. Account id 2 has null values for itemslist and orderslist columns. Let us see how to unnest the item name element from the itemslist nested table column. So here we join the parent table account_orders, which we have given an alias a with the TABLE Expression taking in a.itemslist and given an alias of b and then select its single element item name as b.COLUMN_VALUE. Let's run this. So we were able to unnest the two items names from the itemslist column. Next, let's see how we can unnest the order ID and the order item ID elements from the orderslist nested column. Select a.act_id, b.order_id, b.orderitem_id from account_orders a, table operator, taking an a.orderslist column with an alias of b. Let's run this. It returns back the two rows to us for the two rows in the nested table column for account id 1. Oracle here is automatically joining the table operator to the parent table row of account orders. If you have been noticing, it is returning us back information only for account id 1 in the output as the join fails for account id 2 for null values of itemslist and orderslist. We can get information about account id 2 by using outer join as we would use for normal columns. So here, putting a plus sign against the table operator, we perform an outer join. Let's run the statement again. This time we do see account id 2 in the output and the two null nested columns. We can run the same query in PL/SQL. So here is the same query in a PL/SQL block as a part of the cursor definition for get info cur. We can retrieve the column's anomaly and individual variables of appropriate types, or as a cursor for loop in the cursor variable get info var. Inside, we print the values it retrieved. Let's run it. As expected, we see account id 1 and 2 and the null column values for account id 2. Let us now take a look at the second form of the TABLE Expression, which will enable us to do piecewise DML against nested table columns.

Piecewise DML

The other form of the TABLE Expression is the one where it takes in a subquery, so as shown in this SQL, instead of taking in a collection column, we have a subquery inside the TABLE Expression which returns back a collection column. Select orderslist from account_orders WHERE act id = 1, will return back the orderslist nested table. The TABLE Expression has an alias of a and using that we select a.order_id and a.order_item_id from it; however, there are certain restrictions on the subquery you can place inside the TABLE Expression. First, the subquery should only return a collection type like a nested table or ______. It should return back only one column and not multiple columns and the return value should be a single collection item and not multiple items. So in our query if condition where account id is equal to 1 would not have been unique and would have returned multiple rows, we would have received an error. Let us see how we can do piecewise inserts. So here is account orders table and it has a row in there for account id 1 with two items in the items list, bike and treadmill. Say we want to insert a third item, elliptical to it. The way to do it in PL/SQL is using the TABLE Expression with a subquery as shown in this course snippet. Select itemslist for account_orders where account id is equal to 1, inside the TABLE Expression would return us back the itemslist nested table, which we can manipulate. Now we can insert in this table using the insert into class and pass values to it. We would use the same syntax if you have to run it as a SQL statement. Let us see how we can do a piecewise insert for our nested column having multiple elements like the orderlist column. It has two elements, order_id and order_item id. Again in PL/SQL the TABLE Expression takes in the query select orders list from account_orders where account id is equal to 1. It will return us back this orderslist column. In the using the values class we insert a third row 3,3 to it. Doing it outside PL/SQL using the SQL statement follows the same syntax. Piecewise update follows a similar approach of retrieving the nested table using the TABLE Expression, _____ long to update the itemslist item element, elliptical, and make it weights, again using the TABLE Expression, we select itemslist from account orders where account id is equal to 1. Since it is a single element nested table, we refer to the element as column_value and set its value to weights where column_value has a value of elliptical. This will replace weights with elliptical. Running it as a SQL statement will follow the same syntax and here it is for a multiple element nested table column orderslist. Say we want to update the order id and order item id from 3 to 4. In PL/SQL we again get the orders list column for account id 1 using the TABLE Expression. Now we update it as a normal table with a set class, setting the order id and order item id to a value of 4 where the previous value is 3. A similar syntax follows for running it as a stand-alone SQL statement. The other way of doing the piecewise update is by using the values class. The values of class allows us to replace the inner element or object using the _____ the nested table is comprised of, so here, since our orderslist table is a table or orders_ot object type, we do a piecewise update by first giving an alias to the TABLE Expression a, then using value a with sends the inner object to the order_id with a value of 4 and 4 where a.order id is equal to 3 and a.order item is equal to 3. The same syntax follows for a stand-alone SQL statement and how do we use the values class if we want to update a single element nested table column, say, for example, over here we want to update elliptical to weights. In case of a single element column comprised of a basic data type like VARCHAR 2, we can set the value a to weights where column value is elliptical. A similar syntax will follow for SQL statement. Let us see how we can do a piecewise delete. Let's say we want to delete the third element, elliptical. The piecewise delete will follow the same pattern of first getting the nested table column we want to operate upon using the TABLE Expression and then deleting the column value you want to remove, in this case elliptical. The same syntax would be used for a stand-alone SQL statement. For doing a piecewise delete from a multiple element nested table column, like, for instance our orderslist column over here, say we want to delete the third row. We will follow the same way for deleting a multiple element nested table by first selecting the column in the TABLE Expression. The only difference is that we use the actual inner element name before I need to find the rows to delete versus the column value keyword for a single element nested table, and the same syntax follows for a SQL statement. So Oracle provides us a very fine-grained control to manipulate the nested table elements. Let us now take a look at a demo to see the piecewise operations in action.

Demo: Piecewise DML

In this demo we will see how to perform piecewise DML on nested table columns. Let's first start off reviewing the data in the account orders table for account id 1. We see that currently the orderslist column for account id 1 has two orders in it. Now let's do a piecewise insert in the account orders table using the TABLE Expression. Select orders list from account_orders where account id equal to 1 inside the TABLE Expression will return back the nested table column orderslist for account id 1 for which we insert a third row with values 3 and 3. Let's execute this. Let's select again from the account orders table. As we can see, a third row was inserted successfully. Next, let us update the orderslist column again for account id 1 using the TABLE Expression. Let us update order id to be 4 and order item id also to be 4 for our previous insert of 3 and 3. Let's run this block. Let's select from the account orders table again. As we can see, the third row was indeed updated with the new value being 4. Now let us update using the values class. Our TABLE Expression has an alias of a so a set value a, using the orders ot constructor having a value of 5 and 5 will update where a.order id is equal to 4 and a.order item id is equal to 4. Let's run this again. Let's select from the account orders table. Indeed, the value was updated from 4 to 5. Finally let us delete from the orderslist column for account id 1 the row where the order is equal to 5. Let's run this. Let's select again from the account orders table. Indeed the row with value 5 and 5 is gone and we are left with two rows as expected. Let us now take a look at the multi-set operator which is a very powerful operator to perform unions and dissections, etc., on nested tables and transform them.

MULTISET Operators

One of the reasons nested tables are convenient to work with is due to the MULTISET operator. The MULTISET operator is a very convenient operator which can be used to transform nested tables. It greatly simplifies coding and performs a lot of useful, commonly needed operations against nested tables. We all are familiar with union, intersect, and minus, which you can use in SQL to compare two sets of rows. The MULTISET operator provides a similar functionality when you want to compare two nested tables. The nested tables have to be of the same type, however. Let us see the comparison between MULTISET operators and equivalent SQL operators. The MULTISET union is similar to UNION ALL operator in SQL, which combines the two sets of records, keeping the duplicates. MULTISET UNION DISTINCT is similar to the UNION operator in SQL, which eliminates the duplicates. MULTISET INTERSECT is equivalent to the INTERSECT operator which results in the rows or records which are common to the two sets. MULTISET EXCEPT is equivalent to the MINUS operator in SQL, which results in the rows present only in the first set and not in the second. Let us now take a look at these in more detail. The MULTISET UNION operator takes two nested tables as arguments and returns a nested table as a result, which is also of the same type. The ALL option is the default, which combines the elements of the two nested tables including nulls and keeping the duplicates. DISTINCT returns the distinct values. So for instance, if our first nested table has three elements, bike, treadmill, and elliptical, and the second one has treadmill and elliptical, applying the MULTISET UNION ALL will return in combining the two, keeping the duplicates. So here is the same example in the code snippet where we have the two nested tables, l_first_nt, and l_second_nt of type items_nt. L_final_nt is also of type items_nt to hold the result. We apply the MULTISET UNION command to get the command result in l_final_nt. All is the default option so we do not have to specify it. MULTISET UNION DISTINCT eliminates the duplicates including duplicate nulls. So applying the MULTISET UNION DISTINCT to the same two sets will result in bike, treadmill, and elliptical, eliminating the duplicate treadmill and elliptical elements, and here is the code snippet showing this operation in PL/SQL. L_first_nt MULTISET UNION DISTINCT l_second_nt will result in distinct values in l_final_nt. The MULTISET operator can also be used when working with nested tables defined at a schema level. To understand that, let's create a type items_nt as table of VARCHAR 260. Let us use this type in the item_orders table, which holds for a given account month the list of items ordered from our two stores, store 1 items and store 2 items, both of which are of type items_nt with a default constructor items_nt applied to them at the time of defining. Nested tables store 1 is stored as store 1 and nested tables store 2 is stored as store 2. Let us say for the month of January store 1 sold bike, treadmill and elliptical, while store 2 sold treadmill and elliptical. So in PL/SQL we have l_final_nt of type items_nt. Then we have the cursor cur_get_items as select store 1 items MULTISET UNION, store 2 items from item orders where account month equal to January. So applying the MULTISET UNION between the two column values which would fetch in l_final_nt will give us the items from the first bike, treadmill and elliptical, and the items from the second, treadmill and elliptical. You can simply run the statement in SQL also. Applying MULTI UNION DISTINCT would give us the distinct values of bike, treadmill, and elliptical. The same SQL statement can be run in SQL. In SQL, if we run the SQL statement, select store1_items MULTISET UNION DISTINCT, store2_items from item orders where account month equal to January, you will get the output which shows the nesting of values within the items_nt type. If you want to unnest or get the individual values you can use either of the two TABLE Expression forms. For example, using the first form you can issue select column value from item orders a, table, a.store1_items, MULTISET UNION DISTINCT, a.store2_items with an alias of b, where a.act_month = January. The resulting nested type will become the table b and since it is a single column, we get the value as column_value or we can have the query inside the TABLE Expression and then select from it as in select column value from table, select store1_items, MULTISET UNION DISTINCT, store2_items from item_orders, where account month equal to January. Using either of these forms we can unnest the elements and the output will be as shown. The MULTISET INTERSECT ALL finds the elements common to the two nested sets. ALL is the default which would include duplicates and using the DISTINCT option just gives us the distinct elements. So in this example, the MULTISET INTERSECT will result in a nested table with the common elements treadmill, elliptical and elliptical. Here it is in the code snippet where we again have the two nested tables and applying the MULTISET INTERSECT will result in treadmill, elliptical, and elliptical. Since are losing the MULTISET INTERSECT ALL option, it gives us the elements common to the two nested tables, keeping the duplicates. The MULTISET INTERSECT ALL operator can similarly be applied against the nested table columns in the database table. So here is our database table with our two nested table columns, store1_items and store2_items. Again, l_final_nt is of type items_nt. In our cursor, cur_get_items, we are selecting store1_items MULTISET INTERSECT ALL store2_items from item orders where account month equal to January. This will give us the intersection in l_final_nt using the cursor fetch. If you will do it right through this nested table you will get treadmill, elliptical, and elliptical as these are the common values and MULTISET INTERSECT ALL preserves the duplicates. The statement in the cursor can also be run stand alone in a SQL statement. Applying the MULTISET INTERSECT DISTINCT will result in the distinct common values. So in this example, we will get back treadmill and elliptical, the two distinct common values of the two nested tables and here is our PL/SQL code snippet showing the same operation. Here we have type items_nt which is declared as a table of VARCHAR 260. L_first_nt is of type items_nt containing bike, treadmill, elliptical, and elliptical. L_second_nt contains treadmill, elliptical, and elliptical. L_final_nt is of type items_nt and applying MULTISET INTERSECT DISTINCT between l_first_nt and l_second_nt will result in treadmill and elliptical. Applying MULTISET INTERSECT DISTINCT against nested table columns stored in the database table will give us back the same results. So here in the cursor we select store1_items, applying MULTISET INTERSECT DISTINCT, store2_items from item_orders where account month equal to January and doing a cursor fetch should result in treadmill and elliptical. And of course, we can run the same statement in SQL. The MULTISET EXCEPT ALL takes two nested tables as arguments and returns elements present in the first and not in the second, keeping the duplicates. ALL is the default if not specified. For instance, here the first set has duplicate bike elements. Treadmill and elliptical are common with the second set. So applying the MULTISET EXCEPT ALL operator will result in two bike elements. Here is the code snippet demonstrating the same. Applying MULTISET EXCEPT ALL will result in a nested table l_final_nt, which is also of type items_nt and contains the two bike elements and here is the same example against nested table columns. In the cursor select, applying MULTISET EXCEPT ALL will result in bike and bike as these are two elements present in store1_items and not in store2_items and the ALL option keeps the duplicates. You can run the same SQL stand-alone. Using MULTISET EXCEPT DISTINCT against the two nested tables will remove the duplicate bike element and here is the same PL/SQL code and over here, l_first_nt MULTISET EXCEPT DISTINCT, l_second_nt will give us back bike, removing the duplicate. And here is the same illustration against nested table columns and this is the same code which we saw in MULTISET EXCEPT ALL. The only difference is that using MULTISET EXCEPT DISTINCT will remove the duplicates and this time will just get the bike element and of course, we can run the SQL against the table as a stand-alone statement.

SET Operator

The SET operator takes a nested table as an argument and returns a nested table of a same type with duplicate elements removed. So here if our nested table set contains duplicate treadmill and elliptical elements, applying the SET operator against it will remove the duplicates and return us back only the distinct values, and here is the code snippet showing the same. We again define items_nt as nested table of VARCHAR 260. L_final_nt is of type items_nt. In the execution section we apply the SET operator, which returns back to us a nested table l_final_nt of type items_nt containing bike, treadmill and elliptical, eliminating the duplicate elements, and here it is against our nested table columns, store1_items and store2_items. Store1_items has duplicate bike elements and so applying the SET operator against this column in the cursor, select SET, store1_items from item orders where account month equal to January will return us back the distinct elements bike, treadmill, and elliptical. You can run the same statement in SQL also. Let us now see the MULTISET and the SET operators in action in a demo.

Demo: MULTISET and SET Operators

In this demo, first we will take a look at the MULTISET operator in action with nested tables declared in PL/SQL. Later, we will show how to apply it against the nested tables defined in database columns. So here, we have an anonymous block where we have declared a type items_nt as a table of type VARCHAR 260. L_first_nt is of type items_nt and we have initialized it with the constructor, passing in duplicate elements for bike, treadmill and elliptical. L_second_nt is again of type items_nt and has duplicate elliptical elements. L_final_nt is also of type items_nt. We begin the execution section and assign to l_final_nt the result of l_first_nt MULTISET UNION l_second_nt. This should bring all the elements from the two tables, keeping the duplicates because of the default ALL option. Using a FOR loop, we read through the elements of l_final_nt. Then let us apply the SET operator to l_final_nt and again it read through the elements. Let's run this block. As expected, we see the elements from l_first_nt and l_second_nt. Running it the SET operator applied against it removed the duplicate elements. So here it the same piece of code again. We have removed a section of the SET operator and we have changed the MULTISET UNION operator to MULTISET UNION DISTINCT. Let's see how the output looks now. This time we see that we are left with bike, treadmill, and elliptical and the duplicate elements have been eliminated. Next, let's change to the MULTISET INTERSECT operator. (typing) The MULTISET INTERSECT operator will return elements common to both the sets and returns the duplicate elliptical elements. Let's now change it to MULTISET INTERSECT DISTINCT operator. Let's run it again. (typing) The MULTISET INTERSECT DISTINCT operator removed the duplicates and now we are just left with the elliptical element. Let's now change it to the MULTISET EXCEPT operator, which should return us elements in l_first_nt which are not in l_second_nt. (typing) It returns back the duplicate bike and treadmill elements which are present in l_first_nt and not in l_second_nt. Let's now change it to MULTISET EXCEPT DISTINCT. The duplicates are not eliminated and now we just have bike and treadmill. Let us now see how we can apply the MULTISET operator against nested table columns defined in the database table. So here let's first create our table, item_orders, which has account month and two nested table columns, store1_items and store2_items, both of type items_nt with a default _____ constructor. Next, we are inserting in this table a column for account month January. Store1_items will have duplicate bike, treadmill, and elliptical elements and store2_items will have duplicate elliptical items. We then commit the change. Let's run these statements. Let's select from the item_orders table. So everything got inserted successfully. Now here's the field SQL block where we've declared l_final_nt of type items_nt. Using our cursor, we select store1_items MULTISET UNION store2_items from item_orders were account month equal to January. Inside the execution section we open the cursor and fetch it into l_final_nt and then using the for loop we direct the items in the nested table. Let's run this block. As expected, we get a union of the elements of the two nested table columns. The MULTISET UNION ALL option reserves the duplicates. Now let's change the MULTISET UNION operator to MULTISET UNION DISTINCT. Let's run it again. The duplicates are eliminated. Now let's change the operator to MULTISET INTERSECT. (typing) Let's run it again. The MULTISET INTERSECT operator will return us back the common elements in the two nested table columns and it returns us back the duplicate elliptical elements. Let's now change it to MULTISET INTERSECT DISTINCT. (typing) Using the DISTINCT, I eliminated the duplicate and now we just have the single elliptical element. Let's now change it to the MULTISET EXCEPT operator. (typing) The MULTISET EXCEPT operator would give us elements in store1_items which are not in store2_items and so it gives us back the duplicate bike and treadmill elements, which are present in store1, but not in store2. Let's now change it to MULTISET EXCEPT DISTINCT and run it again. (typing) As expected, the duplicate elements are eliminated and we are just left with the bike and treadmill elements. One of the unique advantages of working with nested tables is that Oracle allows us to compare nested tables. Let's take a look at that next.

Comparing Nested Tables

Nested tables, unlike associated arrays can be compared; however, they can be compared only for equality or inequality and not for greater than, less than, kind of operations. The IS NULL, IS EMPTY, IS A SET, or NOT A SET, CARDINALITY, MEMBER OF, and SUBMULTISET are some of the operators, which can be applied against nested tables. Let us take a look at each of these in detail. Using the equal to or not equal to operator you can compare for equality or inequality of two nested tables. They have to be of the same type though so here if we apply the equal operator against these two nested tables, it will obviously evaluate to false, so in this course snippet we have the type declared and the two nested table variables, l_first_nt and l_second_nt filled with values. You can use these comparisons in the if classes as shown. The second comparison of not equal to will evaluate to true in this case and we will get _____ output not equal. IS A SET or IS NOT A SET can be used to check for distinct values. So here a bike is not a set against l_first_nt will evaluate to true since it has duplicate elements. Evaluating is a set against l_second_nt will result back in true since it doesn't have any duplicate elements. Of course, we can use these operations against our nested table columns too. So looking at our item_orders table we notice store1_items has duplicate values while store2_items has only distinct values, so in our PL/SQL code fetching store1_items using a cursor fetch into l_final_nt and applying IS A SET operator against it will result in false. You can use IS A SET or IS NOT A SET operator in case statements in SQL for comparison. So here we select account month case when store1_items is a set and then return it is a set, or else it is not a set and giving the case statement in the alias of dup_items from item_orders. Since store1_items has duplicate values, we will get it IS NOT A SET returned back to us. The cardinality function _____ in a nested table and returns back the count of the elements inside it. So here, applying the cardinality operator against this nested table will return back a value of 5 and here, is our illustration of the cardinality function inside the PL/SQL code. L_first_nt has five elements and applying the cardinality function against it will return us back a value of 5. You can apply the cardinality function against the nested table columns of our database table too. So for instance, here in the select applying cardinality to store1_items will return 5 in that count. You can run the SQL statement stand alone too, applying this function against the store1_items. The MEMBER OF or NOT MEMBER OF condition tests for the existence of an element in the nested table. The data type of the element has to be the same as the data type of the internal element of the nested table. So here we have a nested table, items_nt consisting of three internal elements of type VARCHAR 2. Bike, treadmill, and elliptical. L_present is of type Boolean, checking if bike is member of l_items_nt will return us back true, checking if weights is a member of l_items_nt will return back false. The MEMBER OF operator can also be applied against the nested table columns in your database tables. So here in the cursor we select account month from item orders where bike is member of store1_items. Since bike is a member of store1_items, this condition would be true and January would be returned back. Of course, you can use this operator in a stand-alone SQL statement also. The IS EMPTY or IS NOT EMPTY condition checks if the nested table is empty. So here l_first_nt has elements; l_second_nt is not initialized and is atomically null. Checking for IS EMPTY condition against l_first_nt will return false. If the collection is null then both the IS EMPTY or IS NOT EMPTY conditions will return false and so can be misleading. You should start of checking the IS NULL condition first and then check for IS EMPTY condition. This operator can also be applied against the nested table columns, so as shown in this PL/SQL code snippet, the cursor, cur_get_items is selecting account month from item orders where store1_items is not empty. Since store1_items has elements in it, so this condition would be true and January would be returned back in the cursor fetch and you can apply this operator in a stand-alone SQL statement also. The SUBMULTISET operator checks if one nested table is a subset of another nested table. Of course, they have to be of the same type, so here, l_first_nt is of type items_nt and contains several elements including bike. L_second_nt is also of type items_nt and contains just bike, so the if condition check of l_second_nt SUBMULTISET of l_first_nt will evaluate to true. The SUBMULTISET OF operator can be similarly applied against nested table columns in our database table. For example, in this PL/SQL code snippet the cursor cur_get_items is select account month from item_orders where store2_items SUBMULTISET OF store1_items. This condition of store2_items SUBMULTISET OF store1_items will evaluate to true as both treadmill and elliptical are in store1_items and so the month of January would be returned back. You can run the same statement as a stand-alone SQL statement also. So as you can see, there are several useful operators available with nested tables, which allow easy comparisons and checks against nested tables and this is one of the main advantages of using nested tables. Let us now take a look at a demo to understand nested table comparisons and its operators better.

Demo: Comparing Nested Tables

In this demo we will see how to compare nested tables and the different operators which can work with it. So here we have an anonymous block where we have items_nt as table of VARCHAR 260. L_first_nt is of type items_nt and has two elements each of bike, treadmill, and elliptical. L_second_nt is of type items_nt and contains two elements, both of which are elliptical. In the execution section using the NOT EQUAL TO operator, we can compare the two nested table variables and since they are not equal we should expect NOT EQUAL to be printed out. Let's run it to confirm. Next, let's change the NOT EQUAL TO operator to IS NOT OF SET operator. So _____ is not a set operator against l_first_nt should evaluate to true since it contains duplicate elements and we should get back NOT OF SET in the output. Let's run it to confirm. Next let us see the _____ of the NOT EMPTY operator. Let's change our condition to if l_first_nt is not empty, since l_first_nt is not empty we should expect to see NOT EMPTY in the output console. Let's run it to confirm. Now let us see the MEMBER OF and SUBMULTISET operators. So here we are checking if bike MEMBER OF l_first_nt and since that is true, we should get in the output IS A MEMBER. Let's run it to confirm. Let's change this condition to if l_second_nt SUBMULTISET of l_first_nt. Since the two items in l_second_nt, elliptical and elliptical, are also present in l_first_nt, this condition should be true and we should get IS A MULTISET in the output. Let's run it to confirm. Next, let's see the use of the cardinality operator. So applying the cardinality operator against l_first_nt should give us back 6 since it has six elements. Let's run it to confirm. (typing) Next, let us see how to use some of these operators against nested table columns. First, let's select from the item_orders table to see what's contained in there. We see that for the account month of January the store1_items has six elements with duplicate bike, treadmill, and elliptical elements and store2_items has two elements, both of which are elliptical. Now here is an anonymous block where we have declared l_store1_items as items_nt. Then we have a cursor cur_get_items, which is is select store1_items from item_orders where cardinality of store1_items is greater than 2. So we should expect to get this column back as store1_items has indeed more than two items. We declare l_items_nt of type items_nt and initialize it to bike. Inside the execution section we open the cursor. Fetch the nested table column in l_store1_items and then loop through it. _____ cardinality and then check for IS NOT A SET operative against it. We also check of l_items_nt is a submultiset of l_store1_items, which would be true. Let's run it. (typing) As expected, we get a count of 6, l_store1_items is not a set and l_items_nt is a submultiset of l_store1- items. Let's now summarize what we have talked about.

Summary

In this module we covered a lot of important concepts working with nested tables. We talked about the TABLE Expression, which and be used to unnest individual columns out of a nested table collection. We looked at both the forms of TABLE Expression, the first one which states in the nested table column and the second one which takes in a subquery and returns a single nested table column. We saw how using this form we can do piecewise insert, update, and delete in nested table columns. We then looked at the powerful MULTISET operator, which can be used to perform SET-like operations against two nested tables. Namely we can MULTISET UNION to combine the results of two nested tables, MULTISET INTERSECT to get elements common to the two nested tables, and the MULTISET EXCEPT, which gives everything in the first nested table which is not in the second. The MULTISET operator makes working with nested tables so much more convenient. We looked at using this operator against both the PL/SQL level nested tables as well as the ones we have declared at the schema level. Another convenient operator is the SET operator, which gives us the distinct elements in the nested table. Nested tables are unique among collection types as they allow comparisons. There are several useful comparison operators like IS NULL, IS EMPTY, IS A SET, the CARDINALITY operator, which gives its count, as well as A MEMBER OF and SUBMULTISET operators. Because of these useful operators, which when applied against nested tables, it makes its use ideal for situations where in your field simple code you have to do a lot of comparisons and manipulation of collections. Next, let us take an in-depth look at the third collection type offered by Oracle of varrays.

Varrays

Characteristics & Usage Guidelines

Hello and welcome to Pluralsight. My name is Pankaj Jain and welcome to this module on varrays. A varray or a variable sized array is an array whose elements can vary from 0 to the maximum size specified during declaration. It is the third collection type available with Oracle. In this module we will talk about what is a varray and what are the usages scenarios for varrays? We will see how to declare and use varrays. We will see how to add and remove elements from the varrays, the different exceptions we need to be careful of while working with varrays. We will see how to create schema-level varray types and use them as columns of a database table as well as how we can perform DML on them from PL/SQL. So there's a lot of good stuff to talk about. Let's get started. A varray, as its name indicates is a variable sized array. It is the third collection type available in Oracle. You specify the maximum number of elements the varray can hold at declaration. So the lower bound is 0 elements and the upper bound keeps growing as you add elements to it until the maximum size of the varray is reached. And like the associative varrays and nested tables, which can be sparse, varrays are always dense and they do not allow gaps. You can declare a varray at the PL/SQL level as well as the database level and as columns of database tables. Oracle does allow you the option to increase the size of the schema level varray after declaration. We will see how to do that. Unlike nested tables, varrays can do piecewise operations on nested table columns of a database table. With varrays you cannot do piecewise operations on varray columns of a table. You have to swap the entire varray with a new one if you want to change it. The varray data type maps to the array data type in other languages like Java or C#. This is useful to know when interacting with Oracle in other languages. As I mentioned to you earlier, varrays can be declared in PL/SQL, anonymous blocks, or stored program units like procedures, functions, packages. They can also be declared at the schema level as columns of a database table where with each row you want a collection of values to be stored in a column. For example, with each person row you want to store all their phone numbers in a single column. Oracle stores each varray column as a single object. It is less than 4 kilobytes it resides inside the table otherwise it is stored outside the table, but in the same table space. You would find yourself using associated arrays and nested tables most of the times, but the scenarios where varrays can be useful are where you know the maximum number of elements in advance and you do not want that maximum number to be exceeded. For example, in the storings table say with each _____ row, you have a column indicating the number of books checked out for each student, which is a varray type, in order to specify the maximum number of books a student can check out. The varrays are always dense and are useful when you would generally like to do a sequential access of elements. Since the varrays are stored and retrieved from the database column as a whole object every time, its use may not be very practical for a large number of elements. Varray columns unlike nested table columns, maintain the insertion order of the elements inside it and so they are useful if you want to maintain the order of elements inside it. For instance, you might have the primary and secondary phone numbers you are storing inside the varray column and you always want the primary phone number to come up first when you retrieve elements from the varray column. In that case, using a varray is very practical. Let's take a look at defining and initializing varrays next.

Defining & Initializing Varrays

Let us see how we can define varrays in PL/SQL. The definition starts with a type keyword, followed with the name we want to give to the varray type. IS VARRAY is followed by the size limit in parentheses with just the maximum number of elements it can hold. OF element type specifies the internal data type of the element the varray is composed of, which can be a number, string, record type, etc. You can specify the optional NOT NULL constrained to restrict the null value assignment. Here are a few excitement of the declaring varrays in PL/SQL. Type mytype_va is varray 5 of number creates a varray which would allow a maximum of five elements of type number. The va effects is a naming convention I like to follow for easily identifying varrays in my code. I highly recommend you to follow a naming convention too. Type mytype va is varray 5, on VARCHAR 260 not null will create a varray with a not null constrained and type mytype va is varray 5 of customers percentage row type creates a varray each element of which is a record of type customers. In SQL, the definition is similar, just that we add a create keyword followed by an optional or replace keyword in the big name. Or replace will overwrite an existing definition. We can give our name to the type followed by is or as varray with a size limit. Of element type followed by an optional not null constrained and here are some examples of defining them. Create or replace type, my type va, is varray 5 of number will create a type at the schema level, which can be consumed at the PL/SQL level also. Create or replace type, mytype va is varray 5 of VARCHAR 260 not null creates a not null array of type VARCHAR 260. Just like nested tables and associative arrays, we first declare the type and then we declare the variable of that type with which we can work. So here in this PL/SQL code we declare the type items_va first and then we declare L items va of type items va with which we can work from this point on. If we declare the type at the schema level, then we can declare a variable L items va of that type and work with it. However, this time L items va variables are atomically null. You need to initialize varrays before you can start using them. So here if you try and access the count method against L items va variable, it'll give us ORA-06531 or reference to uninitialized collection error. We have to use a constructor first to initialize a varray variable before we can start using it. So here we have initialized our L items va variable within the constructor, which is of type items va, followed by the elements in parentheses, bike and treadmill. Now it's showing a count against it will give us a value of 2. We can also initialize the varray at the time of declaration as in this code snippet. Again with this, account _____ will give us a value of 2. We can also use a constructor without arguments to initialize it as an NT array. This time you will not get an error when we move the count method against the L items va variable, but a value of 0. Let us take a look at a demo to see creating and initializing varrays in action.

Demo: Defining & Initializing Varrays

In this demo, we will see how to create a varray both in the PL/SQL level as well as at the schema level and then see how to initialize them. First, let's create a varray at the schema level by showing in SQL create or replace mytype_va is varray 5 of VARCHAR 260. This would create a varray, which can hold a maximum of five elements of type VARCHAR 260. Let's run this. Now here is an anonymous block where we start off by creating a varray at the PL/SQL level as type items_va is varray 5 on VARCHAR 260. We then declare L items_va of type items_va and initialize it with an empty constructor. Next, we declare L mytype_va of type mytype va, which we declared at the schema level earlier. So this shows that a schema-level varray has visibility at the PL/SQL level also. We initialize it using the second kind of constructor, which can take in elements. We pass in two elements, bike and treadmill, to it. Inside the execution section, we are printing the count of elements in L items va and L mytype va. Let's run it. As expected, the count of elements inside L items va is zero and L mytype va is 2. So this is how you can start declaring and initializing varrays in your PL/SQL code. Now let us extend our understanding further as to how to add and remove elements from varrays after they have been initialized.

Extending & Reducing Varray Size and Varray Assignments

The varray index like nested tables has to be an integer and should start with 1; zero is not allowed. You can add elements to a varray using the extend method. The usage is similar to as when we were working with nested tables so let me just quickly review it over here. You can use any of the three forms of the extend method. The first form, extend, with no argument will add an element at the end. So here after extending, we add the first element. Then, using the next form which takes in an argument, we can extend it by multiple elements. We extend it by two elements over here and then add elements at the indices 2 and 3. The third form takes in two arguments, the first indicating the number of elements to extend, and the second, the value at index I, which it should copy over to the newly extended elements. So here, it will extend it by two elements and copy the value at element 1 to those two elements, so printing elements at indices 4 and 5 will output bike and here's just an example to show you that you can create varrays of more complex structures like the items_rec, which is a record consisting of two elements, item name and count. The items_va is declared as a varray 5 of items_rec. L_items_va is of type items_va initialized with an empty constructor. Now we can extend it as normal using the last method against it, we get the last index counter added and add that counter to the line record we add the item name and the count. Practically you will use the cursor fetch to get items from a DWS table and fetch it in a varray. However, one thing to note here is that since our varray items_va can hold a maximum of five elements, our cursor definition ensures that we do not get more than five rows by putting here a condition of row num less than 6. Now using the cursor for a loop, you fetch the cursor and get items var. Inside the loop we keep extending the varray and adding the elements of the last index counter added. After the loop is over we have the varray filled up with the elements obtained from the cursor. Generally with the cursor fetch you don't know the number of elements in advance and use up associated varrays or nested tables may be more appropriate. However, in situations where you do know the number of maximum elements you want to fetch, a varray might also be a good option. Let us see how we can delete elements from our varray. You cannot use the form of delete method which takes in an argument. That form deletes the element at an index counter and varrays do not allow sparse collections, so trying to delete the element at index 2 will result in an error near PLS-00306, wrong number of arguments in call to delete. The delete method with no arguments which deletes all the elements of the collection is allowed. The count after calling it, will result in 0. We talked about the trim method earlier with nested tables so I am going to go over it quickly. The trim method has two ordered options. The one without argument deletes an element from the end, but trim with an argument of n deletes n elements from the end. So here in this code snippet we extend L_items_va variable by 3 and add elements at index counters 1, 2, and 3. Calling trim first will remove one element from the end and will result in a count of 2. Calling trim again with an argument of 2 will remove everything and taking a count now will run us back a value of 0. Reassignment will override the previous assignment at that index counter. So here at index 1 we assign bike first and then later reassign it to be elliptical. Trimming the value at index 1 will now result in elliptical. We can assign another varray of the same type to a varray. So here, l_items_va and l_copy_va are both of type items_va. We assign values to l_items_va and then copy it to l_copy_va. This copies all the elements of l_items_va to l_copy_va and printing the index counter at index2 will give us a value of bike, and again, you can assign a varray to another varray as long as it's of the same type. So even though we has the internal data type over here, since they have different names, you cannot assign them to each other. Assigning an empty array would reinitialize and array variable and it can be used in the beginning of a loop processing, for example. So assigning l_copy_va to l_items_va over here will reinitialize it. Let us now take a demo to understand these operations better.

Demo: Extending & Reeducing Varray Size and Varray Assignments

In this demo we will see how to add and remove elements from a varray after it has been initialized. We will see how to assign a varray to another varray. So here in this anonymous block we have declared that a record, items_rec, consisting of two elements, item name and count. We then declared a varray type, items_va, as varray 5 of items_rec. L_items_va is of type items_va and initialized using an empty constructor. We start off by extending the varray, which should add an element to it. L_items_va.last method should return us the last error index or 1 in this case. At this index we assign to them the line_items_rec record, the item name of bike, and a count of 1. We extend it again. Now the last method will run too. We add item name treadmill and a count of two at that index counter. If we want to get the value of the item name element in the record at index control 1, we would use l_items_va 1 to get the recorded index counter 1 and then .item_name would give us access to the item name in that record. We also create the number of elements in the varray, which should return us back at value of 2. Let's run it to confirm. As expected, we get the item name and the next one is bike and count of elements as two. Now let's change our anonymous block to use a second form of the extend method. So now instead of using the extend method twice, we use the second form of the extend method to extend it by two elements. This time instead of using the last method which would give us two both times, we specified index counters one and two. Let's run it again. (typing) We get the same results as expected. Let us now see how to use the third form of the extend method. So here in the third form of the extend method we extend the variable by two elements, copying the value of element and _____ to both. Now we _____ the item name at index 3, which should be treadmill, and the total count, which should return us back a value of 4. Let's run it to confirm. (typing) As expected, we get the item name at record 3 as treadmill and the count is 4. Now let us see how to assign a varray to another _____ of the same type. So we define l_copy_va again as of type items_va and initialize it to an empty varray. Now in the exclusion section after extending l_items_va to four elements and adding values to it, we assign l_items_va to l_copy_va. This would copy all the elements to l_copy_va, so printing the item name and the third element should give us treadmill as before and the count of l_copy_va should be 4. Let's run it to confirm. As expected, the item name is treadmill and count is 4. Let us see how to remove the elements from a varray now. So we have extended our varray two times, first using the second form which extended by two elements and then using the third form, which again extended it by two elements. So at this point of time we should have a total of four elements in the varray. Calling the trim method after adding the four elements should remove one element from the end and the count should come back to 3 now. Calling delete would remove all the elements from the varray and the final count should result in 0. Let's run it to confirm. As expected, after the trim, the count is 3 and delete removes all the elements from the varray. Let us now see how to fetch elements from a DWS table into a varray. First, let us see the content of the items table. We have three items in there. Next we have an anonymous block where we have declared type items_va is varray 5 of VARCHAR 260, so this varray can hold a maximum of five elements. L_items_va is of type items_va initialized to an empty constructor. We declare cursor, cur_get_items, with select start from the items table, restricting the fetch to five elements with row num less than 6 condition. Inside the execution section, we have a cursor for loop where we fetch cur_get_items cursor into get items_var. Inside the loop, we extend l_items_va and then assign the last error index, the item name fetched from the cursor. This extending and adding will continue in the loop until there is no more to fetch. Then we trade over the l_items_va using the first and last method and fill in the elements fetched inside. Let's run it. (typing) As expected, the three items in the items table were fetched. Let us now see the possible exceptions we can encounter when working with varrays.

Exceptions

You will get the value error if you're trying to assign a value larger than the varray type can hold. So here since the varray can hold a string literal up to four characters long, if you're trying to assign treadmill to it, you will get numeric or value error. The value error can be caught using the predefined error exception. You will also receive the value error if it ran a sign, a non-numeric index counter. If you're trying to assign value to an uninitialized collection variable as in here, you will get ORA-06531 or reference to uninitialized collection error. If your varray is defined with a not null constraint, then you cannot assign it a null value. Trying to do so will raise PLS-00382 or expressions of wrong type error. If you have initialized the varray variable, but you're trying to assign a value without extending it, you will receive ORA-06533 or subscript beyond count error. We can also get a subscript beyond count error if you're trying to trim more elements than there are in the varray. So trying to trim four elements when there are only two elements in the varray will result in ORA-06533 or subscript beyond count error. Let us now see a demo to see these situations which can lead to exceptions.

Demo: Exceptions

In this demo we will see some of the common mistakes while calling varrays, which can lead to exceptions. Seeing the situations which can cause exceptions should help us code appropriately to avoid them. So here in this anonymous block, we have declared type items_va as a varray with a max capacity of two elements of type VARCHAR2 4. L_items_va is of type items_va inside the execution section we try and extend it by three elements. Let's run it. We get the error, ORA-06531, reference to uninitialized collection. Let's correct this. So we have initialized l_items_va with an empty constructor. Let's run it again. This time we get subscript outside limit error as we are trying to extend it by three elements when the varray can hold a maximum of two elements. So let's correct that. So we now just extend it by a single element and then try and assign the value treadmill at index 0. Let's run it again. (typing) We get subscript outside limit error as 0 is outside of the limit of index counter which starts with 1. We would have gotten a similar error if we had tried assigning a string literal as an index counter. Let's change index counter to 1 and run it again. (typing) This time we get numerical value error as the maximum limit of the string literal the varray can hold is 4 and we are trying to assign a literal treadmill, which is more than four characters long. Let's change this to bike. Let's run it again. (typing) This time all the conditions are place and it runs successfully. Finally, let us try and trim two elements from the varray when it contains just one element currently. Let's run it again. (typing) This time we get subscript beyond count exception, so these are some common mistakes which can happen when working with varrays and being aware of them can help us avoid them in our code. Next, let's take a look at how we can create varray columns in DWS tables and interact with them in our PL/SQL code.

Schema Level Varrays

A varray can also be defined on the schema level, which has a lot of advantages. Once defined, it is available throughout the system including PL/SQL, providing a consistent definition. It can be used to define a database column to hold a collection of data for each row. A customer row having a collection of account numbers in a varray column might be an example. It similarly makes getting all that information in a single select easy. We can create a schema-level varray and use it also as a column type of a database table. So here, create or replace items_va as varray 5 of VARCHAR 260 creates a schema-level varray. We can create a varray of a more complex data type like an object, for instance. Create type orders_ot as object with two attributes, order_id of type number and order_item_id of type number. Then create or replace type orders_va is varray 5 of orders_ot will create a varray, each element of which is an orders_ot object. We can use these varrays in database columns, for instance, the account orders table, which stores account id, account month, and a list of items ordered that month as an items list column of type items_va defaulted to an empty constructor, a list of orders for that month in the orders list column of type orders_va defaulted to an empty contructor, orders_va. Dropping the schema-level varray can be done by issuing drop type followed by type name with the option force or validate. So if you try and drop a varray using the command, drop type mytype_va which has dependents, you will get an error ORA-2303, cannot drop or replace a type with type or table dependents. This command will drop only the varrays which has no dependents. Using the force option allows you to drop a varray which has dependents. You can use the command alter type varray name modify element type, providing the new data type size with cascade or invalidate option. Cascade will push the changes to all the dependents. Invalidate will make all the dependent objects invalid. So let's say we create a varray items_va as varray 5 of VARCHAR 260. We can increase the length using the command alter type items_va modify element type VARCHAR 2 100 cascade to make it 100 characters. Reducing the length, however, is not allowed and trying to reduce it to 10 characters will error out.

DML Against Varrays in Database Tables

Oracle does not allow piecewise operations on varrays as it does for nested tables. You can only insert update to varray columns as a whole or as atomic units. Let us see how we can interact with the varrays stored in database tables in our PL/SQL code. So I have got the account orders table for our reference over here. In this code snippet, we show how we can insert a row in the varray column. We have declared l_items_va of type items_va and l_orders_va of type orders_va and initialized them with empty constructors. L_orders_ot is an object initialized with the orders_ot constructor and values 1 and 1. In the execution section, we extend the varray first by two elements, assign elements at indices 1 and 2. We extend the orders varray, l_orders_varray by 2 and assign at index 2 the l_orders_ot variable from the declaration section and at the second index, orders_ot with a value of 2 and 2. Now using the insert statement we put one for account id, January for account month, l_items_va for items list, and l_orders_va for orders_list and commit. We can run the same statement in SQL just as we used constructors to add values for the items list and orders list columns. Updating again is not very different. We again construct new items list variable as l_items_va and orders list variable as l_orders_va and with an update swap the old assignments with the new variables. The same thing goes for using the update statement in SQL directly where we swap the old varray column values with the new values. Deleting is pretty straightforward. You can, of course, remove the entire row or using update you can set the columns to null, essentially flushing out everything which was there in those columns before. You can use the same statement in SQL directly. You can select varray columns in PL/SQL variables and work with them. So here I have declared l_items_va of type items_va and initialized it. L_orders_va is of type orders_va and is also initialized. Using a cursor, get_details_cur, we select items list and orders list from account orders table for account id 1 and account month January. Inside the execution block we fetch it into l_items_va and l_orders_va. Then we can trade over them and print the inner elements and work with them as normal in our PL/SQL block. Selecting them using a select statement in SQL will give you a nested view of the varray. Similarly, selecting the orders list column will give us a nested view of the orders_va varray, showing the two objects orders_ot inside orders_va and again, like nested tables, you can unnest the columns of a varray using the TABLE Expression. For instance, here we are selecting the internal attributes order_id and order_item_id of the orders list using the TABLE Expression which takes in select orders list from account orders where account id is equal to 1 and account month equal to January. And we can also use the other form of the table operator where it takes in a nested table column and joins it with the parent table. So here since items_list varray is composed of just one element, we'll refer to it as column_value. So assuring b.column_value from account orders a TABLE Expression taking in items list with an alias of b, will join this table with the parent for account id 1 and account 1 January. You can use these selects inside of PL/SQL code also as regular selects or as a part of a cursor select. Let us now see a demo of how we can create varrays and DWS tables and interact with them.

Demo: DML Against Varray Columns & TABLE Expression

In this demo we will see how to create schema-level varray columns and interact with them in PL/SQL. Let's first create items_va varray as create or replace type, items_va as varray 5 of VARCHAR 260. So our items_va varray can hold a maximum of five elements. Next, let's create an object orders_ot as create type orders_ot as object consisting of two attributes, order_id of type number and order_item_id of type number. Next, we create a second varray as create or replace type orders_va as varray 5 of orders_ot. Let's next create a table, account_orders, which holds the order information for account ids. So it tells us that for a given account id and a given account month, what is the items list which was ordered by that account. The items list of type items_va varray initialized to the empty constructor and orders list is of type orders_va initialized with an empty orders reconstructor. Let's run these statements. (typing) Next is an anonymous block where we declare l_items_va of type items_va, l_orders_va of type orders_va and l_orders_ot of type orders_ot. We assign l_orders_ot an object using the constructor, taking in elements 1 and 1. In the exclusion section we extend l_items_va by two elements and assign values bike and treadmill. We extend l_orders_va next by two elements at index 1, we assign l_orders_ot and at the second we put orders_ot with elements 2 and 2. We insert into account orders values account id 1, account month January, items list, l_items_va, and orders list, l_orders_va. Then we commit. Let's run this block. (typing) Let's now select from the account orders table. (typing) We see that the values were inserted successfully. We see the two elements bike and treadmill in the items list column and the orders list column has the two orders with elements 1/1 and 2/2. Let us see how to update the row. We'll now put in l_items_va the value elliptical. So now it has just one element in it. In l_orders_va it has objects with elements 1/1 and 3/3. Now we update the account orders table and swap the values in items list column with l_items_va and the value of the orders list column with l_orders_va. Let's run it. Let's now select from the account orders table. (typing) We see the new value for the items list column and the orders list column has the new rows with values 1/1 and 3/3. So we were able to swap the old columns with the new values. Let's now delete from account orders table. (typing) Let's now select from the account orders table (typing). There is nothing in it as expected. Let's now insert in the account orders table using the SQL insert. We insert in the items list a value using the items_va constructor, adding in two elements, bike and treadmill, and similarly for the orders list we insert using the constructor orders_va, having two objects inside it with orders_ot having two elements, 1/1 and orders_ot having elements 2 and 2. Let's run this statement. Let's perform the commit. And now let's select from the account orders table again. (typing) So the row got inserted successfully and we're seeing the items list of the two items, bike and treadmill and the orders list, you see over two ordered rows with elements 1/1 and 2/2. Doing just a simple select star from account orders table we see the items list and orders list as nested table columns. Let's now see how we can use the TABLE Expression to unnest the individual elements from the varray columns. Let us select the inner elements from the orders list varray. Inside the TABLE Expression we select orders list from account orders table where account id is 1 and account month is January. Now we select the order id and order item id from the query column. Let's run the select to confirm. So we were able to unnest the individual elements from the orders list varray column and here is the other way of getting the inner elements from the items list varray. So we use the column_value keyword as the items list varray is comprised of a single element. So we say select d.column value from account orders a table, items list b where account id equal to 1, and account month equal to January. Oracle will join the nested varray with the parent row. Let's run it. And we were able to successfully unnest the individual element out of the items list varray column. We talked about a lot of useful concepts in this module; let's go and summarize them now.

Summary

In this module we took a look at working with varrays in PL/SQL. We saw how we can declare and initialize them. Varrays like nested tables need to be initialized before they can be used, where a declaration specifies the maximum number of elements it can hold. Varrays are particularly useful in situations where we know the maximum number of elements you expect to get and perhaps you want to use this structure to enforce the maximum limit. Varray columns retain the order of insertion of elements and so are useful in situations when order of internal elements is important. Since varrays are retrieved and inserted as a whole, we should use them only when you need sequential access and when the number of elements is relatively small. We saw how we can use the extend and trim methods to add and remove elements. Varrays do not allow sparse collections and so the only form of delete which works with it is the one which removes all the elements from the varray. We looked at the various exceptions we can encounter when working with varrays. If you try and extend it beyond the maximum number of elements it can hold, we will get subscript outside limit error and if you try and use the varray without initializing it, you will get error reference to uninitialized collection. We saw how we can declare the varrays at the schema level and create them as columns of a database table. We looked at how we can manipulate these from PL/SQL; however, we can only manipulate the varray as a whole and we cannot do piecewise operations against them as with nested tables. In the next module let us talk about how to create multilevel collection elements and how we can use the cast operator in conjunction with the multiset and collect operators to convert varrays.

Multilevel Collections & Converting Collections

Overview

Hello and welcome to Pluralsight. My name is Pankaj Jain and welcome to this module on Multilevel Collections and Converting Collections. In this module we will see how we can nest Collections within one another to create multilevel Collections. This might be useful in situations where you want to keep all the related information together. For instance, a collection of orders which has another collection inside it, which stores all the items requested with that order. We will see how we can use the CAST function to convert name collection types like nested tables to varrays and vice versa. We will also see how we can use the CAST function in conjunction with the MULTISET function to cast the results of a subquery into a name Collection type. We will also see how using the Collection function along with CAST we can convert scalar database column values into a Collection. So there's a lot of good stuff to talk about. Let's get started. Oracle allows us to create multilevel Collections. You can nest one Collection within another. You can go many levels deep though practically I do not see where you will need to go more than two or three levels deep. There are three collection types and you can nest one within another. So for instance, you can have a nested table and one of its elements can be another nested table. You can have a varray Collection nested within another varray or an associative array within another associative array. A varray Collection within a nested table and so on and so forth. So for instance, say we have a Collection of orders. Each order object has two elements inside it, the order id and the items for that order. The second element items is another Collection, a Collection of items. For instance, the first order object in the orders Collection consists of order id 1 and items bike and treadmill as a part of that order. The second order object has three items ordered against it. Let us understand this better by seeing how we can nest an associative array within another associative array.

Associative Array Within Associative Array

Let us first see how we can nest an associative array within another associative array. Let us first create type items_aa, which is an associative array of VARCHAR 260 indexed by binary integer. Let us create an order account now that consists of two elements. Order id of type number and the second element is the Collection of items which is the associative array, items_aa, which we declared earlier. Next, let us create an associative array, orders_aa, which is a tables of orders_rec index by binary integer. So now orders_aa is an associative array which has items_aa associative array nested within it. Let's now clear l_items_aa of type items_aa and l_orders_aa of type orders_aa. In the execution section we begin by assigning l_items_aa at index 1 a value of bike and at index 2, a value of treadmill. Now we assign to the associative array l_orders_aa at index 1 an order id of 1, and at that index to the items Collection we assign l_items_aa, which we have just assigned values to earlier. We again assign that index values 1 and 2 to the l_items_aa variable the values of weights and elliptical, which overrides the previous assignments. To l_orders_aa, at index counter 2, we assign an order id of 2 and the items Collection as l_items_aa. So now we have our order orders Collection, which has an inner items Collection which stores the items requested for each order. Let's now see how we can access and replace elements from the inner Collection. So say for instance we want to access the second element of the items Collection from the first order. We would first get to the first order element by using l_orders_aa with an index of 1. Now to get to get to the items array inside it and get to the second element, this should give you back treadmill. How do you replace it? It's pretty much the same where you start off accessing the first order element by using l_orders_aa with an index of 1 and then you follow it by the items array at index 2 and assign the new value of weights over there. This should replace the earlier assignment of treadmill with the weights. Now accessing it will give us a value of weights. Now let's see how we can add and delete elements from the inner Collection. Let us first add a third item to the items Collection of the second order. We first access the second order by using l_orders_aa, passing it an index of 2, and then add to the items Collection at index 3 the element swing. A count of the items for the second order will result in here at this point of time. Now let us delete the second item from the second order by using l_orders_aa, passing an index of 2.items .delete, passing it an index of 2, for the second element. Taking a count now will result in a value of 2. Let us now take a look at a demo to see this in action.

Demo: Associative Array Within Associative Array

In this demo we will show how to nest an associative array within another associative array and perform operations like accessing, adding and removing inner elements. So here, in our code snippet we have inner associative array, which is items_aa, which is a table of VARCHAR 260 indexed by binary integer. Next we define the record orders_rec, recording item id and number, and our associative array, items_aa, essentially storing the items ordered for each record. Next, we define our order associative array, which is of type orders_rec indexed by binary integer. So each record of this order array will have an inner items array. L_items_aa is of type items_aa and l_orders_aa is of type orders_aa. We start off by adding two items, bike and treadmill to l_items_aa at indices 1 and 2. We now access the first record of the l_orders_aa Collection by passing in the index counter of 1 and to that record we add the order id of 1 and the items for it order as l_items_aa. We again use our l_orders_aa variable and override the previous assignments at indices 1 and 2 with weights and elliptical. We add a second orders record to l_orders_aa with an order id of 2, and items as l_items_aa with the new values. How do we now access the inner Collection? Let us say we want to access the second item from the inner items Collection of the first order. The way to do it would be by first accessing the first orders record using l_orders_aa with an index of 1 and then from the nested items Collection in that record, the second element. The same syntax goes for replacing that item, just that now we assign a new value of weights to it. We confirm it by printing it. Let us now add a third item to the second order. L_orders_aa with an index of 2 gets us to the second order record. Items 3 will add the third item to which we assign a value of string. We confirm the addition by taking a count of items of the second order using l_orders_aa with an index of 2.items.count. Let us now remove the second item from the second order. We access the second order by l_orders_aa 2 and then the items array over there and then delete the second element. We confirm the deletion by printing the count again. Let's run this block. (typing) Initially the first orders second item element accessed gave us a value of treadmill. Then we replaced it with weights. We added a third element to the second order as the count confirms. Then we removed an element, making the count as 2. Let's now see how we can nest a nested table within an varray.

Nested Table Within VARRAY

Let us now take a look as to how we can nest a nested table within a varray. So here we declare items_nt as a nested table of type VARCHAR 260. We again declare the orders object containing the order id and the items Collection which is of type items_nt. We now declare orders_va which is a varray with the maximum number of five elements of type orders_ot, and is showing the first two records in the visual presentation on the left, but this varray can take a maximum of five records. L_items_nt is of type items_nt and l_orders_va is of type orders_va. Both of these are initialized using their empty constructors. We extend the items_nt by two elements, add bike at index 1, and treadmill at index 2. Now we extend order_va varray and add order id of 1 to the inner object at that index and assign l_items_nt to the inner nested table. In the l_items_nt variable, we replace the elements at indices 1 and 2, extend the varray and add order id 2 and assign l_items_nt to the items Collection. So this way you can keep extending and adding elements to the inner nested table. Accessing elements is similar to what we saw earlier with associative arrays, so to get to the second item element of the first order, we get to the first order by using l_orders_va, passing in an index of 1 and then get to the second item using the inner items nested table at index 2. Assigning weights to l_orders_va at index 1.items at index 2 will replace the previous assignment of treadmill at that spot. To add a third item element to the inner nested table of the second varray, we first extend the items element at l_orders_va2 and then add the element at index 3 over there. Taking a count of the items of the second order now will result in a value of 3. From the second order, l_orders_va2, if we delete the second item from the inner nested table using items.delete2, we will be left with a count of 2. Let us now take a look as to how we can nest a nested table within another nested table.

Nested Table Within Nested Table

Let us now to see how to nest a nested table within another nested table. The operations are no different is the Collection is declared at a schema level or at the PL/SQL level. So let us now see an example of creating a nested table within another nested table at a schema level. Create or replace type items_nt is table of VARCHAR 260 will declare a nested table items_nt at the schema level. Create or replace type orders_ot is object, order id number, items of type items_nt will create an object to hold the order id and the nested tables items_nt. We cannot declare a record at the schema level so we use an object instead. Create or replace type order_nt is table of orders_nt will create nested table orders_nt of type orders_ot. Now we know with PL/SQL code we can refer to these nested tables and work with them. So l_items_nt is of type items_nt and l_orders_nt is of type orders_nt. We again begin by extending items_nt by two elements, add the two elements over there. We then extend the outer nested table and assign to the orders_ot object at that location using a constructor with an order id of 1 and l_items_nt as inner nested items table. We similarly can extend the outer nested table l_orders_nt and add at index 2 an object, orders_ot with an order id of 2 and items_nt nested table using its constructor items_nt, taking in two elements. So we can construct and assign values to items_nt before and assign it or create it using a constructor and assign it directly. Accessing and replacing elements is very similar to the previous examples. L_orders_nt1.items2 will give us access to the first order and the second item inside the inner items nested table. Similarly, assigning weights to l_orders_nt1.items2 will replace the second item of the first order. You would add and delete elements as you would do normally to a nested table. Adding a third item element to the second order will involve first extending the items nested table at l_orders_nt2 and then adding the element swing at l_orders_nt2.items3. This will result in a count of 3 obtained by l_orders_nt2.items.count. L_orders_nt2.items.delete with an index of 2 will result in deleting from the second orders items table the second element resulting in a sparse inner nested table. Taking a count now will result in 2. If you want to use orders_nt now as a column of our database table monthly orders, you will first have to use nested table order info stored as orders store as you would do with a nested table column normally, but since it contains another nested table items inside it, you will have to have within parentheses nested table items stored as item store. So if there are more levels of nested table inside, you will have to keeping doing this within child parentheses. Now let's do an insert in this table using an insert statement. For the orders info column we insert using orders_nt nested table constructor, which will take in a Collection or orders_ot objects. Each orders_ot object is injected using its constructor, which takes in two elements with the order id and inner nested table items_nt. Using a constructor items_nt, we're passing the elements to it. Inside of our PL/SQL code we can work with this nested table as normal using our cursor. In the cursor we are selecting account id, order info from the monthly orders table for account month of January. We declare l_act_id of type monthly orders.account id% type and l_order info of type orders_nt. Now using the cursor we fetch order into l_order_info and then we can work with it normally. Let us now take a look at a demo to understand these concepts better.

Demo: Multilevel Collections

In this demo we will see how we can nest a nested table within another nested table at the schema level and work with them in our PL/SQL code. The operation would work similarly if these nested tables were declared in the PL/SQL level. So here, first we are declaring a nested table type by using create or replace type items_nt, this table of VARCHAR 260. Next we create an object orders_nt as create or replace type, orders_ot as object consisting of order id, a number, and items of type items_nt. Finally, we create the outer nested table orders_nt of type orders_nt. Let's create these objects. (typing) Now inside this PL/SQL code snippet we declare l_items_nt of type items_nt and l_orders_nt of type orders_nt. We initialize both of them with their empty constructors. We need to initialize them in order to work with them. We start off by extending l_items_nt by two elements. We add bike and treadmill at indices 1 and 2. We now extend l_orders_nt and add the first orders object using its constructor orders_ot, taking in an order id of 1 and l_items_nt for the items. We extend l_orders_nt again and at index 2 we add the second orders object, this time taking in an order id of 2 and items using its constructor, taking in two items, weights and elliptical. I wanted to show you various ways of adding elements. We now access the second items element of the first order by using l_orders_nt1.items with an index of 2. Assigning weights to l_orders_nt1.items2 will replace the first orders second element to weights. Let us add a third item to the second order. We access the second order by using l_orders_nt, passing it an index of 2. L_orders_nt2.items will give us access to the items Collection at that order. As with nested tables, we have to extend it to add another element and then we add to the newly added element 3 the value of swing. We print the count using l_orders_nt2.items.count, which would give us the value of 3 now. Let's remove the second item now. L_orders_nt2.items.delete2 will remove the second item on the second order. Printing its count should now give us a value of 2. Let's run this block to confirm. (typing) We could successfully access the first order's second item which is treadmill. We then replaced it with weights after adding a third item element for the second order the count is 3. Next, removing an item from the second order will result in the count of 2. In this demo we will see how to use the multilevel nested table type as a DWS table column and work with it in PL/SQL. Here is a monthly orders table where for a given account id and account month, we insert the order information in the order info multilevel nested type. Nested table order info stored as order store is the internal name for the nested table and since it has an _____ nested type items _____, we nest its internal storage name within parentheses as nested table items, store as item store. Let's create this table. (typing) Next we insert in this table using orders_nt constructor for the order info type, which is composed of the orders_ot type. Each order_ot type has the order id and the items ordered as a Collection, to which we assign values using the items_nt constructor. Let's insert this row. (typing) Now in this PL/SQL block, we have a cursor, order_info_cur, which selects account id and order info for monthly orders for account month January and account id is monthly orders.act_id%type. L_order_info is of type orders_nt and l_items_nt is of type items_nt. Inside the execution section, we open the cursor and fetch the order info in l_order_info variable. Then within a for loop, we trade over l_order_info obtaining the inner nested items Collection in l_items_nt. Then we have a nested loop where we trade over l_items_nt using the first and last Collection methods and print the item id inside. Let's run it. (typing) As expected, we see that our l_order_info nested type has an order id of 1, which further has a nested Collection of items bike and treadmill. Next, is our order 2 with the nested item weights. Next, let's look at the CAST function, which is used to convert a built-in COLLECTing type into another.

CAST and COLLECT Functions

The CAST function lets us convert a built-in data type or named Collection into another built-in datatype or named Collection. We will see how can we use to convert a varray into a nested table and vice versa, as well as how we can use it to convert an inner subquery into a named Collection type. Both the Collection types, the one converted from and the one converted to, should have the same internal components in both datatype and the number of components. The CAST function takes in an expression or a subquery and casts it into another built-in Collection. The expression can be a built-in datatype, a schema-level named Collection type like the nested table or a varray, or the ANYDATA type. The ANYDATA datatype is useful for storing generic attributes, the datatype of which you do not know at the runtime. Like you might store a number, VARCHAR2 or date in the same variable of type ANYDATA. Then using the get type name function against it will tell you what type of data is stored inside it. We will not discuss it here. Our discussion here will be focused on Collection types. The CAST function can also take in a query inside a MULTISET operator and convert the result as a named Collection type. When you want to use a scalar database column with the CAST function to create a named Collection, you need to use the COLLECT function instead. We will take a look at each of these. In order to understand the CAST function, let us create some types. As you saw before, create or replace type items_va as varray 5 of VARCHAR 260 will create a varray with a maximum length of 60 characters. Create or replace type items_nt as table of VARCHAR 260 will create a nested table of VARCHAR 260. We create an object, order_info_nt consisting of two elements. Order id of type number and the item name of type VARCHAR 260. Then we create order_info_nt as a nested table or order_info_nt. We create a table, items ordered which consists of account id, account month, and a varray column items list of type items_va with the default value of items_va with an empty constructor. Now with these Collection types and structures let us understand the CAST function. Let's keep our table in the reference over here. So one of the ways to use the CAST function is to convert a nested table type into a varray type or vice versa. So select CAST items list as items_nt from items ordered will convert the varray type of the items list column, items_va, to the nested table type, items_nt. Of course, you can use this in PL/SQL as a cursor select and then fetch the results in l_items_nt, which is of type items_nt. Converting the varray type into a nested table type for instance, allows us to use some of the operators applicable against the nested table like the set operator to eliminate duplicates. You could have fetched the varray column without casting it. So here we fetch items list varray column into l_items_va variable, which is of type items_va. Then we can use select CAST l_items_va as items_nt into l_items_nt from dual to cast the PL/SQL varray variable into a nested table type. The CAST function can also take in a query and using a MULTISET operator, convert it into a named Collection. So here it the order info for the object we had created earlier and order info nt nested table of type order_info_nt. Now we use select CAST and inside it, the MULTISET operator, which takes in a subquery. This subquery returns two columns, order id and item name, which are the two elements of the order_info_ot object. So select order id, item name from orders, items, where order item id equal to item id and order account id equal to 1 fetches the items ordered by account id 1. The result of this query is cast using the MULTISET operator into order info nt nested table, which is a Collection of order info ot object. Of course, we can use this query as a part of a cursor select in a function get order info, which takes in p account, which is account id and it returns a Collection of type order info nt. It uses the same query, but it uses the past account id in the query. We declare l_order_info_nt of type order info not. We fetch the cursor into order info nt and then return the Collection, which will be consumed by the client in working this function. If you want to use scalar columns we can use the COLLECT function in conjunction with the CAST function. So we had created items_nt nested table earlier of type VARCHAR 260, select CAST, COLLECT item name as items_nt from items will return back a Collection of type items_nt. Since we are using the scalar column item name of the items table, we use the COLLECT function along with CAST to cast it to the appropriate type. If we had used the MULTISET function instead, which uses a subquery, we could have read this query in as select CAST MULTISET select item name from items as items nt, from dual. Of course, this query would work in PL/SQL and you can use it in a cursor to fetch into a variable l_items_nt of type items_nt. Next, let's take a look at a demo to understand this function better.

Demo: CAST and COLLECT Functions

Let us now see the CAST function in action to convert a built-in Collection type to another, as well as its usage with the MULTISET and the COLLECT operators to convert query fetches into Collection types. So first, let us create the types we will need for our demonstrations. We create items_va as varray 5 of VARCHAR 260. Items_nt is a nested table of VARCHAR 260. We create an object order_info_ot comprising of two elements. Order id of type number and item name, which is of type VARCHAR 260. Then we create a nested table order_info_nt as table of order_info_ot. Let's create these types. (typing) Next, we create our table items ordered, which contains the items list column of type items_va with a default value of items_va, so the items_list column is a varray type. Next, we insert a couple of rows in this table. The first row has the varray column with bike and treadmill, and the second one has elements weights, elliptical, and bike. Let's create the table and insert the rows. (typing) Now let us use the CAST operator to convert the varray column into a nested table type. So select CAST items list as items_nt from items ordered will convert the items list varray to items_nt nested table type. Let's run this select. (typing) The CAST operator indeed converted the varray column into the items_nt nested table type. What if you want to convert the result of a query into a Collection type? Select CAST MULTISET operator which takes in the query select order id, item name from orders items where order item id is equal to item id and order account id equal to 1. As order info nt will cast the result of this query in the order info nt nested table type we had created earlier. Let's run this. (typing) So the result of the query was converted into the order info nt nested table type. Internally this composed of the order info ot object, which gets the order id item name selected as its elements, so here in this anonymous block we have the same query as part of a cursor select. L_order_info_nt is type order_info_nt. Inside the exclusion section, we open the cursor, get the result of the CAST and MULTISET operator in the nested table l_order_info_nt. Now we can loop through it using the first and last Collection methods and obtain the order id and item name from it as we would do with a normal nested table type. Let's run this block. (typing) We see the order id and item name which were stored in our nested table l_order_info_nt, which was created as a result of the CAST and the MULTISET operators. Finally, let us see how we can convert a scalar column into a Collection type using the CAST and COLLECT functions together. So select cast COLLECT item name as items nt from items will fetch the items name from the items table and cast them as items of the items nt nested table. Let's run it. (typing) So in this demo, we saw the usage of the CAST, MULTISET and COLLECT functions to convert a Collection type or a query into another Collection type. We have reached to the end of this module. Let's summarize what we talked about.

Summary

In this module we saw how we can nest one collection within another. For instance, an associative array within another associative array or a nested table within a varray. Though you can have many levels of nesting, there is generally no good need to go beyond one or two levels of nesting. We saw how we can access, add, and remove elements from the nested collections. You saw the use of the CAST function, which can be used to convert a built-in collection type into another built-in collection type. For instance, a nested table into a varray and vice versa. We can use the MULTISET function in conjunction with the CAST function to convert a result from a subquery into a collection type. However, with scalar columns we use the collect function to convert it into a collection type. Let us now take a look at the bulk features of Oracle in the next two modules. The bulk features are perhaps the most important performance optimization technique in PL/SQL, which every PL/SQL developer should know and be proficient with. In the next module we will start off by talking about the bulk collect feature, which is used to fetch information from the database server in bulk.

Bulk Operations: Bulk Collect

Overview

Hello and welcome to Pluralsight. My name is Pankaj Jain and welcome to this module on Bulk Operations where we'll talk about Bulk Collect. In this module we will talk about bulk operations, one of the most powerful optimization techniques in PL/SQL. We will talk about bulk collect in this module, which is a way to fetch data in bulk from the Oracle server. We will cover the other bulk operation, the for all statement in the next module, which is a way to do bulk DML. We will start off with trying to understand how PL/SQL blocks are processed to better understand the need for bulk operations and the benefits they offer. We will then see how to use bulk collect in our PL/SQL code. We will talk about the limit clause, which is a way to control session memory usage with the bulk collect operation. Finally we will do a performance comparison between a normal cursor fetch and using bulk collect. We will see how using the bulk collect significantly reduces the time it takes to do the fetch operations. This is a very important topic and will greatly enhance the value of your PL/SQL code, so let's get started. As I have mentioned before, we have two kinds of bulk operations. The bulk collect is when we are trying to optimize our fetches from the database server. Forall is a converse operation where we are trying to optimize _____, our DML statements to the database. Let us now take a look at how a PL/SQL block is processed and in that context see the benefits of using bulk operations.

Context Switches

Let us understand the use of bulk operations by first taking a look at how a PL/SQL block is processed and how context switches happen. A PL/SQL block can consist of SQL statements, which are executed against the database server as well as procedural code like loops, if statements, local operations, etc. The procedural code is sent over to the PL/SQL engine. When it encounters the SQL statement, it stops and sends it over to the SQL engine. The SQL engine executes the statement and then sends the results over to the PL/SQL engine. This transfer of control within the PL/SQL and the SQL engine is the context switch. The context switches are performance overheads, which make our code slow. Imagine the loop where we are inserting hundreds of rows. For each insert statement, the PL/SQL engine will send over the statement to the SQL engine. This will result in hundreds of context switches and _____ round trips resulting in drastic performance hit. Would it not be efficient if the PL/SQL engine can _____ the transactions and send them in batches to the database. That will significantly reduce the context switches and the overhead. That is what exactly the forall feature does. Conversely, if you are fetching hundreds of rows from the database, would it not be efficient that the SQL engine gets all the rows, puts them in a collection structure, and passes it back to the PL/SQL engine in one go. This is what the bulk collect feature does. So by now, the benefits of the bulk operations would be obvious to you. They would provide a significant boost to your PL/SQL code and they will definitely reduce the number of network roundtrips your code will need to do to get the results back. This is truly one of the most powerful ways to enhance your PL/SQL code's performance. Let's talk about bulk collect in detail now.

Bulk Collect

Let us talk about bulk collect. With bulk collect in your code, we would use the bulk collect keyword into, followed by the collection name you want the results to be fetched into. So where you can use the bulk collect clause? You can use them in direct selects in your PL/SQL code, or with the cursor fetch clause. You can the bulk collect clause in the returning into clause of the insert update or delete statements. For instance, say you update the salaries of all the employees in department id 10 and then as a part of the returning into clause you can get all the employee id's in a collection using bulk collect. They can also appear in the Dynamic SQL statements. We will see examples of using all of these statement types. Bulk collect can be used to fetch in all the three collection types, many associative arrays, nested tables, and varrays. The fetch would result in a dense collection with consequent numbers indices starting with 1 and with no gaps. Also, when fetching into nested tables and varrays we need not worry about initializing and extending them. Oracle will do that automatically for you. And if the fetch does not result in anything, it will wipe away anything previously stored in the collection variable. One thing to be cognizant of while working with bulk collect feature is the memory utilization by the session. As you can imagine, if you are trying to fetch thousands of rows from the database using bulk collect clause, it is going to need a lot of memory to store it in a collection variable and pass it to the session. Further, the memory comes out of the PGA or programmed global area of each session. It does not come out of SGA which is shared memory across sessions. So if many sessions are simultaneously running the code it can severely affect the memory availability. For that reason, instead of bringing in all the rows at once, we should try and batch it up in a reasonable number. That number would depend on how much memory is available to your session, but I generally like to use batches of 100, stating with Oracle 10G if you set the PL/SQL optimize level initialization parameter of the database to a value of 2, Oracle will automatically rewrite your cursor loops to do a bulk collect, 100 rows at a time. This is useful for enhancing the performance of your existing code without any rewrite on your part. However, you will still need to manually convert it to a bulk collect if the for loop also contains DML statements, as Oracle does not automatically optimize them using forall. You should use the bulk operations for any new code you write. Let us now take a look as to how to use the bulk collect clause in our PL/SQL code.

Bulk Collect with Direct Select

You can use the bulk collect clause directly in your select into clause. For instance, in this code snippet, we have declared a nested table type itemid_nt is table of PLS integer. We then declare l_itemid_nt of type itemid_nt. Inside of our execution section, we do select item id, bulk collect into l_itemid_nt from items. Notice the use of bulk collect to fetch all the items at once in the l_itemid_nt collection. As you know, if you're using a direct select in your PL/SQL code, and if it does not fetch anything, it'll raise a noted upon exception, but our select statement using the bulk collect clause would not raise an exception if it didn't fetch anything, something to be aware of. For instance, in this code snippet if you put in a where condition, which will result in no row being fetched, that would not raise any errors. Doing a count against l_itemid_nt will result in a value of 0. You can select multiple columns in your bulk collect. Each column can go in its own collection type variable and these collection variables do not necessarily need to be the same collection type. For instance, here we have declared l_itemid_nt as nested table variable of type itemid_nt, but type item name is table of VARCHAR 260 index by binary integer, and it creates an associative array to hold the fetched item name. L_item_name_aa is of type item_name_aa. Now in our select we get item_id and item_name bulk collect into l_itemid_nt and l_item_name_aa collections respectively. Or if you so desire, you can create a selection of a composite datatype like a record and fetch all the individual elements into it. For instance, here we have declared item info as a record consisting of item id and number and item name of type items.itemname% type. Next, we declare a nested table type item_info_nt as table of item info. We declare l_item_info_nt of type item_info_nt. Now in our select we can get itemid_item_name bulk collect into l_item_info_nt from items to get both the selected columns as part of the record elements. As I have mentioned earlier, the larger the fetch, the more PGA memory our session will consume, which might have an impact on the overall performance of the system and may slow other processes down. We should try and limit the number of rows you fetch at a time. With direct fetch using select into clause, you could potentially limit the number of rows fetched using the rownum clause. For instance, rownum less than 101 to get the first 100 rows only. Or you could use the sample clause to get a sample, say 60% of the rows. This approach is useful for selects when you do not want all the rows of a table, but just a sample or a small number of rows. However, if you want all the rows of a table or a large subset of the rows, or if your query fetches a lot of rows, it might better to use a cursor fetch and use the limit clause to limit the number of rows and the memory usage of a session. We will talk about the limit clause shortly, but let's first quickly do a demo to see the usage of the bulk collect with the select into clause.

Demo: Bulk Collect with Direct Select

In this demo we will see how to use bulk collect with the select into clause. Let's first do a count against the items table. There are currently 10,000 rows in there. Let us see how we can fetch them in bulk in one go versus making multiple roundtrips. Next is our anonymous block where we have declared a nested table type itemid_nt as table of PLS integer. L_itemid_nt is of type itemid_nt, type item_name_aa is an associative array and is a table of VARCHAR 260 index by binary integer. L_item_name_aa is of type item_name_aa. We start the execution section with a select into clause, selecting item id and item name bulk collect into l_itemid_nt, l_item_name_aa from items. So we can fetch individual elements into individual collection types and these collection types don't have to be the same. We print the count of these individual collections. Let's run this block. It executed successfully and we got back the 10,000 rows, each column of the row in its own collection type and all this happens without needing multiple roundtrip to the database server. Let us now modify the query, putting in a condition of item value equal to -1. This condition would result in no rows being fetched. If it would have been a normal select it would have raised a no data found exception, but with bulk collect it will complete with no exception and the count will be zero. Let's run this. (typing) No exception was raised and we get a count of 0. Let us now see the use of the bulk collect clause with the cursor fetch as well as the use of the limit clause to limit the memory usage within a session.

Bulk Collect with Cursor Fetch

Here is an example of doing a bulk collect using a cursor fetch. In this anonymous block we have declared a nested table type items_nt of type PLS integer. L_itemid_nt is of type itemid_nt. The cursor get_item_info_cur selects item_id from items where item value is greater than 500. In the execution section, we open the get_item_info_cur. Then we fetch get_item_info_cur bulk collect into l_itemid_nt. Using bulk collect, we get all the rows in one go using this single fetch. Notice that we do not have to use a loop _____ over the cursor. This is how bulk collect helps avoid multiple roundtrips to get the rows. Let us say our items table is very large and contains thousands of rows. Getting all the items in one go may be too memory intensive and may negatively influence other processes. A good approach is to use a limit clause to limit the number of rows you want to fetch in one round trip. I generally like to use 100 as a good number for the limit. So here is the same cursor where we are fetching the item info in the nested table. However, here after opening the cursor we open the loop. Inside the loop we fetch get_item_info_cur bulk collect into l_itemid_nt with a limit of 100. Then we print the count of items fetched and do whatever other processing we have to do. We the exit from the cursor using the condition exit when l_itemid_nt.count = 0. We then end the loop, after the loop we close the cursor. Generally I like to pass a limit as an input parameter to a program unit or as a packet specification variable instead of hard coding it inside the code. That gives us some flexibility and ease of changing. Secondly it is important to note the exit condition. We have used the exit condition of exit when l_itemid_nt.count = 0. We have not used our standard exit condition of exit when get_item_info_cur percent is not found. That exit condition over here would have resulted in incomplete processing of rows. Let us see how. So we'll just say we are fetching 212 rows. So if we had used the exit when get_item_info_cur percent is not found, then the first fetch would have gotten us back 100 rows and cursor percent is not found would have been false. Next fetch gets 100 rows and the cursor attribute is false again. Third fetch gets the remaining 12 rows, but now the cursor percent is not found would have resulted in true, causing us to exit the loop without processing the last 12 rows through our loop logic. Using the exit condition when l_itemid_nt.count = 0 would have resulted in 100 rows fetched with the first two calls and the condition of l_itemid_nt.count = 0 to false. The condition would have been false for the third fetch also with results into our rows, and finally, the fourth fetch does not get us back anything and the condition is not true, exiting the loop. So for a bulk collect and limit loops, don't rely on the cursor found or not found attributes for exiting the loop and use the count instead. Let us now take a look at a demo to see the use of bulk collect with cursor fetch in action. We will also demonstrate the performance gains using bulk collect.

Demo: Bulk Collect with Cursor Fetch & Performance Comparison

In this demo we will see bulk collect with cursor fetch using the limit clause. We will also tie in the execution with bulk fetch versus normal cursor fetch to illustrate the performance gains. Let's first do a count against the items table. (typing) The items table has 100,000 rows in it. Now here is a our PL/SQL block where we have declared type itemid_aa as an associative array of number indexed by PLS integer. L-itemid_aa is of type itemid_aa. We declare a cursor get_item_info_cur as select item id from items. We declare l_start_time and l_end_time as numbers to capture the start and end times. Inside the execution block, we first get the start time and l_start_time by using the _____ utility.gettime function, which returns the current time in 100th of a second. If you open up our cursor and in the loop, do a fetch bulk collect into l_itemid_aa with a limit of 100 rows at a time. We exit when the fetch returns nothing or when l_itemid_aa.count = 0. We end the loop and close the cursor. We get the end time using DBMS utlity.gettime function again. We print the time elapsed in seconds by subtracting l_end_time from l_start_time and dividing it by 100. Let's run this block. (typing) The block executes successfully and we fetched the 100,000 rows and it took 0.4 seconds using the bulk collect. Let us see the performance using a normal cursor fetch where for each row fetched we make an end for roundtrip. Here I have replaced the bulk collect fetch with a normal fetch, fetching item id into l_itemid_aa with the index counter of l_itemid_aa.count + 1. I have again timed the execution with the begin time and the end time and we are printing the elapsed time at the end of the cursor fetch. Let's now run this block with a normal fetch. (typing) This time to fetch the 100,000 rows with a normal fetch took us 0.96 seconds. This is almost 24 times more to fetch with a normal fetch than to fetch with the bulk collect. This is a significant difference and goes to show how bulk collect enhances your code's performance. Let us now see how it can be used with a returning into clause and used for the Dynamic SQL statements.

Bulk Collect with Dynamic SQL and Returning into Statements

We can also use bulk collect with a returning into clause with we used with the DML statements. So for instance, here again we have our nested table type itemid_nt as table of PLS integer. L_itemid_nt is of type itemid_nt. We update the items table, increasing the value of items by 10%. So setting item value to be equal to item value multiplied by 1.10, returning item id's, bulk collect into l_itemid_nt. So the collection variable l_itemid_nt will have all the affected item id's returned back in one roundtrip. We can also use bulk collect with Dynamic SQL statements. If we want to learn more about Dynamic SQL statements, please refer to my course Oracle PL/SQL Transactions Dynamic SQL and Debugging on Pluralsight. Say we have a schema-level nested table type items_nt which is a table of VARCHAR 260. Here is a function, get_itemid, which states in the user-defined where condition parameter, beware of type VARCHAR2. It returns the items_nt collection, which is the list of item names meeting the condition. Inside we declare l_items_nt of type items_nt. Using execute and mediate we construct and execute this statement, select item name from items, concatenate the past where condition beware, and bulk collect the result into l_items_nt. We print the count and then return l_items_nt. We can then execute this function using the block shown below, passing in our condition where item values greater than 500 and fetch the return the collection into l_items_nt. Let us now see a demo to see the returning into clause and the Dynamic SQL in action with bulk collect.

Demo: Bulk Collect with Dynamic SQL and Returning into Statements

In this demo we will see the use of bulk collect with the returning into clause and Dynamic SQL statements. So here in this PL/SQL block we have declared type itemid_nt as a table of PLS integer. L_itemid_nt is of type itemid_nt. In the execution section we issue an update statement against the items table, updating the item value, item value times 1.10 from the items table where item value is greater than 400 and using returning item id bulk collect into l_itemid_nt, we fetch the affected item id's back. Using _____ output we print the rows fetched. Let's run this. (typing) We get the affected 100,000 item id's into l_itemid_nt collection using bulk collect with the returning into clause. Here we will see how to use bulk collect for Dynamic SQL. Let's first describe items_nt which is a nested table type of VARCHAR 260. Here is a function get item id's, which takes in a user-defined where condition beware and returns items_nt nested table. Inside the execution section, we build a SQL and execute it using Dynamic SQL as execute and mediate select item name from items concatenate with beware bulk collect into l_items_nt. We then print the count and return items_nt. Let's compile this. Next is the block where we execute this function. We pass in our beware condition of where l_item value is greater than 400 and get the results back into l_items_nt nested table variable. Let's run this. (typing) The bulk collect with execute and mediate returns the selected item id's into l_itemid_nt. We have now come to the end of this module. Let's now summarize what we talked about.

Summary

In this module we looked at bulk operations in Oracle. PL/SQL block processing involves contact switches from PL/SQL engine to SQL engine when a SQL is executed from within a PL/SQL block. This context switch is a big overhead for performance. Further, fetching or updating multiple rows involves an equal number of network roundtrips to get the data. Bulk collect and forall are the bulk operations available within Oracle which fetch or perform DML in just one roundtrip, saving a lot of network roundtrips and improving performance significantly. In this module we specifically talked about bulk collect, which is used to get data in bulk from the database server. We saw how to fetch data in bulk using direct select statement or using a cursor fetch. We also saw how to do a bulk fetch using returning into clause used with DML statements as well as how to use it with Dyamic SQL. Fetching data in bulk in collection variables is a memory intensive operation. The memory usage is by session PGA and it is important to limit the fetch using the limit clause. Generally, 100 is a good number to use for the limit clause. In the next module we will take a look at the other bulk operation, forall clause, which is used to perform DML statements in bulk. The bulk collect clause definitely gives us a performance gain as we saw in the demo, but that gain is even more significant when we use the forall statement. Let's take a look at that next.

Bulk Operations: FORALL

Overview

Hello and welcome to Pluralsight. My name is Pankaj Jain and welcome to this module on the forall class, which is another construct for the bulk operations in Oracle PL/SQL. We saw in the last module the bulk collect statement, which is used to perform a fetch from the database in bulk. Forall is the other part of the bulk operations in Oracle, using which we perform bulk writes to the database. Using forall we can batch up inserts, updates and delete operations and send them in one network roundtrip to the database. This mechanism again provides tremendous performance gains. In this module we will take a look at how to define and use the forall clause in our PL/SQL code. The forall clause works with collections in order to send writes in bulk to the database. If the collections are sparse we have to use the indices of clause in order to process the records in the collection. You can also use the values of clause with forall, if you want to process the records in the collection with a specific order or process them more than once. We will talk about these in detail with examples. The forall statement executes a bunch of updates, deletes and insert statements in one call and if you want to know how many rows were affected by each of those DML statements, SQL%BULK_ROWCOUNT is useful to obtain that information. If you want that during the bulk operations, let us say while doing bulk inserts, even if one of the insert statements fails, we want to save that information and continue on with the rest of the inserts. The SQL%BULK_EXCEPTIONS collection can later provide us the information of which rows failed. Lastly, we will do a demo to see the performance boost we're can get by using the forall statement versus doing a DML using a regular for loop. So there's a lot of exciting stuff to talk about so let's get started.

Usage

The syntax of the forall statement is forall followed by the index counter, the in keyword, followed by the bounds clause. The bounds clause specifies the upper and lower index counters in the collection, which is used with the forall clause. There are several ways you can provide the bounds information, we will take a look at that. We can specify the optional save exceptions clause to save the exception information, if any statement fails, in order to continue processing the other statements in the bulk operation. This is followed by the DML statement we want to bulk up. As we spoke about earlier, the forall clause can be used with insert, update and delete statements. It can also be used with both static and Dynamic SQL statements. We can use associative arrays, nested tables, and varrays with the forall statement. Let us see a quick example to understand the forall statement and its usage. So in this code snippet we have declared type itemid_nt is table of PLS integer. L_itemid_nt is of type itemid_nt and using the constructor we have provided three elements to it at index 1 is 4 index 2 is 6, and index 3 is 8; 4, 6, and 8 are the item id's we want to delete. We can do it in bulk in a single network roundtrip using the forall statement. Forall I in l_itemid_nt.first to l_itemid_nt.last will take all the index values in the collection from the first value 1 to the last value 3 and execute the delete statement. Delete from items where item id in l_itemid_nt is a subscript of I. So this will send all the delete statements in one batch to the database. If you notice, there is no loop or end loop clause over here. We print the rows deleted using the SQL% rowcount statement, which should report to us the total number of rows deleted with all the statements. In this case it is three. Let us talk about some things we need to be aware of while working with the forall clause. The forall iterator is declared implicitly as an integer. So in this code snippet the iterator I is implicitly defined as an integer and will override the visibility of any other variable of the same name if declared earlier and you cannot refer to a variable with the same name as the iterator, in this case I, inside the DML statement, and the iterator I cannot be assigned a value or be part of the expression. The DML statement used with the forall statement has to refer to at least one collection so in this example it is referring to l_itemid_nt collection. Secondly, the iterator has to be used as the index value in the collection so we have iterator I, which is passed on to the collection variable l_itemid_nt. We can only have one DML statement per forall statement. So if you have a second DML statement as in here where after the delete statement which is associated to the forall statement, we have an update statement, it will error out. If you want to use the bulk operation with the other DML statement also, we need to have another forall statement for the second one as shown in this code snippet. Let us now take a quick look at a demo to understand the usage of the forall statement.

Demo: Usage of FORALL Clause

In this demo we will see how to use the forall statement to perform updates in bulk. Let's first select from the items table. So currently both item id 1 and 2 have a value of 100. Next is the anonymous block where we have declared item_rec as a record consisting of two items, item if of type number and int factor, which is also a number. Next we declare items_aa as an associative array of item_rec indexed by a binary integer. L_items_aa is of type items_aa. Inside the execution section we fill in the associative array with two records. At index 1 the item id is 1 and the int factor is 1.10. At index 2 the item id is 2 and the int factor is 1.15. Now we issue a forall as forall I in l_items_aa.first to l_items_aa.last to issue a bulk update to the items table, setting the item value to item value multiplied by the int factor stored in the associative array at that index where item id is the item id stored in the associative array at that index. So here we are referring to the associative array collection variable both inside the set and the where clause of the update statement using the index counter I. The forall statement will perform the update for all the rows of the associative array in one go. The SQL percentage row count would report the rows updated and we should get back a value of 2. Let's run this to confirm. (typing) As expected, the two rows were updated using the forall statement in one go. Now let's select again from the items table. (typing) And as we can see, both the item values got incremented appropriately. Let us now take a look at some more considerations when working with the forall statement.

FORALL Considerations

If you provide the bounds for a forall statement in terms of the low value, high value, for instance, as in this code snippet, l_itemid_nt.first and l_itemid_nt.last, then the l_itemid.nt collection needs to be densely filled. If not, we will get an error. In case it is passed we can use the indices of or values of clause as we will see later. We can have a collection of records and refer to the integer record fields in the collection inside your DML statement. For instance, in this code snippet we have item_rec which is a record consisting of two elements, item id of type number and int factor of type number again. We declare items_aa as a table of item_rec indexed by binary integer. We fill the l_items_aa table with two record elements, the first one having an item id of 22 and int factor of 1.10 and the second one with an item id of 26 and an int factor of 1.15. Now using the forall statement we go from the first to the last element of the collection and issue update items, setting item value to item value multiplied by l_items_aa_i.int_factor where item id in l_item_aa_i. itemid. So we can refer to the integer required fields inside of our DML statement. Further, we can refer to the same collection in the set and the where clause of the update statement as of here. This was not allowed until Oracle version 11G. If you don't want to, you need not go through all the elements of our collection, but can just access a part of it. So as in this code snippet where we are just accessing elements between indices 3 and 5. If our composite collection type like a collection of records contains all the items on the table, then we can insert it using a single record collection type in the values clause. So for instance, here we have declared items_aa as a table of items percentage row type indexed by binary integer. So each row of this associative array contains all the columns of the items table. L_items_aa is of type items_aa. We fill up the collection at indices 1 and 2 for the various columns of the items table. Now our forall statement can insert into the items table using values l_items_aa with an index of I. The only thing to note here is that a composite collection type should have all the columns of the table in the right order. In our case, since items_aa is a table of items percentage row type, it has all the columns of the items table in the right order. So far, we have been looking at collections which are dense. What happens if our collection is not dense, but has gaps? Let's look at that next.

VALUES OF and INDICES OF Clause

Let us now talk about our options to handle sparse collections with the forall statement. In this code snippet we have declared itemid_aa is table of number index by PLS integer. L_itemid_aa is of type itemid_aa. We are assigning values to it at indices 1, 3, and 7. So with these gaps in the next values, if we run the forall statement with the first and last bounds, we will get an error, ORA-22160 element at index 2 does not exist. So in this case, we can use the indices of clause. So here we say forall I in indices of l_itemid_aa, which will send in the existing index values 1, 3, and 7 to the forall statement and will not raise any errors. The values of clause is another type of clause you can use with the forall statement. This clause is useful if you want to iterate over specific elements of a collection and not all of them. See just elements 1, 3, and 5, or if you want to iterate over them in a specific order, say in the reverse order, or if you want to iterate over an element more than once. What we do then is we create another reference collection and the values assigned to that collection are the elements we want to iterate over in the order we need. Let us take a look at an example. So here we have the itemid_aa as an associative array of PLS integer indexed by PLS integer. We declare l_itemid_aa and l_second_aa of type itemid_aa. We assign values to l_itemid_aa at indices 1, 2, 3, and 4, but say we want to process the value at index 3 first. We then want to repeat processing of index 3. Next we want to process the value at index 2 and then next at value 1, so we assign these as values to the second collection l_second_aa. Now our forall statement will be forall I and values of l_second_aa. So the forall will go to l_second_aa greatest values which are 3, 3, 2, and 1, and pass them as indices to l_itemid_aa for processing inside the forall statement in that order. You can use the forall and the bulk collect statements together. So here, using the forall statement we delete all the orders in the l_order_id_nt nested table in one go and then _____ the item id's associated with those orders back in l_itemid_nt nested table using bulk collect. So returning item id bulk collect into l_itemid_nt returns the item id's deleted and bulk collects them into l_itemid_nt. Let us now take a look at a demo to understand the indices of and the values of clause.

Demo: VALUES OF and INDICES OF Clause

In this demo we will take a look at the indices of clause, which is used for the forall statement with a sparse collection. We will also take a look at the values of clause, which is used to control the iteration and enable repetition of an index counter in the forall statement. Let us first select from the items table for item id 5, 6, 7, and 8. As we can see, all of them have an item value of 100. Next is an anonymous block where we have declared type itemid_aa is table of PLS integer indexed by PLS integer. L_itemid_aa is of type itemid_aa. We start off by filling the l_itemid_aa variable sparsely with the item id's. So we have item id's at indices 1, 5, 7, and 9, so obviously a lot of gap over here. Now we use the forall clause with the indices of keyword to iterate over the sparse l_itemid_aa collection. We update the items, setting the item value to be the item value multiplied by 1.10 where item id is l_itemid_aa, taking in the index counter returned using the indices of clause. If we had not used the indices of clause, we would have received an error. We check the count using SQL% rowcount. Let's run this block. (typing) As expected, we were able to process a sparse collection and update all the four rows. Let's select again from the items table for item id's 5, 6, 7, and 8. The item value for all these items got updated successfully. Next, let us take a look at the values of clause, but before that, let's first select from the items table for item id's 1, 2, and 3. (typing) All of them have an item value of 100 dollars. Next is an anonymous block where we have filled the l_itemid_aa variable at indices 1, 2, and 3. L_second_aa associative array variable is filled at indices 1, 2, 3, and 4 with values 3, 3, 2, and 1. So what we are trying to do here is to run the forall statement twice for the item id at index 3 of the associative array l_itemid_aa. Next we want to run the update for the item id stored at index 2, followed by item id at index 1. So item id 3 will be processed twice and then we want to reverse the order for item id's 2 and 1, forall I and values of l_second_aa will obtain the values of l_second_aa and use them as indices for l_itemid_aa for the update. We again print the rows updated. Let's run this block. (typing) Indeed, all the four rows are processed. Now let's take a look at the items table where item id is in 1, 2, and 3. (typing) Item id 3 was indeed processed twice as we see its value was upgraded to 121. Item id 2 and 1 were just processed once. So this is how we can use the values of clause if you want to control the order of iteration or if you want to repeat the processing for a specific index value. Next, let's take a look at the SQL% bulk rowcount function, which allows us to see the number of rows affected for each index value in the forall statement.

SQL%BULK_ROWCOUNT

SQL%bulk_rowcount stores the rows affected by each iteration on the DML statement inside the forall clause. We batch up the DML statements with the forall clause, but if you want to know how many rows were affected by each individual DML statement in that batch, SQL%bulk_rowcount gives us that information. For instance, here in this code snippet we have declared itemid_aa as table of PLS integer indexed by PLS integer. L_itemid_aa is of type itemid_aa. We assign values at indices 1, 2, and 3 to l_itemid_aa. Now in the forall clause where we go from the first index to the last, we delete from orders where order_item_id is the item id stored in the associative array l_itemid_aa at that index. So based on how many orders are there for each item id, each individual delete may affect a different number of rows. We use a for loop to get that information from SQL%bulk_rowcount. The forall and SQL%bulk_rowcount use the same subscript. So since the forall uses I in l_itemid_aa.first to l_itemid_aa.last as iterator over the DML, the SQL%bulk_rowcount would also use the same iterator as it stores the affected row information at the same index counter as the index counter where it was iterated over in the original forall loop. In this case, we used a normal loop with a loop and end loop clauses to get the information from SQL%bulk_rowcount. So if you use a limited subset in the forall clause, like here, I in 1 to 2, you would use the same subscript in the loop for SQL%bulk_rowcount. With the indices of clause the forall iterator is the index counter of the array. So in this case, 1, 4, and 5. To get the rows affected by these indexes, we will have to iterate with the same index values and provide them as input to SQL%bulk_rowcount. Since our associative array l_itemid_aa is sparse, it will use the while loop to iterate over it. We get the first index counter or 1 and while it is not null, we enter the loop. There we provide that index counter to the SQL%bulk_rowcount function to find the number of rows affected for that index and we can pass that index to the items array to print the item id also. Then using the next method we get the next index, which is 4, and repeat the same logic. Finally, we get 5. So we trade over the SQL%bulk_rowcount with 1, 4, and 5, the same way as the original forall loop using the indices of clause. With the values of clause the iterator is the value of the reference array, in our case l_second_aa. So the forall will use 2 and 4 as iterators and SQL%bulk_rowcount will store the number of rows affected with 2 and 4. So now the question is, how should we programmatically loop through the SQL%bulk_rowcount and find the rows affected for each item id of the original array? To do this we now iterate over l_second_aa using the while loop. We get the l_index for the first element. This will give us 1. Now inside the loop we get the value of the second array by passing in the index to it and store it in l_value. This l_value for the first index will be 2. We now pass this value to SQL%bulk_rowcount to get the rows affected for this value. We can get the original item id by passing this value as the index to l_itemid_aa. This should give us back item id 21. The next function against the second array will now give us the next index counter of 3. We cycle through the loop again and at the top we get the l_value by passing it in the second array which is 4. The item id for this value is 23. Let us now talk about some of the exceptions we can encounter while working with the forall class.

SQL%BULK_EXCEPTIONS

Let us now talk about exceptions which might occur with forall statements and how they are handled. If an exception occurs and it is unhandled then Oracle will roll back all previous changes it made with the forall statement. So in this code snippet, if the delete is successful for the items table for item id 21, but it fails for item id 3, it may be because it had a dependent child in another table and if that exception is unhandled, meaning that there is no exception block, either catching that specific exception or one with the when others exception handler, Oracle will roll back all the previous deletes too. But if we have an exception handler, say we have a when others exception handler, it will not roll back the previous delete for item id 21 and it leaves it upon us to assure rollback, or if we desire, we can issue a commit to make that change permanent. But if we wanted that the forall statement should just know the exceptions, but should not stop and continue processing all these statements that can execute off of that. We can achieve that with the save exceptions clause. We put the save exceptions clause after the forall bounds clause and before the DML statement. So in this block we have our associative array, l_itemid_aa of type itemid_aa. We define an exception, array DML exception using pragma exception init we map the array DML exception with the error code, minus 24381. This is the error code which is raised when we use the save exceptions clause to indicate if there were errors. Inside the execution block, we assign values to l_itemid_aa and then run the forall loop from l_itemid_aa.first to l_itemid_aa.last, but notice our use of the save exceptions clause over here. So now the forall successfully processes the delete for item id 21, notes the exception for item id 3, doesn't stop there, goes on to successfully process item id 25, again encounters an exception for item id 2, which it notes. This way it processes all the statements it could in one go and notes the ones that fail and thus it avoids us to run the block multiple times to find the next one which would fail. After the entire processing is over, Oracle will raise ORA-24381 error to indicate that there were errors in the processing of the forall statement. We catch this exception in our exception handler using the predefined array DML exception. Now where are these errors saved and how do we find out the filling statements? This is where the SQL% bulk exceptions clause comes in handy. The SQL% bulk exceptions cursor attribute stores information about the errors encountered during our bulk operation. It is a collection of records. So with the I, I + 1, I + N, I'm indicating that it's a collection. At each index of the collection, we have a record, which consists of two elements. First, is the error index. This is the iteration of the forall statement where the exception occurred. If the collection we are working with starts with 1 and is dense, this will directly correspond to the index counter in the collection where the error occurred. In case of a sparse collection when we are using the indices of clause, this error index will be the iteration of the forall loop and not the actual index counter. In case we are using the values clause to process _____ of the original collection, then you will have to use the error index to find the element in the referenced collection, get its value to find the index counter of the original collection. We will take a look at some examples to understand this better shortly. The second element of the record is the error code. This is the error code for the error which was traced. The total number of errors encountered will be SQL%bulk_exceptions.count. Let's understand this further with a code example. So in this code snippet we have added an l_error_count variable to store the number of errors which occurred during the bulk DML. Inside the exceptions section we get the total number of errors within SQL%bulk_exceptions.count. Next we have a for loop, which goes from 1 to l_error_count. Inside we get the index at which the error occurred using SQL%bulk_exceptionsI.error_index. This error index would be 2 and 4 in our example. Since our collection is dense and starts with 1, it would correspond with the second and fourth element of the l_itemid_aa collection where the error occurred. SQL%bulk_exceptionsI.error_code stores the error code, in our case 02292. In order to get the error message, we pass it on to the SQL ERRM function with a negative sign since SQL ERRM expects a negative number. So SQL%bulk_exceptions is a dense collection and the values it stores for error index is the index counter of the array. Let us understand SQL%bulk_exceptions.error_index when you are using the indices of clause. Let us say our collection has passed with indexes 1, 3, 6, and 8. Doing the forall, using the indices clause, the index values passed in will be 1, 3, 6, and 8. Let us say the error occurs during the second and fourth iteration of the forall statement. So the error index in SQL%bulk_exceptions would be 2 and 4, which is the iteration when the errors occurred. It is not the actual index counters 3 and 8 of the original array. So to find the offending index counters of the original collection we need to iterate all the original collection and then find the index counters which come up in the second and fourth iterations. So here we get the total number of errors using SQL%bulk_exceptions.count_function. Now we loop to the SQL%bulk_exceptions collection from 1 to l_error_count. Inside we have a counter to keep track of the iteration of the original collection. So since it is a sparse collection, we use the while loop to go through it. We get the first index counter using the first function. While does not null we enter the loop to implement the counter. So after the forall situation it will have a value of l_counter equal to 1. We then check and see if this iteration corresponds to the error index. So this would not match for the first situation. We get the next index in the collection using the next method. This will give us an index counter of 3. L_counter is now incremented to 2. This will now match with the error index value of 2, which is the second iteration when the error occurred. So the value of index counter 3 will correspond to the value in the original collection where the error occurred. In the next situation, l_counter will be 3. Finally in the fourth iteration l_counter will be 4. It will match again with the error index of 4. This will correspond to index counter 8. So this is how we obtain the actual error indexes in the original array when working with the indices of clause. In the values of clause we will iterate using the values of l_second_aa, which is 1, 6, 3, and 8. See, the error occurs for values 3 and 8, which are the third and fourth iterations of the loop, so we trade using the error count which is 2. SQL%bulk_exceptionsI.error_index will be having values 3 and 4 to correspond with the third and fourth iterations. Putting them as index counters to l_second_aa will give us 3 and 8, which are the index counters of the items array. These correspond to the item id's 3 and 2. So this is how we can use the SQL%bulk_exceptions with the values of clause. We will now look at a couple of demos, to first understand the SQL%bulk_rowcount and SQL%bulk_exceptions clauses and the second one is the one where we compare the performance using the forall to do a DML versus doing DML using a normal for loop.

Demo: SQL%BULK_EXCEPTIONS & SQL%BULK_ROWCOUNT

In this demo we will demonstrate the use of SQL%bulk_exception as well as the SQL%bulk_rowcount functions. Let's first do a select from the items table. (Typing) There are currently 10 items in there with item id's 1 to 10. Now let's do a select from the orders table. (typing) We see that there are currently orders in there for item id's 1, 2, and 3. Let's first see how we can use the SQL%bulk_exceptions clause to capture the statements which fail while doing the bulk DML. So here is an anonymous block where in the declaration section we have a type id_aa, which is an associative array of PLS integer indexed by PLS integer. L_id_aa is of type id_aa. L_error_count, l_index, and l_itemid are all of type number. Array DML exception is an exception we have declared to capture the error thrown by the forall statement when one or more of the DML statements fail inside it. It throws that error after it has finished processing the rows to indicate to the client that not all rows were processed successfully. The error code for this error is 24381, which we associated with the array DML exception using the pragma. To begin the execution section by filling up our associative array with the item id's we want to delete, we then start our forall iteration going over the item id's. Inside we try and delete from the items table for the item id's passed. Item id's 3 and 2 have records in the orders table which are linked to the items table by a foreign key relationship. So trying to delete them should raise errors. We should be able to delete items id's 5 and 7 with no problem. So our first and third iterations should be successful and the second and fourth should fail; however, using the save exceptions clause, it will not stop the forall processing when the error occurs, but the errors will be captured in SQL%bulk_exceptions collection. Later, in the exception block in the when array DML exception, we first get the error count by SQL%bulk_exceptions.count and then loop from one to the error account. SQL%bulk_exceptionI.error_index gives us the index position of where the error occurred. So using that as an index counter for l_idea will give us the item id for which the delete failed. SQL%bulk_exceptionsI.error_code gives the corresponding error code. Since the SQL ERRM function takes in a negative number, we put a minus sign and pass it in. Let's run this clause. (typing) As expected, from the outward console we see that errors occurred at indexes 2 and 4 for item id's 3 and 2 and the corresponding error messages integrity constraint violated, child record found. Let's now select from the items table again. (typing) Indeed, the other two items, 5 and 7, were successfully deleted. (typing) Let's roll back our delete. (typing) Let us now see the use of a SQL%bulk_rowcount function, which returns the count of the rows affected by each DML statement run as a part of the forall statement. First, let's select from the orders table. (typing) We see that there is one order for item id 1, two orders for item id 2, and three orders for item id 3. (typing) This is the same code snippet as before. The only difference is that we have changed the id array to hold the item id's 1, 2, and 3, and inside the forall statement we are deleting from orders table where order item id is the item id in the l_id array. Now using the same loop construct as we had used for the forall statement, so for I in l_id_aa.first to l_id_aa.last, we loop and print the rows affected for index I by passing into the SQL%bulk_rowcount function. Let's run this. (typing) As expected, we see the rows affected for index 1, for item id 1 is 1, 2 is 2, and 3 is 3. Let us now take a look at a demo to compare the performance using the forall statement versus doing the DML using the normal for loop. (typing)

Demo: Performance Gain with FORALL

In this demo we will see how the forall statement can give us a tremendous gain in performance. We will compare the performance using the forall statement versus doing a similar DML using the for loop. First, let's delete everything from the items table. (typing) Now here is an anonymous block where we have declared type number_aa is table of number index by binary integer. Type VARCHAR_aa is table of VARCHAR 260, index by binary integer. L_itemid_aa is of type number_aa. L_item_name_aa is of type VARCHAR_aa, and l_item_value_aa is of type number_aa. As you can imagine, these three collections will be used to store the values for these individual columns. L_start_time and l_end_time would be used to record the start and end times for both the normal for loop and for all statements. L_time_normal is the time elapsed for normal for loop inserts and l_time_for_all is elapsed time for forall inserts. We first start off by filling our associative array variables with 100,000 rows in a loop assigning values to l_itemid_aa, the index counter I, l_item_name_aa, the string item concatenated with I, and l_item_value, a value of 600. These three collection variables will be used for the three columns, item id, item name, and item value of the items table. (typing) Then using the DMS utility.get time function, which returns us back the time in 100th of a second, we get the start time in l_start_time. We run the normal for loop insert from 1 to 50,000, inserting into the items table these three columns. Using the three collection variables we had filled in earlier. After the insert, we record the end time in l_end_time. We then print the elapsed time using l_end_time minus l_start_time divided by 100 to get the time in seconds. We commit our inserts. Next we insert the next 50,000 rows using the forall insert by using forall I and 50,001 to 100,000, insert into items, item id, item name, item value and then with the values clause supplying the three collection variables. We capture the end time. We again calculate l_time_for_all as l_end_time - l_start_time divided by 100 to get the elapsed time in seconds. We print the elapsed time, commit our inserts, then we compare how much more time the normal for loop insert took versus the forall insert by diving l_time_normal with l_time_for_all and truncating the result. Let's run this. (typing) We see from the output that the elapsed time for a normal for loop insert is 4.56 seconds. The elapsed time for a forall loop insert on the other hand was just 0.18 seconds. So the normal for loop insert took 25 times more than a forall insert, which is a pretty impressive performance gain. With this we have come to an end of this module. Next let's summarize what we talked about.

Summary

In this module we talked about the second bulk construct of a level in Oracle, the forall statement. We saw how we can use this construct within our DML statements. When the collection is passed, we use the indices of and values of clauses along with the forall statement. We then saw the use of SQL%bulk_rowcount function to obtain the number of rows affected by each statement executed with the forall clause. We saw some _____ save exception clause, which enables the forall statement to complete processing all the rows in the collection and not stop if an error occurs. SQL%bulk_exceptions class helps us find the items which failed and the reasons for the failure. So as you can see, Oracle provides us with a lot of easy and powerful constructs to manage the forall clause, and finally we concluded with the demo, demonstrating the significant performance boost we get by using the using the forall statement and why it is important to understand and use this feature in our PL/SQL code.

Course author

    
Pankaj Jain
Experienced technologist, with expertise in various aspects of software development lifecycle, architecting software solutions and software development.
Course info

LevelIntermediate
Rating
(75)
My rating
Duration4h 52m
Released8 May 2015
Share course

