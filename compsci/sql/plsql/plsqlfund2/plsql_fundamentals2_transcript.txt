
Code School
Oracle PL/SQL Fundamentals - Part 2
by Pankaj Jain

In this course, we will take an in-depth look at Procedures, Functions, and Packages. These named program units are powerful programming constructs which can greatly enhance and optimize your code.

Resume CourseBookmarkAdd to ChannelLive mentoring
Table of contents
Description
Transcript
Exercise files
Discussion
Learning Check
Recommended
Overview

Overview

Hi, welcome to Pluralsight. My name is Pankaj Jain, and welcome to this course on Oracle PL/SQL Fundamentals - Part 2. This course is a continuation of the Oracle PL/SQL Fundamentals - Part 1 course, and builds on the concepts we learned in that course. So if you have not checked out that course yet, I highly encourage you to do so. In this course you will talk about named program units, which are blocks of PL/SQL code stored in the database with a name. These named program units are the core of PL/SQL programming and provide a lot of benefits in terms of performance optimization and reusability. We will talk about procedures, which allow us to encapsulate business logic in a named program unit. We will take a look at functions, which like procedures, encapsulate business logic, but also return a value. Parameters provide a way to customize your named program units and extend their power further. Oracle provides a lot of flexibility and features with parameters in terms of passing them with reference or by value, named or positional notation, IN, OUT, and IN OUT mode, as well as the NOCOPY hint. We will talk extensively about these. We will talk about local subprograms, which allow repeated functionality, which is unique to a subprogram, more usable. We will then dive into package specification, which is a very important programming construct in Oracle. Package specifications are like interfaces, which provide public APIs for clients to consume. They facilitate logical grouping or subprograms, as well as provide session state and global variables. Package body is the place where we provide implementations of the subprograms you declared in the specification, and it goes hand-in-hand with the package specification. We will take an in-depth look at it. We will talk about calling functions from SQL, which extends the power of SQL statements. We will also talk about the eligibility criteria for a function to be called from SQL, the restrictions, and key features like DETERMINISTIC and PARALLEL_ENABLE, which you can use with functions. Finally, we will talk about how roles and privileges come into play with named program units, subprogram resolution, and the definer and invoker of _____ clauses. There is a lot of exciting stuff to cover, so let's get started.

Benefits of Named Program Units

What are named program units? Let us talk about the example of photography. I recently bought my Canon DSLR camera. It is a very impressive camera, which allows me to have my own custom settings for various parameters aperture, focal, and etc. This is analogous to the anonymous blocks we spoke about in the Part 1 course as these settings are known only to me. However, my camera also has some prebuilt modes like the scenic mode or nighttime mode, etc., which one can refer to and call by name, and anyone with a Canon DSLR camera can understand and get to. This provides a lot of convenience as it makes it very easy for everyone to share the same configuration and talk about them. With one click, when these named modes are called, any Canon DSLR camera is configured with identical settings. This is similar to the named program units like procedures, functions, packages, etc., which are precompiled and stored in the database directly, and can be called by name. Some of the obvious benefits of having named program units are that they help create reusable modular pieces of code. So we write the business logic once and then it can be used and called by several consuming clients in several places in code, providing consistent logic at all places. All changes have to be done at one place, which then takes effect across all consuming clients. They provide a layer of abstraction or complex business logic, which then can be called by name. They also help in performance as named program units are precompiled and stored in the database, making it efficient for the database to call and execute them. They help in reducing errors as _____ business logic inside of the stored program unit, then you can call it with confidence in other clients knowing it is going to work consistently and as expected.

Prerequisites

Let us talk about some of the prerequisites for taking this course. This course is a continuation of the Oracle PL/SQL Fundamentals - Part 1 course on Pluralsight. In the Part 1 course we cover some of the basic concepts and programming constructs, which provide the building blocks for the named program units. We talked there about anonymous blocks, PL/SQL data types, conditional executions, loops, cursors, exceptions, debugging, etc., which will come into play when we _____ the named program units. So one of the prerequisites to be more effective with this course is to take the Part 1 course, or otherwise you should have the equivalent basic Oracle programming knowledge to get the most out of this course.

Audience

Who would be the audience for this course? This course is for Oracle database programmers with basic Oracle programming knowledge who want to learn writing named program units in the database in order to effectively utilize the power and flexibility offered by Oracle PL/SQL programming. This course will also be useful for more experienced Oracle programmers who might find this as a good refresher course and may discover some new concepts. This course might be of interest to web programmers who like to execute the database and SQL-intensive business logic in the database layer versus the web layer, thus preventing multiple round trips to the database and reducing _____ latency. This course will also be beneficial to programmers from other languages who have followed along the Part 1 course and would like to further expand their Oracle PL/SQL programming knowledge to be more effective with it.

Tools

In this course, we will be talking about PL/SQL programming constructs and concepts, which should work with most Oracle database versions. However, I will recommend you to work with the latest versions in order to take advantages of the optimizations and efficiencies Oracle builds with each new database version. For the demos I will be using Oracle Express Edition, which you can download from Oracle's website. It is an entry level, small footprint database, free to develop, deploy, and distribute on. For the tools I will be using Oracle SQL Developer, a free IDE, or development environment. You can download that too from Oracle's website. SQL*Plus is a command line utility, which you can install on the client machine to communicate with the database. You can use it for running scripts against the database. Most of the examples we will talk in this course I'm going to run using SQL*Plus, however, if you have access to and are more familiar to other IDEs like Toad and SQL Navigator, just to name a few, feel free to use them to try out the exercises on your own. I will be using SQL Developer exclusively for running the demos in this course.

Procedures

What is a Procedure?

Hi, welcome to Pluralsight. My name is Pankaj Jain, and welcome to this module on Procedures. A procedure, as the name indicates, is performing a set of tasks in a certain order. For instance, when you select the wash program on your washing machine it will first fill it with water, and then perform the other steps in sequence to wash, rinse, and spin your clothes. Oracle Database also provides the mechanism to create procedures, which encapsulates a series of tasks performed in a certain order, and all these procedures can be called by several clients. The database compiles and stores it internally, as well as caches it in memory, enhancing reusability and performance. Let us take a look at this important programming construct. So, what is a procedure? A procedure is a named program unit stored in the Oracle database. It offers all the benefits of a stored program unit we talked about earlier, like reuse, consistency, and performance optimization of the PL/SQL code. The procedure performs a unit of work or a piece of business logic. This can be a commonly performed task like process customer order, _____ processing, etc. The procedure does not return anything. You can possibly still return values using the out parameters of a procedure, but generally a procedure does not return anything. In this module, we will take a look at the basic structure of a procedure, how to define compile, and execute it. This will build a basic foundation for our discussions in later modules where we talk about passing parameters to procedures, and defining local programs. Before we dive deeper into our modules, let us take a look at the tables you will be using throughout this course. We will be using the departments table, having two columns, dept_id and dept_name, and the employee table, having emp_id, emp_name, emp_dept_id, emp_loc, emp_sal, and emp_status column, the emp_dept_id being a FOREIGN KEY to the dept_id column of the departments table. I like to use prefixes for each of my table columns, like emp for employee, and dept for department columns. This helps with the readability in queries. I also like to use the source table, underscore, foreign table left key format for naming my constraints. For example, emp_dept_fk, which tells me right away the relationship. I cannot emphasize enough the importance of standard naming conventions in improving the readability and maintainability of your code.

Defining Procedures

In order to create stored program units like procedures, functions, and packages in your own schema, you need to have CREATE PROCEDURE privileges assigned to you. In order to create these named program units in another schema, you need to need to have CREATE ANY PROCEDURE system privileges assigned to you. To alter a procedure created in another schema, you will need to have ALTER ANY PROCEDURE system privileges. And, to execute a procedure created in another schema you will need the EXECUTE privileges. These privileges can be assigned by a DBA. So here in this code snippet we are demonstrating the syntax for granting these privileges. The GRANT CREATE PROCEDURE TO demo grants necessary privileges to demo to create a procedure. GRANT CREATE ANT PROCEDURE TO demo grants necessary privileges to demo to create a procedure in any schema. GRANT ALTER ANY PROCEDURE TO demo grants necessary privileges to demo to alter any procedure in any schema. And finally, GRANT EXECUTE ON schema_name.procedure_name TO demo grant demo the privileges to execute a procedure owned by another schema. Note, the procedure name is fully qualified by the schema name, followed by a dot, if the schema name is not used it defaults to the current schema. The most basic syntax to define a procedure is CREATE OR REPLACE procedure followed by the schema_name.procedure_name. Note that OR REPLACE is optional. If not used, then if there is an existing procedure by the same name, Oracle will come back with an error that the name is already used by an existing object. So I almost always use the OR REPLACE syntax, which will override an existing procedure if it exists, or otherwise it will simply just create a new one. Next is the IS or AS keyword. After this, you can do any variable or cursor or exception declaration. Note, there is no declared keyword to explicitly start the declaration section, but after the AS or IS keyword, and before the BEGIN keyword is where you will declare. The BEGIN keyword start the execution section. Inside of the execution section you can have the DML statements like inserts, updates, and deletes, as well as the DDL statements like create or drop, along with other procedural constructs and statements to define your business logic. You can have an optional EXCEPTION section. I highly encourage you to have an EXCEPTION section with every program unit to trap exceptions and do the necessary actions, as well as display more meaningful messages to the client applications. Finally, the END keyword ends the procedure. You can optionally have the procedure_name after the end, which I think is a good practice to help with readability. Let us take a look at an example of creating a simple procedure. Here is a simple procedure called update_dept, which updates the department ID of a given employee. It starts with CREATE OR REPLACE PROCEDURE update_dept AS, followed by the declaration section. Here we have declared l_emp_id of type employee.emp_id%TYPE, and assigned it a value of 10. The BEGIN keyword begins the execution section where we issue an UPDATE statement, updating the emp_dept_id to a value of 2 for the emp_id l_emp_id. We COMMIT the changes. Then we have the EXCEPTION section where we have the WHEN OTHERS exception handler, where using DBMS_OUTPUT.PUT_LINE, we show the SQL error message, as well as the exception stack trace. To learn more about exception handling and exception stack traces, please refer to the exception handling section in the Part 1 course of this series. We ROLLBACK the update. Finally, we RAISE the error again to the client. Note this is important, especially from the WHEN OTHERS handler so the client application is aware that an exception has occurred. Without the RAISE keyword, no error will bubble up to the consuming client as it is handled in WHEN OTHERS handler. Finally, the END update_dept keyword ends the procedure.

Compiling Procedures & Native Compilation

In SQL*Plus, you compile the procedure by simply typing it and having a slash after the END keyword and hitting Enter, as in this example. You can do it similarly in SQL Developer by typing it in SQL Worksheet and pressing Run Script. Once compiled, you can also open the procedure in a separate window in SQL Developer where you have the compile option on the top as we will see in the demo shortly. Oftentimes you will have saved your procedure in a file to check it in source control repository. You can compile the procedure, which is in a file, say we have this procedure in a file named update_dept.sql. You can give it any name, but I like to give it the name of the procedure or function so that it is easy to identify followed by a .txt or .sql extension. So that file is saved in SQL and the Demo directory. To render files from SQL*Plus or SQL Developer, I will put the at sign followed by the full path name to the file, and then hit Enter in SQL*Plus or click Run Script in SQL Developer to run it. Once you have compiled a procedure, you can compile it again using the ALTER PROCEDURE COMPILE syntax. ALTER PROCEDURE update_dept COMPILE will recompile the update_dept procedure. While we are on the topic of compilation of program units, let me share with you a couple of useful tips, which can possibly improve the performance of your program units. Those will be native compilation and PL/SQL optimize mode. This discussion is valid for procedures, functions, as well as packages. Let us talk about native compilation first. Oracle, by default, compiles a PL/SQL program unit in an intermediate machine-readable code. At runtime, this machine code is interpreted by the runtime engine. Starting with Oracle version 11g, you can compile your code in the native format. With native compilation, the code is directly compiled into native C code that need not be interpreted at runtime, thus increasing performance. This is particularly useful for computation intensive program units where a lot of PL/SQL logic, expressions, and computations are involved. The downside to native compilation is that the compile time has increased, but if that is not a big concern, I think it is a good setting to use. Oracle provides us with an option, PLSQL_CODE_TYPE, which has two values, the default INTERPRETED, and the new NATIVE value. You can turn on native compilation for the entire system or just for your session. Here, I'm showing you how to turn it on for the session by using ALTER SESSION SET PLSQL_CODE_TYPE equal to NATIVE. After this, all the program units compiled in this session will be natively compiled, you can just compile an individual unit natively if you want to. So, ALTER PROCEDURE update_dept PLSQL_CODE_TYPE equal to NATIVE will compile update_dept in the native mode. So this is a good setting to use while compiling to make your code faster and more performant.

PLSQL_OPTIMIZE_LEVEL & Compile for Debug

I also wanted to briefly mention the PL/SQL optimize level parameter, which you can set from a value from 0 to 3. This parameter makes the compiler do more efforts to optimize that code at compilation time. Of course, it should be an effort to write optimized code, but sometimes you might be maintaining large pieces of old code and rewriting all of it may not be possible, or sometimes simply you might have overlooked something while writing your own code. Just like native compilation, this is another setting you can use to compile your code to make it more performant where Oracle transparently does the work for you behind the scenes without any code changes on your part. The PL/SQL optimize level of 0 will keep the optimization to pre-10g database level, and will not take advantage of the performance gains of PL/SQL in version 10g and above. Level 1 will cause optimizations, like say removing unnecessary computations. For example, if you are assigning a constant value of 2 to a variable inside the loop, which runs 1000 times, then you could as well do it once outside the loop and avoid unnecessary assignments 999 times. That is one of the things what level 1 will transparently do for you. Level 2 will, among other things, replace cursors for loops to a _____. And level 3 will automatically do code inlining and other optimizations. What is code inlining? Say you have a procedure called in the loop several times, instead of going and fetching it every time, the compiler will automatically copy it inline, thus increasing performance. You can set this parameter at the system or session level. The syntax of setting the optimizer level to a value of 2 for a session is ALTER SESSION SET PLSQL_OPTIMIZE_LEVEL equal to 2. We will see how to do it from SQL Developer also. I recommend you keep it at least at a value of 2. Setting is at a value of 1 or lower also turns off native compilation, so it is a good idea to keep it at above level 1. I will check the current PL/SQL optimization level and PL/SQL code type settings for your program unit. You can run the query SELECT PLSQL_OPTIMIZE_LEVEL, PLSQL_CODE_TYPE FROM ALL_PLSQL_OBJECT_SETTINGS WHERE NAME is your procedure or function or package name in the uppercase. This will tell you the PL/SQL optimize level and PL/SQL code type settings with which your program unit was compiled. Let me also briefly touch upon compiling a procedure for debug. If you have a need to debug your procedures or functions or packages, you have to compile them in the debug mode. This will allow you to set breakpoints and debug your procedure. We covered how to set breakpoints, etc., in the Oracle PL/SQL Fundamentals - Part 1 course, so please review it if you need to. Only INTERPRETED code can be debugged and compiling a natively compiled code in the debug mode will make it interpreted. You should do this in non-production environment only as it can slow the performance. You can compile the procedure for debug using the syntax ALTER PROCEDURE update_dept COMPILE DEBUG. We will take a look at how to compile a procedure in debug mode in SQL Developer when we take a look at the demo. PLSQL_DEBUG is a parameter, which was used until version 10g, and is deprecated in version 11g. This parameter, when set to true, will compile the program unit in the debug mode. It can be set at the session or system level. I have noticed that sometimes in SQL Developer, the default value is set for this is true, causing all the procedures I created there in debug mode. In order to have control over whether I want to compile a program in debug mode or not, I set this to false in the beginning of the session and then only compile in debug mode the programs I do want to compile in that mode. I would recommend you to do the same. The command to set it to false is ALTER SESSION SET PLSQL_DEBUG equal to FALSE.

Errors and Warnings

When you compile the procedure, and we will shortly see a demo, the compiler will throw you errors or warnings. The discussion about errors or warnings is applicable to procedures, as well as other program units like functions and packages, which we'll talk about later. Errors are saved for situations when you have misspelled the table name and so obviously the compiler cannot find it and will complain. Or, if we have syntax errors, which the compiler will catch for you to correct, the error conditions are always enabled when you compile the code and your code will not be marked as valid and executable until you fix them. For instance, when I misspell the employee table name in my prodecure, the compiler comes back with an error in SQL*Plus as Warning: Procedure created with compilation errors. In SQL Developer, it will report it as Errors: check compiler log, and in the log view it will display the error. I can type SHOW ERRORS in SQL*Plus or SQL Developer and it will show me the errors. Here it tells me that at line 4, column 12, the table or view I have mentioned in my code does not exist. Starting with Oracle version 10g, Oracle compiler can also give you warnings. These are conditions which are not errors, but conditions in code, which may lead to incorrect results, or result in slower performance or logic which seems wrong. The warnings start with the PLW keyword. For instance, PLW-06002, which stands for Unreachable code. The severe category is the category of conditions which might lead to incorrect results, for instance not explicitly stating the _____ clause for the procedure. We will talk about _____ clauses later when we talk about roles and privs for our stored program units, but briefly it states the permissions set under which the program is going to run, either the permission set of the definer of the procedure or the permission set of the executor of the procedure, and can make a whole lot of difference to the final result. Then, there is a performance category, which points to conditions in code which might lead to slower performance like unnecessary use of variables, etc. Finally is the informational category, which gives warnings for conditions like Unreachable code where, for example in the EXCEPTION block you have some code after the RAISE statement. The RAISE statement will immediately transfer control to the calling client and the code after it will never get called. So the compiler indicates that was with the unreachable code warning. The warnings can be set at different levels like enable and disable, which are self-explanatory, or they can be set to error where we are telling the compiler to treat the warning as an error condition. The procedure which is compiled with warnings can still be executed, however, a procedure which is compiled with errors cannot be executed as the compiler marks it as invalid. In the development mode, I always set all the warnings to enable as it helps me catch for these situations early on. The compiler helps in looking out for situations which can slow my code or lead to incorrect results, which is a great help. I would highly encourage you to also do so. Let us now see how we can enable these. There are several ways you can set warnings. Oracle gives you fine-grained control in that it can set each category for the warning at a different level, and you can do it just for your session or it can be set for the entire system. The first way of doing it is using the ALTER SESSION or ALTER SYSTEM command. For example, here we have set the PLSQL_WARNINGS to be enabled for the session, for all categories using ENABLE:ALL. Similarly, using ALTER SESSION SET PLSQL_WARNINGS DISABLE:ALL, we can disable them all. We can give them individual settings using the example syntax as shown. Here, for the session, we enable the PERFORMANCE category, enable the SEVERE category, and disable the INFORMATIONAL category. We can just specify them at the procedure level, for instance, with the ALTER PROCEDURE compile command specifying the PLSQL_WARNINGS for the different categories. Here we compile the procedure setting warnings to enable state for PERFORMANCE, error for SEVERE category, and even though code 06002 is an INFORMATIONAL warning for unreachable code, we can tell the compiler to treat it as an error. This shows the fine-grained control we have to specify these at different levels. The REUSE SETTINGS clause it optional and it tells the compiler that for the settings not specified, for example, here we have not specified a level for INFORMATIONAL category, we use the setting from the last time it was compiled. If there was no setting specified the last time also, then it uses the current session settings. If there are warnings, the compiler will come back with Procedure created with compilation warnings. You can type SHOW ERRORS command to see the warnings in SQL*Plus, in SQL Developer the compiler log will show the warnings. DBMS_WARNING is another package to which you can set these settings and get the current settings for the session. This package has many procedures, but we will take a look at a couple of them that I think you will be using most often. We have the procedure add_warning_setting_cat, which takes in three parameters, the first being the warning_category, which can be informational, severe, and error, or all for all of them. The second parameter is to specify the warning_value as in enable, disable, or error. And the third parameter of scope takes in session or system. In this code snippet, we have shown the use of dbms_warning to add the warning_setting. For instance, INFORMATIONAL will be disabled for the session and enabled for the SEVERE and PERFORMANCE category. And of course using ALL, we can set it for all of them. We can display the current setting, calling the dbms_warning.get_warning_setting_string function FROM dual. Dual is a sort of dummy table with a single record used for selecting when you are not actually interested in the data, but instead want the results of some system function in a select statement.

Demo: Creating & Compiling Procedures, Errors and Warnings

In this demo we will take a look at how to create and compile a procedure, as well as how to execute it. We will then see how we can see the errors, if any, and set the warning levels. Let us start off by creating the setup tables and inserting some sample data in them. First is a departments table with two columns, dept_id and dept_name. We insert a couple of rows in this table for dept_id 1 for IT and 2 for Accounting. Next we create the employee table with columns emp_id, emp_name, emp_dept_id, emp_loc, emp_sal, and emp_status with a FOREIGN KEY constraint emp_dept_fk, creating a FOREIGN KEY on emp_dept_id, referencing the dept_id from the departments table. Let us insert a few rows in here too. Let us run this script. (Running) So everything got created successfully. Let us create the procedure update_dept. We have a SQL worksheet open here where we have the procedure as CREATE OR REPLACE PROCEDURE update_dept, followed by AS. We begin the execution section with the BEGIN keyword where we issue the UPDATE statement for the employee table, updating the emp_dept_id to l_emp_id for dept_id 2. Note that here purposely, I have passed 2 as a character string even though emp_dept_id is a number. We then print the rows updated using DBMS_OUTPUT and using the SQL%ROWCOUNT function. We make the changes permanent using the COMMIT statement. We then have the EXCEPTION block where using DBMS_OUTPUT statements we are printing the SQL error message and exceptions stack trace to the console. We are then raising the error to the client application and rolling back any updates we have done. Let us hit the Run Script button to compile and create it. The script output says that the PROCEDURE UPDATE_DEPT was compiled successfully. Now, if you expand the Procedures tree, you will see the procedure there. You might have to right-click and click Refresh to see our procedure. You can double-click the procedure and it opens it up in a window with the procedure name on top. Over here you can make further changes, and then you can press the Compile button over here to compile the procedure again. Another way of creating the procedure in SQL Developer is, is to click on the Procedures node and then right-click and select New Procedure. It'll open up a new window for you where you can specify the procedure name, you can specify any parameters, if any. We will talk about adding parameters to the procedure later on. It also has a DDL tab where it keeps building the DDL for you, you can then click OK and it opens up the Procedure window with the basic body built for you. You can further fill the body with the logic, and then hit the Compile icon on top. It tells us that our procedure was created successfully and you can see it in the Procedures tree that our procedure indeed shows up there. Let us go back to our update_dept procedure and let us try to introduce some errors to our procedure now. Let me misspell the employee table name and call it employees instead. (Typing) Let us hit the Run Script button again. The Script Output reports to us that there were errors and to check the compiler log. Let's click on the Log, and then over here we see that Oracle is complaining that the table or view does not exist at line 4. In the Procedures node, if you refresh by right-clicking, you will see that there's a red cross sign against our procedure, indicating that it is currently invalid. Let us fix the error and click the Run Script button again. Let us refresh the Procedures node, and now our procedure is again back in the valid state. Let us now set and understand the warning levels. First, let us run the SQL statement select dbms_warning.get_warning_setting_string from dual to see the current warning levels. We see that it is set to DISABLE:ALL. Click on Tools, References, expand the Database node, and select PL/SQL Compiler. Here you can see that it allows us to set the warning values for the different categories. In the drop-down you will see the default value of NULL followed by ENABLE, DISABLE, and ERROR. You can set values for specific categories or set them to ENABLE for ALL. I generally prefer to keep it enabled for all levels. Let's keep the optimization level at 2 and click OK. We could have also issued the statement ALTER SESSION SET PLSQL_WARNINGS equal to ENABLE:ALL. We could have issued the statement call dbms_warning.add_warning_setting_cat ALL, ENABLE, SESSION to enable the warnings and the session level using the dbms.warning package. All these are different ways to set the warning levels for different categories. Now let's run the select statement again, and this time we see that the warnings have been set to be enabled for all categories. Now let's go back to our procedure again and compile it. This time we see that the warnings came up, and if you click on the Log, you will see that warnings over here. If you see the warning regarding PL/SQL debug as it is _____ parameter, then use ALTER SESSION SET PLSQL debug equal to false in the session. The first warning in this list is the severe category of warning regarding our program unit UPDATE_DEPT, omitting optional AUTHID clause and the default value of DEFINER being used. We will talk about this in detail later on, but in short, the AUTHID clause decides the privilege set under which the procedure runs, the one defining the procedure or the one executing it. We will let this warning stay for now, the default value of AUTHID DEFINER is what we want anyways. Next is a performance category warning, which says that the bind type will result in conversion as the bind type is not the column data type, and any unnecessary conversions can reduce performance. The last warning is an informational category warning for unreachable code as the raise statement will cause the execution to jump out of the procedure not executing the rollback statement. If you go to the procedure from the navigator and compile it over here, you will get similar warnings. Let us fix some of these warning situations. This will prevent the bind type conversion and let's keep the raise statement as the last one to be executed. Let's compile it again. And this time all the warnings but that of the AUTHID clause go away. We will talk about the AUTHID clause later on. Let us now see how we can compile our procedure in the debug mode. There are two ways we can do it. One is by showing the command ALTER PROCEDURE update_dept COMPILE DEBUG. Let's do that. Now if you go to the Procedures node and refresh it, you will see that green sign against our UPDATE_DEPT procedure, which indicates the debug mode compilation. The other way is to go to the procedure directly, and then over here choose the Compile for Debug option, and this will do the same thing. How do we compile our procedure in the native mode? By issuing the command ALTER PROCEDURE update_dept COMPILE PLSQL_CODE_TYPE equal to NATIVE. Let's run this. And how do we check the current settings? By issuing the SELECT plsql_optimize_level, plsql_code_type, plsql_warnings FROM all_plsql_object_settings WHERE name equal to UPDATE_DEPT. Running this query shows us that our code was compiled at PLSQL_OPTIMIZE_LEVEL of 2, it is compiled in the native mode, and the warnings were enable for all categories.

Executing Dropping & Terminating Procedures

You can execute the procedure by using the EXEC or EXECUTE or CALL keyword followed by the procedure name and a semicolon. We will take a look at passing parameters procedures in a later module. For instance, we can execute the update_dept procedure in the following ways. We can use the call keyword as call update_dept followed by brackets. The brackets are necessary with the call keyword. We can also use exec update_dept followed by a semi colon. Here brackets are optional. Finally, we can use execute update_dept to execute a procedure. You can also call it from an anonymous block. Here we just call it by name without having to use the exec or execute or call keyword as shown in this code snippet. You can simply drop a procedure by using the keyword DROP PROCEDURE followed by the procedure_name. In this code snippet, we drop the update_dept procedure by issuing DROP PROCEDURE update_dept command. A procedure, which does not encounter any errors, does its job and terminates gracefully. So here is the same procedure we looked earlier, if everything goes fine then it will execute the procedure onto the last line where it prints Finished Successfully and completes the execution and returns back to the calling client. However, if an error is raised explicitly, or anywhere during the execution of a statement, the execution goes right from the point where the exception is raised to the exception block, if defined. Otherwise it goes to the calling client. The statements are for the point where the exception is raised are not called. So in this code snippet, if you try and update the dept_id to a non-existent department, and since there is a foreign key from this table to the departments table, an exception _____ 0291 for integrity constrained violation will be raised, taking the execution from the UPDATE statement to the WHEN OTHERS exception handler, and the last DBMS_OUTPUT statement will not be executed. You can also explicitly come out of a procedure without it completing normally until the end of a procedure by using the RETURN keyword, which will make the execution jump outside the procedure for the calling client from where it is called.

Demo: Executing Dropping & Terminating Procedures

In this demo we will take a look as to how we can execute or run our procedure. Here is our procedure update_dept again where we are declaring l_emp_id of type employee.emp_id%TYPE. Then we begin the execution section with the BEGIN keyword where we issue the UPDATE statement for the employee table updating the emp_dept_id with dept_id 2. We then print the rows updated using DBMS_OUTPUT and using the SQL%ROWCOUNT function. We make the changes permanent using the COMMIT statement. We then have the exception block where using DBMS_OUTPUT statements we are printing the SQL error message and the exceptions stacked raise for the console. We rollback the update and raise the error further. There are several ways to run it. The first one is through an anonymous block where we call it in the executable section by name. Let's run it. We get the output Rows Updated 1. We can also run it using the call statement as call update_dept with parenthesis. Note the parenthesis are required for the call statement. Let's run it. We get the same result. Let us now run it as the exec statement as exec update_dept. Again, we get the same result. And finally, let's run it as execute update_dept, and again we get the same result. The parenthesis are optional with the exec and execute statements. We can also go back to our procedure and you can run it directly from here by pressing this green triangle. This brings up a Run window where it builds an anonymous block for you to run it. Notice, here it is calling the update_dept just by name. We will talk about passing parameters to a procedure shortly, but if you had parameters you could specify them right here and then click OK. It executes the procedure and brings up the log with the messages and now our output. If our procedure had output parameters, it would have shown them in this window. Let us now see how to do explicit domination of the procedures. The RETURN keyword returns control immediately to the client. Let's put a RETRUN keyword before the DBMS_OUTPUT. Let us compile it and run it again. This time it comes back without the DBMS_OUTPUT statement. So the return statement calls the execution to jump out of the procedure from the point where it is called. Let us see how the execution will flow in case of an exception. Let us introduce a situation, which will result in an exception. Say for instance, let's assign the deptm_id to a non-existent dept_id of 20, this will cause a foreign key violation causing an exception to be raised. Let's compile this and run it again. The output window reports of an exception, so the execution flows from the UPDATE statement to EXCEPTION block, and then to the client with the raise statement, and the last DBMS_OUTPUT statement never gets a chance to be executed.

Summary

In this module, we took a look at procedures and the reasons why they might be needed. Procedures perform a unit of business logic, they are compiled and stored in the database, and can be called by name, which greatly increases reusability and performance. We saw how we could define a simple procedure. Procedures can also take parameters, which further enhances customization and reusability. We will take a look at how to pass parameter's procedures in a later module. Compilation of procedures can raise errors for syntax or invalid object names, but Oracle can also give us useful warnings to help us identify and correct situations early on, situations which can lead to incorrect results or a slower performance or may result in unnecessary code. I would recommend setting the warning levels enabled for informational, severe, and performance categories in development mode for this reason. We looked at various procedural operations like how to compile, execute, drop, and dominate procedures. We also looked at native compilation and PL/SQL optimized level parameter, which when used during compilation can possibly make our code more performant.

Functions

What is a Function?

Hi, welcome to Pluralsight. My name is Pankaj Jain, and welcome to this module on Functions. Functions, like procedures, are named program units and can greatly enhance the power and flexibility of our code. Oracle provides us with a rich set of built-in functions, as well as allows us to define our own. Functions help extend the SQL statements, as well as modularize and abstract complex business logic. Let us take a look at this very important programming construct. A function, like a procedure, is a stored subprogram, meaning it is precompiled and stored in the database with a name. It has all the benefits of a stored subprogram like reusability and performance optimization. A function always returns something. It can return a simple data type like a number or a character, or more complex data types like collections and records. A function is used in expressions to assign value to a variable, or they can be directly called in SQL statements to fetch values as a part of a select statement, or update, insert or delete values in DML statements. We will take a look at how to call functions in SQL statements and the restrictions in a later module. Though sometimes I can achieve my objective by using either a function or a procedure, the general rule of thumb I follow to decide which one to create for a given problem is that when as a part of business logic, I have a need to return something back to the calling client, then I will use a function. For example, for a given purchase price and location to calculate taxes for an item, or to find out the commission I need to pay a sales rep after applying the commission logic, are just some examples where I might use a function. When I just have to do a unit of work without having to return anything back, I create procedures. For example, to do year end processing or to aggregate the accounting data and update the accounting tables. In these cases I would create procedures.

Oracle Provided Functions

Oracle Database provides a rich set of built-in functions, which are available as a part of the PL/SQL environment. They take care of a lot of commonly used tasks. Some of these functions can be directly called in SQL statements, as well as in PL/SQL subprograms. There is a rich set of functions, but just to give you a small sampling of these, there are numeric functions, which state a number parameter and also return a number. For example, the ROUND function, which we looked at in the Data Types module in Part 1 course of the series, rounds a number to the closest integer. The CEIL function, which returns the next integer value greater than or equal to the given number input. For example, for 15.2 it will return 16. Here in this code snippet we see the ABS, or absolute function, which takes in a number, here -123, and returns the absolute or positive value of 123 and assigns it to l_num. Later, we print it using DBMS_OUTPUT.PUT_LINE statement, which will give us a result of 123. We can also call it from SQL as SELECT ABS -123 FROM DUAL for a similar result. There are character functions like LPAD, which left pads the character argument passed in to make it a certain length. Similarly, LTRIM is a function you can use to say trim spaces on the left of a character. Here in this code snippet, we are calling the UPPER function to convert a passed character literal, Test, and assigning it to l_char variable. Then we print it later using DBMS_OUTPUT. To get a result, in this case, UPPER case Test. We can call it from SQL also directly as SELECT UPPER Test FROM DUAL for a similar result. Then there are DateTime functions. Again some of which we looked in the Part 1 course, like the SYSDATE function, which returns the current date, SYSTIMESTAMP function, which returns the current time stamp. In this code snippet, we are first calling the TO_DATE function to convert a character literal 10-FEB-2014 to a date using the TO_DATE function. The second argument of the DD-MON-RRRR tells the compiler the format of the date character literal to help with the conversion. Then we use the date returned by this function in another function called ADD_MONTHS where the second parameter is the number of months to be added, here 1, which we assign to l_date, and print to get a result of 10-MAR-2014. We can call it from SQL also, similarly. Many functions can be called from SQL directly, however there are some conditions a function has to pass to make it eligible to be called from SQL. We will take a look at that later in the module about calling functions from SQL. Oracle also gives us the ability to define our own functions using PL/SQL. In this module we will focus on those.

Defining Functions

The privileges needed to create and execute functions are the same as for procedures. Even though it says procedure in these privileges, they are for both procedures and functions. In the code snippet, we are giving these privileges for the demo user. You need CREATE PROCEDURE privilege to create procedure or a function in your own schema, CREATE ANY PROCEDURE to create a function or a procedure in any schema, ALTER ANY PROCEDURE to alter a function or a procedure in any schema, and EXECUTE privilege to execute a function or procedure created by someone else. Let us examine the simplest way to create a function. It starts with the CREATE OR REPLACE function. OR REPLACE keyword is optional and just like for creating procedures, if you specify it, it will overwrite a previous declaration, and if there is none, it will simply create a new function. If we do not use it, and you have an existing function, Oracle will error out with an object name already exists error, requiring you to drop the existing function first and then creating it. Using OR REPLACE is very convenient and I prefer to use it. That is followed by the schema.function name. You need to specify the schema only if you are creating a function in other schemas, otherwise we need not specify it and it will default to your current schema. Next is the RETURN class. A function, unlike a procedure, has to return a value. It can be a simple data type like VARCHAR2 or Date, or a more complex one like a record or a collection type. Next is the declaration section. Unlike the anonymous block, there is no explicit declare keyword. You can declare variables, cursors, exceptions, etc., over here. In order to find out more about these, please refer to Part 1 of Oracle PL/SQL Fundamentals course. Next is the BEGIN keyword, which marks the end of the declaration section and the beginning of the execution section. Here, you write the business logic. You return back the data type with the function declaration state it will return back. Next is the optional EXCEPTION section where it catches any exceptions. Notice that if you're handling the exceptions and not raising them further, using the raise keyword, then you need to return an appropriate value from the exception handler too. If you miss doing that, the function with still get compiled with no errors, and there will be no problem if the function completes normally and returns back a value, but if an exception is raised and handled by the exception handler, and there is no raise keyword, as well as no values that are turned over there, then Oracle will raise a runtime exception of ORA-06503 with a message function returned without a value. This is the simplest form of defining a function. We will take a look at how to pass parameters to functions and procedures in the next module. We will also look at keywords like DETERMINISTIC and PARALLEL_ENABLE, which can be used with functions in a later module when we talk about calling a function from a SQL statement. Let us take a look at a simple function example. Here is a function, which returns the count of employees in the IT Department. We start the declaration by stating CREATE OR REPLACE FUNCTION get_emp_count, get_emp_count is the name of the function. Then we say the RETURN NUMBER, indicating that this function is supposed to return a number, followed by the AS keyword. Next we declare a CURSOR to fetch the dept_id or department named IT. We declare it as CURSOR cur_get_dept_id IS SELECT dept_id FROM departments WHERE dept_name is IT. We declared l_dept_id to fetch the results of the cursor and make it the type departments.dept_id%TYPE. We declared l_count to hold the result of employee count for the department. Next, we end the declaration section and begin the execution section with the BEGIN keyword. First, we OPEN the cursor, cur_get_dept_id, we FETCH the results of the cursor INTO l_dept_id, then we CLOSE the cursor. After having obtained the department ID, we now get the count of employees by issuing SELECT count* INTO l_count FROM employees WHERE emp_dept_id is equal to the l_dept_id, which we just fetched. We finally return the result as a RETURN l_count, which is a number type, which the function is expected to return. Next we have an EXCEPTION handler section with the WHEN OTHERS exception handler to catch any unexpected errors. Here, we output the SQL error message and the error stack using the DBMS_UTILITY.FORMAT_ERROR_BACKTRACE function. We then use the RAISE keyword to raise the error to the calling client. If we did not have the RAISE keyword and an error was raised, Oracle would have given a runtime exception of ORA-06503 with the message function returned without a value.

Compiling & Executing Functions

We can compile the function by pasting or tapping the function in SQL*Plus followed by a slash, or by typing it in SQL worksheet in SQL Developer and then pressing the Run Script button. We will see that shortly in the demo. If you have saved the function in a file, say get_emp_count.sql in the C:\Demo directory, then, again like procedures, we can call that with the at sign followed by the full path name of the file and hit Enter in SQL*Plus, or by clicking Run Script in SQL Developer. You can also compile an already existing function like get_emp_count by doing ALTER FUNCTION get_emp_count COMPILE. On the topic of compilation, let me briefly talk about native compilation and PL/SQL optimize level settings, which can help improve the performance of your function. I will also show you how to enable your function for debug. We talked about these in detail in the Procedures module, so I will not go in much detail over here. Native compilation compiles your code in the native C mode versus the default interpreted mode, which allows Oracle runtime process to directly run the code without interpreting it, thus improving performance, sometimes considerably. You can set the PLSQL_CODE_TYPE, which controls compilation level to NATIVE using ALTER SESSOIN SET PLSQL_CODE_TYPE equal to NATIVE, and then compile the function as ALTER FUNCTION get_emp_count PLSQL_CODE_TYPE equal to NATIVE to compile it in the native mode. PLSQL_OPTIMIZE_LEVEL is another parameter, which can make the compiler work hard to optimize your code during the compilation process. For instance, avoiding unnecessary assignments and computations, inlining program calls, and other optimizations. The higher the level, the better it is, but I recommend keeping it at least at level 2. You can do it for your session by the command ALTER SESSION SET PLSQL_OPTIMIZE_LEVEL equal to 2. After this, the programs like functions and procedures you will compile in your session will get this optimization level during compilation. These are a couple of nice ways to optimize your code and make it more performant without having to involve any work or code changes at your end, and I highly recommend using these. Lastly, at some time or the other, you will have a need to debug a program unit. You cannot set breakpoints and debug using SQL Developer unless you compile your program unit in the debug mode. ALTER FUNCTION get_emp_count COMPILE DEBUG will compile it in the debug mode. You should do these only for the programs you need to debug and then compile them back in the normal, or non-debug mode, as the debug mode can slow performance, and also cannot take advantage of native compilation. Like the procedures, compiling functions can lead to errors and warnings too. The discussion of errors and warnings we had for procedures is also applicable for functions, and so we will just briefly talk about them over here. Some conditions which can raise errors are syntax errors or invalid object names being referred in the function. Starting with version 10g, Oracle can also give us warnings. The warning categories are severe, performance, and informational, and these categories can be enabled, disabled or treated as errors. So the compiler can help us catch informational situations like unreachable code, or give us performance warnings for unnecessary bind conversions. The commands to set them are the same as we saw in the procedure module. For example, we can use ALTER SESSION commands to set the warning levels to be enabled for the session. We can use the ALTER FUNCTION command to compile get_emp_count function, specifying the warning levels as ENABLE for PERFORMANCE, ERROR for SEVERE, ERROR for the PLW warning code of 06002, and reuse the settings from the last execution for the remaining parameters like informational, which are not specified. So as you can see, Oracle gives us a lot of control and flexibility in specifying these. Warnings or errors, if any, can be reviewed by using SHOW ERRORS command in SQL*Plus and SQL Developer. Another way of setting warnings is using the dbms_warning package. Call dbms_warning.add_warning_setting_category ALL, ENABLE, SESSION will enable it for the session. Executing the function is a little different than executing a procedure, because a function returns a value and we need to cast that value somehow. We can call a function from a PL/SQL block and another subprogram like a procedure or a function. So first, we see a code snippet of using an anonymous block where we have declared a variable l_return of type NUMBER to hold the results of calling the get_emp_count function. Since the declaration of the function says that it returns a number, we declare a number to hold its result. The name can be anything we want to be and it does not have to be the name of the variable returned from inside the function. We could have also declared here l_return is of type VARCHAR2 and Oracle would have implicitly converted the return number value to a VARCHAR2 and assign it to l_return. But of course it is extra work we are making Oracle do, and we should avoid such unnecessary conversions. If we had declared l_return as another data type, which Oracle cannot implicitly convert the return value to, say a date, then Oracle would have given an error, ORA-06550, expression is of the wrong type. Inside of the execution section, we invoke the function and assign its return value to l_return. This is the same way you would have called this function in another procedure or another function. Running this block will give us the return value, say 1. Functions can also be called in SQL statements if they qualify certain conditions. We will talk about those in detail later in the module about calling Oracle functions from SQL. So we can call our function, get_emp_count as select get_emp_count from dual to give us the same result of 1. These are the most common ways of calling functions. Let us look at another way of calling functions, which is not that commonly used. We can also call a function using the EXEC or EXECUTE command using bind_variables as _____ to the function call. Bind_variables are variables you can declare outside of PL/SQL using SQL commands for basic types like VARCHAR2, number, date, etc., as well as REF CURSOR types, then you refer to them later with a colon sign in front. So in this code snippet we declare a bind variable as VARIABLE l_return of type NUMBER. Now we run the statement EXEC :l_return equal to get_emp_count, EXECUTE :l_return equal to get_emp_count is another equivalent way to call the function get_emp_count in SQL*Plus or SQL Developer worksheet to get the result in l_return bind_variable. After this, we can see the value of the bind_variable using the PRINT:l_return statement, which will give us a value of 1. In the next code snippet, I have shown how you can refer to a bind_variable declared in SQL*Plus or SQL Developer inside a PL/SQL block. Here again we us the colon in front of the bind_variable name inside PL/SQL to refer to it. Here we have assigned the value return by get_emp_count to :l_return. Then outside the PL/SQL block, we can get its value by PRINT:l_return statement. This is how you can use bind variables inside and outside of PL/SQL blocks. This way of execution of functions, however, is not very common, but I just wanted you to know about it if you see it in some code you are maintaining, or you have a need to use them this way.

Dropping & Terminating Functions

We can drop a function simply by using the command DROP followed by the function_name, like DROP get_emp_count. Let us talk about the different ways a function can be terminated. The first case is for normal completion. If there is an exception raised during the function execution then like here it will execute all the lines of code, print the statement Finished Successfully, and then the return statement will send the result of the function back to the calling environment. If, however, an exception is raised during the execution of the function, the control flows from the point the exception is raised to the exception handler section. Here, an exception is raised since we are trying to fetch dept_name, which is a character to a number variable, so all the statements in the execution section beyond the point the exception is raised are not executed, and the execution flows to the exception handler section. Inside the exception handler section, as a good programming practice, we check if the cursor is still open, and if so we close it reclaiming memory. In our example here, the FETCH statement caused the exception to be raised, not giving a chance for the CLOSE cur_get_dept_name statement to be executed, leaving the memory area open. We are also raising the exception to the calling client using the RAISE statement. If the exception handler section is not further raising the exception, then it needs to return an appropriate value back to the calling client, otherwise Oracle will raise an error, ORA-06503 with a message, Function returned without a value. You can also explicitly end the execution by the return statement. You're not limited to having just one return statement, but you can have multiple return statements. As shown in this code snippet, I have a function get_teir, I have declared l_salary a NUMBER variable and given it an initial value of 50000. Inside the execution section, I'm checking for the value of l_salary, and if it is less than 40000, I'm returning 1, if it less than 60000, I'm returning 2, and for all other values, I am returning 3. Notice here I have 3 return statements, so since the condition l_salary less than 60000 were valued to true, the second RETURN gets executed, taking the execution flow out of the function to the calling client. The last DBMS_OUTPUT outputting the final completion status never gets executed. In some situations you might have no other option but to do it this way, but I try to avoid having multiple return statements in the function if I can as it leads to a kind of spaghetti code, and I have to look really hard for all possible exit points to see what code will or will not get executed for certain conditions. I rather prefer to code it as shown in the second snippet where I have declared an additional number variable called l_return, and inside the IF ELSIF clauses I am assigning it the tier values. I print the final status of the program and then RETURN the l_return at the end. This makes it more readable in my opinion, and is a much cleaner way to code.

Demo

In this demo we will take a look at how to create and compile a function, as well as how to execute it. We will demonstrate how to see the errors, if any, and set the warning levels. Here I have a SQL worksheet open where I have a function, which returns a tier level 1, 2 or 3 for a given salary. I have typed in create or replace FUNCTION get tier RETURN NUMBER AS, and then declared 2 variables, l_salary of type NUMBER with an initial value of 50000, l_return will hold the results of tier evaluation. The BEGIN keyword ends the declaration section and begins the execution section. Here we have an IF clause comparing the l_salary value. If it is less than 40000, we assign l_return a value of 1, if it is less than 60000, we assign it a value of 2, ELSE we assign it value of 3. At the end, we print a message, Finished Successfully, with the value of l_return and return it back to the client. Then we have an EXCEPTION handler section where we have a WHEN OTHERS handler, we are using DBMS_OUTPUT, we print the SQL error stack and the error backtrace. We can compile it by clicking the Run Script button. It gets compiled, but the compiler log opens up, giving us four warnings. If you recall that we can turn the warning on by going to Tools, then Preferences, then we expand the Database node, go to PL/SQL Compiler, and over here we have set our warnings to be enabled for all the categories. You could have also done it using ALTER SESSION set PLSQL warnings equal ENABLE ALL command, or using the DBMS warning package as we saw in the Procedures module. Let us now look at the warnings by clicking on the Log window. The first warning is for the AUTHID clause, which defines the privilege set the function runs under, the definer or the executor of the function. We will talk about it in a later module on rules and privileges. The second warning is that we have not returned a value in line 18, or the exception block, which can lead to a runtime error of function returned without value in case an exception is raised. We can toggle the lines on and off by going to the side pane, right-clicking, and saying Toggle Line Numbers. We can put a RAISE statement in the exception handler to negate to the calling client that an error has occurred. That, or we could have put a return statement like RETURN 0 as a part of our coding logic to indicate to the client that an error has occurred. The next two warnings are for unreachable code, as the Oracle compiler configured that since we have assigned a value of 50000 to l_salary, which is not changed anywhere after that, the IF clause on line 6, and the ELSE clause on line 10 will never get executed. That is very smart. Let us put the raise statement in the WHEN EXCEPTION handler now. We will let the AUTHID and the unreachable code warning stay for now. When we talk about passing parameters later, we will see how to better implement it by passing in a salary parameter. Let us run the script again. We are left with the warnings for the AUTHID clause and the unreachable code, which we will ignore for now. If on the left in the navigation pane, we expand the Functions tree, you will see our function over there. Let us double-click it and open it. You can make changes inside here and then you can click on the Compile button to compile it again. We can also compile for debug here by clicking the Compile for Debug option. This will make the icon change to a green color indicating that this function is compiled in the debug mode. You could have also done it from a SQL Developer worksheet by typing ALTER FUNCTION get_tier COMPILE DEBUG. We can also create a function by right-clicking on the Functions node and selecting New Function. This will open up a new window where it tells you the schema in which this function is going to be compiled. You can select another schema from the drop-down if you want to create it in another schema you have privileges on. You can define parameters, we will talk about parameters later. Then, there is the DDL window where it creates the basic function definition based on your input so far. Let's click OK. It creates a new window for the function where you can add code to the body, let us return HELLO, (Typing) and now let's compile it. You can also see our function in the Functions tree now. Let us see how we can run this. I will show you all the three ways of running it. The most common way of running it would be from the anonymous block or from within another function or procedure. Let us see how to run using an anonymous block. We have declared l_tier of type NUMBER, inside the execution block we invoke the get_tier function and assign the result back to l_tier variable. Then using dbms_output.put_line we print the value of l_tier. Let's run it. As expected, we see the output of l_tier is 2. The second way of running it is using a SQL statement. Not all functions can be run using the SQL statements, but this one can. We will talk about those conditions later. Here, we run it using SELECT get_tier from dual. Dual is a dummy table used for doing computations, running some functions, etc. Let's run it. As expected, we get the output of 2. The third way of running it is using bind variables to hold the result of the function. Let us first declare a bind variable as VARIABLE l_tier of type NUMBER. We can use EXEC to execute the get_tier function and assign its result to :l_tier bind variable. We can do it similarly using the EXECUTE statement. Finally, using the PRINT statement, we print the current value of l_tier. Let's run this. As expected we see a value of 2. We can open the function by clicking the GET_TIER in SQL Developer, and we can run the function directly from here. We have the Run button, let's click it. It creates an anonymous block for you and uses a bind variable to print the value. Let's click OK. As expected, we see the output, Finished Successfully l_return 2. How about if we create an error in the function? Say let us remove this semicolon after the number. Let's compile it again. The compiler log comes up and it reports an error. We also see a red cross in the navigator. If we try and run it using the anonymous block, we get the error that object DEMO.GET_TIER is invalid. Let us go back to the function and correct the error. Let's compile it again, and now it's back in the valid status. Let us now look at how to terminate a function using the return statement. Let us put the return in the ELSIF clause. Let us run it again. Now when we run it, it returns right from the ELSIF clause and the last DBMS_OUTPUT statement is never executed. Finally, let us see how to drop the function. We can simply do this by the command DROP FUNCTION get_tier. And now the function is dropped. If you refresh the Functions node, you will see that's no longer there.

Summary

In this module, we took a look at functions and why they are needed. We saw how they are different from procedures by always returning something back. This makes them appropriates to be created for use cases where we have to return something back to the calling client. We briefly touched upon errors and warnings, which can be raised during the compilation phase and how native compilation and PL/SQL optimize mode settings can make our code more performant. We looked at various function operations like creating, executing, and dropping them. We discussed various ways to terminate functions. Having one return statement in the end is much cleaner than having multiple return statements all throughout the code. Also, having appropriate return statements, and even the exception block, is also important.

Parameters in Procedures & Functions

Introduction

Hi, welcome to Pluralsight. My name is Pankaj Jain, and welcome to this module on Parameters. We are all familiar with the concept of customization. We like to customize our house, our cars, or coffee, our sandwich, you name it, to meet our specific tastes and requirements. Typically it involves starting with a prebuilt product and replacing or moving a few things around to meet our needs. Oracle provides us with the ability to pass parameters to procedures and functions, to customize their behavior to meet our business needs. Parameters allow us to extend the reusability of procedures and functions by not having to duplicate a majority of code or logic, which stays constant, for the small portion with changes. It also prevents us from hard coding values in our code. Oracle provides us with a lot of flexibility and control when passing parameters, which greatly enhances the power of stored program units. In this module we will talk about how to pass parameters, their modes, constraints on parameters, positional versus named notations, and how to make parameter passing a little faster using the NOCOPY hint. There is a lot of exciting stuff to talk about, so let's get started.

Formal vs. Actual Parameters

Parameters can be passed to both procedures and functions. The general syntax for passing parameters is in the header section of the declaration of a procedure or a function. After the function or procedure name, prefixed by the optional schema, you specify the parameters with a comma separated list within parenthesis. Each parameter starts with a parameter name, followed by the parameter mode which can be IN, OUT, or IN OUT, we will talk about them shortly, followed by the parameter datatype. You can use the scalar data types like number, date, character, composite data types like records, collections, ref cursors, etc. Being able to pass around collections of data fetched in one program unit to another program unit through parameters can help in centralized data retrieval and efficient information exchange. You can also provide default values for parameters using the colon equal to sign, or the default keyword followed by the default value. For example, here is the start section of the definition of a function get_tier. It starts with CREATE OR REPLACE FUNCTION get_tier, then we open the parenthesis to define an input parameter p_salary in the IN mode of type NUMBER. I generally like to prefix my parameter names with a p prefix. That helps me with immediately identifying them in my code later on. They are import parameters versus locally defined variables. Parameters can be passed in several modes. The IN mode allows us to pass input to procedures or functions, the OUT mode allows the procedures or functions to return something back to the calling client, and the IN OUT mode facilitates both passing in information and getting something back. You can have multiple parameters of each type, which can pass in the PL/SQL program unit, but generally if the parameters are getting more than four or five, then I think it gets a little complex managing, as well as using them. In such cases, I prefer to combine them as a single record type and pass one parameter instead of many. That keeps it simple to understand and use. Parameters can also help you in creating overloaded program units. That helps you build friendly APIs with the same name, which act based on the context of data passed into them. We will see how to pass parameters of record types and also talk about overloaded program units when we talk about packages. Before we talk in detail about each parameter mode, I also wanted to introduce you with a concept of formal and actual parameters. Formal parameters are the variables declared as parameters in a subprogram definition. For instance, here is the beginning of the procedure definition CREATE OR REPLACE PROCEDURE update_emp, which take in p_dept_name parameter. Here, p_dept_name is the formal parameter, which will be referenced by this name inside the update_emp procedure. Notice that I do not specify any constraints to the datatype before formal parameters, as in here we are just declaring it to be a VARCHAR2, and not specifying a constraint, like VACHAR2(20) or VARCHAR2(30), it gets the constraints from the actual parameter. We can also declare the formal parameters using the table name.table column %TYPE syntax like the employee.emp_dept_id%TYPE we have used here. So here they derive their datatype from the table column. For numeric types, they derive their size constraint from the table column, but for character types they still derive their size constraints for the actual parameter. So what are actual parameters? Actual parameters are the variables or expressions passed from the calling client to the subprograms. They contain the values passed to the procedure or a function when it is called, and they also get the results back when the procedure or function finishes based on their mode. So here, in this code snippet, we have declared l_dept_name as VARCHAR2(60), which is the actual parameter. Then in the execution section, update_emp procedure is called, followed by parameter p_dept_name is assigned the actual parameter l_dept_name. Inside the procedure p_dept_name is referred to, and if p_dept_name was of type OUT, or an OUT parameter, it would have also been assigned value inside a subprogram, which would be copied back to the actual parameter l_dept_name upon completion. You should take care that the data type of the formal and actual parameters are the same, if not, PL/SQL will follow the normal rules of data type conversions during the assignment process, and if the data types cannot be implicitly converted, say a date into a number, it will raise errors. Further, these conversions would cause extra work to be done by Oracle and should be avoided to keep our code performing at its best.

Parameter Modes

Let us understand the different modes of passing parameters. First is the IN mode. This is the default mode of passing parameters. If you do not explicitly specify a mode, this will be the mode it will be passed in. The actual parameter value is passed in, and inside the procedure or the function, the parameter is in the read only mode, and behaves like a constant. What this means is that you can only read its value, but if you try to write to it, Oracle will raise an error. So in this code snippet we have declared a FUNCTION update_emp, which takes in two parameters, p_emp_id with the IN mode specified of type NUMBER, and p_dept_name of type VARCHAR2. Notice I have not specified the mode here, and so it defaults to the IN mode. The function returns a NUMBER. Then we have a CURSOR, cur_get_dept_id, where we are selecting the dept_id from the departments table for the passed department, p_dept_name. We declare l_dept_id of type departments.dept_id%TYPE to hold the result of the cursor. Inside the execution block you open cur_get_dept_id, FETCH it into l_dept_id, and then CLOSE it. Then we UPDATE the employee table and set the dept_id with the fetched l_dept_id, WHERE emp_id is the passed p_emp_id. We then COMMIT our changes and RETURN a successful status of 1. In case of an error we have an exception block with the WHEN OTHERS exception handler where we print the error message, ROLLBACK the changes made, and RETURN a familiar status of 0 to the client. Let us see how we can pass parameters. In this code snippet we have an anonymous block where we have declared l_emp_id of type NUMBER 10, and given it an initial value of 50. L_dept_name is of type VARCHAR2(60), and given an initial value of IT, l_status to hold the result of the function invocation is of type NUMBER. In the execution block we assign to l_status the value returned by calling the function update_emp, we pass in parameters l_emp_id and l_dept_name. L_emp_id is assigned to p_emp_id, and l_dept_name is assigned to p_dept_name similarly. Inside the function, their value gets read at various places, their done value is assigned to l_status, and no changes made to the values of actual parameters l_emp_id and l_dept_name. Note, if inside the function we try and assign a value to p_emp_id, Oracle will raise an error during compilation that expression p_emp_id cannot be used as an assignment target. Since the IN parameters are read only, you can also pass literals as parameters as shown in this code snippet where we pass 50 and IT directly as input parameters. In the OUT mode, the actual parameter value passed to the procedure or function is ignored. It is assigned to the formal parameter as an uninitialized PL/SQL value, and thus has a value of null. Inside the subprogram you can read and write against the formal parameter. Of course, reading it initially will result in a null value. Inside the procedure or function, you assign a value to the OUT parameter, which is then copied over to the actual parameter. Since we need a variable to receive the value returned by the OUT parameter, we cannot pass a literal to it. A constant variable, by definition, is constant and its value cannot be changed, so it also cannot act as a receiver of an OUT parameter. So in this code snippet, we have the same function update_emp we looked at earlier. It takes p_emp_id and p_dept_id for parameters. In addition, it now also takes p_location as an OUT mode parameter of type VARCHAR2. Inside the execution section, we first read a value of p_location and print it. We execute the UPDATE to the employee table, updating emp_dept_id to p_dept_id, for emp_id equal to p_emp_id, and then using the RETURNING clause, get employee location, and assign it to p_location. You could assign value to the OUT variable anyway you like. We then COMMIT and RETURN 1 for status code. Now in this code snippet we declare l_emp_id with a value of 50, l_dept_id with a value of 1, and also declare l_location of type VARCHAR2(10) with an initial value of CA. Inside the execution section we call the update_emp function passing the three parameters in order and assign the return value to l_status. We then print the value of l_location and l_status. So even though we are assigning a value to l_location initially, it will be passed in as a null value to p_location. Running this block will give us the result of location initially with the value of null, return value of WA for l_location, and l_status as 1. So this way we are actually returning back two values from the function, l_status which it returns, and l_location, which is an OUT parameter. We cannot pass a neutral value of CA for p_location parameter as we need a variable to hold the return value. The IN OUT mode is a combination of the IN and the OUT mode. So like the IN mode, the actual parameter value is assigned to the formal parameter and passed inside. And like an OUT parameter, it is both read and write. The results assigned to the IN OUT parameter inside of the procedure or the function are copied back to the actual parameter in the calling client. Just like OUT parameter mode, you cannot pass literals or constants for an IN OUT parameter to a procedure or a function, as it needs a variable to hold the return value. So continuing with the same example we have been seeing, let us extend update_emp to also have an IN OUT parameter. To demonstrate usage in a procedure, let us write it as a procedure instead this time. If you have been following along trying these examples, you will have to drop the function update_emp first before you can create the procedure update_emp as Oracle will complain that an object with the same name already exists. Here, along with p_emp_id, and p_dept_id input parameters, p_location OUT parameter, we are passing an additional parameter, p_status, in the IN OUT mode of type NUMBER to hold the final status. In the execution section we update the employee table, updating emp_dept_id for p_emp_id, and then using the returning clause get emp_location and assign it to p_location. We assign the value of 1 to the IN OUT variable p_status. Inside the EXCEPTION section in the WHEN OTHERS handler, we assign p_status a value of 0. Now in this code snippet, we declare l_emp_id with a value of 50, l_dept_id with a value of 1, l_location of type VARCHAR2(10) with an initial value of CA, And l_status as a NUMBER with an initial value of -1. Inside the execution section we call the update_emp function, passing the four parameters in order. We then print the value of l_location and l_status. So for l_status, the initial value of -1 will be passed inside update_emp procedure, and it can be read there as such. It gets assigned a value of 1 on successful completion and 0 on unsuccessful completion. Running this block will give us a result of p_status Initially -1, and Location with the return value of WA, and l_status with the return value of 1. So this way we are returning back values using a procedure. We cannot pass a literal value of -1 for p_status parameter as we need a variable to hold the return value.

Passing by Reference & Value

So what is the effect on the actual parameter value in case an exception is raised inside a stored subprogram? At this point let me talk about the semantics of passing parameters to a subprogram. It can be done in two ways, by reference or by value. When you pass by a reference, then a pointer to the actual parameter is passed on to the formal parameter instead of the actual parameter value. So any modifications done to the value of the formal parameter, inside the procedure or the function, directly changes the value of the actual parameter. This is generally a faster operation, especially if you are passing around large collections as it avoids the additional step of copying data first to the former parameter on the way in, and then back to the actual parameter on the way out. By default, the IN parameter is passed in the reference mode. The drawback of this approach is that if there is an exception raised inside of the procedure or the function, then any changes made to the actual parameter will stay. The other way of passing parameters is by value, where the value of the actual parameter is copied to the formal parameter on the way in and copied back from the formal to the actual parameter on the way out. This is the default mode for the OUT and the IN OUT parameter modes. The advantage of this approach is that if there is an error raised inside the subprogram, and if there is no exception handler, or the exception handler raises it further, the value of the actual parameter stays unaffected. Let us first see the effect of an exception inside a subprogram when the OUT and IN OUT parameters are passed in the default copy mode, but we do have an exception handler in sight. Here, we have the same code snippet, but we have added a number variable called l_number. In the execution section, we UPDATE the employee table and returned emp_loc in the OUT parameter of p_location. We assign p_status a value of 1. In order to create an error situation, we are assigning a value, CHAR, to the number variable. This will raise numeric or value error causing the execution to flow to the exception block. Here, errors are printed out, the update is rolled back, and p_status is assigned a value of 0. After that, the execution resumes normally to the client block and the values of p_location and p_status at this point are copied over to the actual parameters. If this procedure is run using the anonymous block where l_location is the OUT parameter and l_status is the IN OUT parameter, in the output for l_location we will see a value of WA as even though the update was rolled back, the return value from the update was copied to p_location, and copying a value to a variable is not rolled back by the ROLLBACK statement. L_status shows a value of 0, which we are assigned in the exception block, so it is important to note that when we are not raising the exception further, and it is handled normally, we need to revert back the values of the OUT and IN OUT parameters ourselves. We could have also set the value of p_location to null in our exception block in order to revert the assignment we had made to it inside the procedure. Another approach, which sometimes is better, is to further raise the exception inside the exception handler of the procedure or the function. In this case, Oracle will automatically rollback the values assigned to the OUT and IN OUT parameter types. This would also be the case if we did not have an exception handler inside the procedure. This is one of the advantages of having the parameters passed by value as the calling client would not see the changed values in case of an exception. So, if we run this code snippet again, then update_emp will raise the exception, which we are handling inside the exception handler. There we are raising it again, using the RAISE keyword, which makes it go to the calling clients exception handler section where printing the value of l_location will give us the original actual parameter value of CA, and l_status has the original actual parameter value of -1, as Oracle automatically reverted back the changes to these parameters.

NOCOPY hint

Sometimes, when passing large collection types as parameters to procedures or functions, passing them by reference makes the code faster by avoiding the extra work of copying the actual parameters to the former parameters on the way in and back to the actual parameters on the way out. NOCOPY is a compiler hint, which can be passed to an OUT or IN OUT parameter to ask the compiler to pass the parameters by reference and not by value. Its syntax is parameter_name, parameter_mode, NOCOPY, followed by the parameter_datatype. So here in this code snippet we have given the NOCOPY hint to p_location, which is an OUT parameter, and p_status, which is an IN OUT parameter. Again we assign values to p_location as a part of RETURNING clause of the update statement. P_status is assigned a value of 1, then we create an error by assigning the value CHAR to l_number. This will cause the exception to be raised and inside the exception handler we are raising it further by the RAISE statement. Had these been passed by value, Oracle would have not modified the values of the actual parameter, but since these are pointers to the actual parameters, the values of the actual parameters are also changed. So in this next code snippet, where we are executing the procedure in an anonymous block, the exception raised and the procedure is caught in the WHEN OTHERS handler of the anonymous block where we print the value of l_location and l_status. Even though the exception was raised inside the procedure, the values assigned to p_location and p_status were not reverted, and since these were pointers to l_location and l_status, their values are now WA and 1. So the NOCOPY compiler hint gives us the performance gain, but comes with this side effect you must be aware of. NoCopy is a compiler hint and it is not necessary that the compiler will follow it always. Some situations it will ignore this hint are, if there is a data type mismatch and there is an implicit conversion of the actual parameter to the formal parameter, say converting an actual parameter of type number to a formal parameter of type corrector. If the actual parameter has a scalar data type, like VARCHAR2, with a not null constraint, or if it is a numeric data type with the range, precision or scale constraints. However, this restriction does not apply to a character variable constrained by length as long as it is nullable. If the formal and actual parameters are both records, and they were declared either implicitly or using %ROWTYPE and the constraints on the individual fields of the records are different. If instead of an entire collections, just an element of it is passed, we have not covered collections yet and we will see them in a later course, or in case of a remote procedure call, say when the procedure is called over a DWS link.

Demo:Parameter Modes & NOCOPY

In this demo, we will demonstrate how to pass and use parameters in the IN, OUT, and the IN OUT mode, as well as demonstrate parameters being passed by value and by reference using the NOCOPY keyword. Here is the procedure update_emp, which takes in p_emp_id in the IN mode of type NUMBER, p_dept_id in the default IN mode, p_location in the OUT mode of type VARCHAR2, and p_status in the IN OUT mode of type NUMBER. We declare a NUMBER variable l_number. In the execution block, using DBMS_OUTPUT.PUT_LINE, we'll first print the initial value of Out parameter p_location and the In Out parameter p_status. Next we update the employee table, setting the dept_id to p_dept_id, where the emp_id is p_emp_id, RETURNING the employee location in the OUT parameter of p_location. We set the value of the IN OUT parameter p_status to 1, indicating sexes. We COMMIT the change. Next we have an EXCEPTION section with a WHEN EXCEPTION handler, where we print the SQL error message, print the error backtrace, roll back the changes, and raise the error to the client. Let's compile this procedure. The procedure got compiled successfully. In this window, we have an anonymous block where we define actual variables l_emp_id of type NUMBER with a value of 50, l_dept_id of type NUMBER with a value of 1, l_location with an initial value of California, and l_status with an initial value of -1. Inside the execution section, we pass these parameters in order to the update_emp procedure, this will assign their value to the formal parameters. Then using DBMS_OUTPUT, we print the OUT value of l_location, returned back, and the IN OUT value of l_status. Then we have an exception handler section with a WHEN OTHERS exception handler. We first print the error message using DBMS_UTILITY.FORMAT_ERROR_STACK, and then we print the value of l_location and l_status in the EXCEPTION block if in case an exception is raised. Let us run this. We notice in the output, as expected, Out parameter p_location initially was passed as an uninitialized value of null to the procedure, and the In Out parameter p_status has an initial value of -1 passed in. Then upon procedure completion, l_location gets a final value of WA and l_status a value of 1. Now here is our procedure again, and now let's try and assign p_emp_id, an IN parameter of value inside the procedure. Let us compile the procedure again. The procedure compiles with error, which is P_EMP_ID cannot be used as an assignment target since it is a read only, IN mode parameter. Let us comment it. Now, let us try and introduce an error by assigning l_number, a NUMBER variable, a character value CHAR. Let us compile it again. This time it compiled successfully. Let us go to the other window and let's run the procedure again with the same values. Again the p_location Out variable has an initial value of null, and In Out parameter p_status has an initial value of -1 in the beginning of the procedure, but then assignment of a character value to a number variable raises the exception numeric of value error, causing it to go to the WHEN OTHERS handler where a further raise sends it to the WHEN OTHERS handler of the calling client. There, we print using DBMS_OUTPUT the values of l_location and l_status inside the exception handler. Inside the exception handler, the value of l_location is CA and the value of l_status is -1. So since the OUT and IN OUT parameters were passed in the default value mode and the exception was raised to the client, Oracle automatically rolled back the values and the actual values remain unaffected. Now let us modify our procedure to pass the OUT parameter p_location and the IN OUT parameter p_status with the NOCOPY hint. Let us compile it again. The compilation was successful. Now let us go back to our client and run it again. This time the sequence of operations is the same as the last time. Again, the Out parameter p_location initially has a value of null, and the In Out parameter p_status has an initial value of -1, however, the output statements inside the exception handler of the client print that inside the exception l_location has a value of WA and l_status has a value of 1. So since the values were passed by reference, or as pointers to the actual parameters, the changes directly affected the actual variable values. NOCOPY hint can give you better performance, but this is one of the side effects you must understand and account for in your code.

Positional, Named & Mixed Notation

In all the examples we've looked so far, we were passing the parameters by position, so our actual and formal parameters were mapped based on the order we passed the actual parameters to the procedure or the function. For example, here is a procedure update_emp, which has four parameters, p_emp_id and p_dept_id are IN parameters, p_location is OUT parameter, and p_status is IN OUT type. We're not showing the body here. Now in this anonymous block, we have four actual parameters, l_emp_id, l_dept_id, l_location, and l_status, their data type matching the corresponding former parameters. In the update_emp procedure we are passing them in sequence, l_emp_id corresponding to p_emp_id, l_dept_id corresponding to p_dept_id, l_location corresponding to p_location, and l_status corresponding to p_status. Passing the parameters this way keeps our code compact with no mappings to be defined. The other advantage of this approach is that it is not affected by the changes in the name of the formal parameters as long as the order stays the same. So the client code does not have to be rewritten in this situation. The drawback of this approach is that the readability of the code is not very good. We are relying on good names for actual parameters to help us figure out what parameter was passed in. Secondly, if the order of the formal parameters change, that'll cause our code to break and we will have to update all our client calls to reflect the new order. The other style of passing parameters is by name, where in our client call we map the formal parameters to the actual parameter. This approach is definitely more verbose, but it also helps with the readability as it clearly tells us the mapping with no ambiguity. Also, another advantage of this approach is that if you reposition the formal parameters, the client code need not change. Notice, here the order of passing the parameters is not important as the mapping resolves the association. Here we are passing, for instance, p_location as the first parameter, which is third in the list of parameters. Also, if you add more parameters for your procedure or your function later, and as long as they have default values, you need not change your client code. These new default value parameters can have any position in the list. We will talk about the four values shortly. The drawback of this approach is that if the names of the formal parameters are changed, then you have to change the client code to reflect the new names. Oracle allows you to have mixed notations too. So you can mix positional with named as long as the parameters in the beginning are positional. So here in this code snippet, l_emp_id is passed by position for p_emp_id, and l_dept_id is passed by position for p_dept_id. P_status and p_location are passed by name notations being mapped to l_status in their location. You cannot have named notations first followed by positional notation. If you try and do this, Oracle will give you an error PLS-00312: a positional parameter association may not follow a named association. Whether you should use named or positional or mixed notation has no effect in the performance or how the code will process, it is purely a matter of style. Generally I like passing the parameters by position as this keeps my code compact. If there are too many parameters, then I like to switch to named notation to help with the readability. I always like to keep the parameters with default values at the end, as this gives me the flexibility to use named or positional notation as we will see next.

Default Values & Constraints on Formal Parameters

Let us now look at how to provide default values for parameters. Let us revisit the syntax of defining a parameter, which is param_name, followed by the param_mode, followed by the param_datatype, followed by the colon equal to, or the DEFAULT keyword to assign a default value. The default value can only be provided to parameters in the IN mode. So let us see the header section of a procedure update_info, which takes in three input parameters, p_emp_id of type NUMBER with a default value of 50, p_dept_id with a default value of 1, and p_bonus with a default value of 10%. We did not show the body of the procedure over here. Now if we do not want to pass values for the parameters, and the default values are good enough, then you can call the procedure just by calling update_info. Inside of the procedure, default values will be passed to the formal parameters. Of course you can provide your own values if you want, as shown in this code snippet where we pass our own values for l_emp_id, l_dept_id, and l_bonus, which will overwrite the default values when passed in. If you want to selectively pass values, say pass your values just for the emp_id, but want to use the default values for p_dept_id and p_bonus, then you can do it as shown in this block where we pass our value of 30 for l_emp_id and let the default values go for the other two parameters. But what if, say we have a procedure definition where p_emp_id has no default value and we have default values only for p_dept_id and p_bonus. If you want to pass default values for p_dept_id and p_bonus, we can simply call update_emp, passing a value for l_emp_id only, and the other two will take default values. That is why it is good to have default value parameters at the end, that way we can add more of these parameters at the end without having to change our client calls. What if we want to pass default value for the middle parameter only? Using positional notation we cannot do that, as p_bonus needs a non-default value. If your _____ does update_emp with l_emp_id as the first parameter and l_bonus as the second, Oracle will interpret l_bonus to be the p_dept_id as it sees it as a second parameter, and will apply a default value for p_bonus. Certainly not what we intended. So in this case, a named notation gives us the required flexibility since using the named notation we tell specifically that we are passing values for p_emp_id and p_bonus, and that the default value for p_dept_id should be applied. As we had talked briefly earlier that you cannot specify constraints on formal parameters and that the _____ from the actual parameters. This includes the range, as well as the not null constraints you might have defined on the actual parameters. So for instance, here are the actual parameters l_emp_id is a NUMBER and has a length of 10, l_location is a VARCHAR2 with a length of 6 with a NOT NULL constraint. These then constraints are also passed to the formal parameters. P_emp_id gets a constraint of NUMBER(10), and p_location a constraint of VARCHAR2(6). So inside of the procedure, initial assignment to p_location of value of length 4 has no problems. Further, p_location also gets a NOT NULL constraint from l_location, and if you try to make it NULL inside of the procedure, Oracle will raise errors. We can also declare the formal parameters using the %TYPE syntax. For instance, instead of saying NUMBER, we could have said p_emp_id is employee.emp_id%TYPE, and instead of VARCHAR2, we could have said p_location is employee.emp_loc%TYPE. So in this case for the number parameter, p_emp_id, it gets the NOT NULL constraint, as well as the length constraint from the database column. But for the VARCHAR2 parameter, p_location, it only gets the data type from the emp_loc column of the employee table where the constraint is still obtained from the actual parameter. So if we call this procedure using this anonymous block where l_location is defined as VARCHAR2(6), in that case, even though the emp_loc column is VARCHAR2 with a length of 2, it still gets the constraint of VARCHAR2(6) from the actual parameter and the assignment of a 4-character value of NONE will not result in an error. If the formal parameter is declared as a constraint numeric sub type, then the formal parameter will inherit the NOT NULL constraint if defined on the sub type, but not the precision and the skill. It will inherit only the range of the numeric base of the subtype, which will be the range of values it will support. If you want to refresh your knowledge of sub types, please refer to Part 1 course of the series. For example, here we have an anonymous block where we are declaring a SUBTYPE numsubtype IS NUMBER(2) with a length of 2 and a NOT NULL constraint. Then we are defining a local procedure. We will discuss local subprograms in detail in the next module, but for now just know that we can declare a procedure or a function, which is local to another procedure or function or an anonymous block. So here we have a local PROCEDURE, testsubtype, which takes in p_num input parameter of type numsubtype. It inherits just a NOT NULL constraint, but not the precision from the numsubtype. For its length it will allow the range of values supported by the number base type, we can test this by invoking testsubtype with a number 1234 with a length or precision of 4, and even though numsubtype has a length of 2, there will not be any errors and it will print it just fine inside the procedure. However, if you pass it a null, then Oracle will complain as the formal parameter inherits the NOT NULL constraint from the numsubtype. If we have declared our formal parameter as a character sub type, then only a NOT NULL constraint, if defined, on the subtype are inherited, but not the length or size restrictions. For example, here we have an anonymous block where we are declaring a subtype, charsubtype IS VARCHAR2 with a length of 2 and which is NOT NULL. Then we are defining a local procedure testsubtype, which takes in p_char input parameter of type charsubtype. So it inherits just a NOT NULL constraint, but not the length of 2 from the charsubtype. We can test this by invoking testsubtype with a character string TEST, which has a length of 4, and it will print it just fine inside. However, if you pass it as null, then Oracle will complain as the formal parameter inherits the NOT NULL constraint from the subtype.

Demo: Default Values, Positional & Named Notations

In this demo, we will demonstrate the use of passing default values to parameters, as well as using positional and named notation for calling the subprograms. We create a procedure, update_info, which takes in three parameters, p_emp_id with a default value of 50, p_dept_id with a default value of 1, and p_commission with a default value of 10. All three are passed in the IN mode and are of type NUMBER. Inside the procedure, using DBMS_OUTPUT, we print the initial value of these parameters received by the procedure. Then we update the employee table setting emp_dept_id to p_dept_id, emp_sal to emp_sal + emp_sal multiplied by commission percent. We divide it by 100 to convert the percent to an absolute commission value. We do this for emp_id equal to p_emp_id. Using DBMS_OUTPUT, we print the SQL%ROWCOUNT, which returns the number of rows affected by the update statement. We then have an exception handler section with a WHEN OTHERS handler where we print the error message, print the FORMAT_ERROR_BACKTRACE, ROLLBACK the changes, and RAISE the error further to the client. Let us compile this. The procedure got compiled successfully. Let us first run it without passing in any parameters. This way the default parameters will be passed into the procedure. Let us run it. As expected, p_emp_id gets a default value of 50, p_dept_id the default value of 1, and p_commission the default value of 10%. One row was updated. Now let us run it overriding all the values with the actual parameter values. So here we have assigned l_emp_id a value of 20, l_dept_id a value of 2, and l_commission a value of 5 in the declaration section, and in the execution section we pass these parameters by position to the procedure. Let's run it again. As expected, the formal parameters got the values assigned to the actual parameters overriding the default values. Now let us run it by just assigning an actual parameter value of 20 to l_emp_id. P_dept_id and p_location are not assigned any values and they should get the default values. Let's run it again. As expected, we see that the default value for l_emp_id gets overridden by the value of 20, which we passed in, but p_dept_id gets a default value of 1 and p_commission a default value of 10, updating 1 row. Since the last two parameters had default values, we could use positional notation. What if we want to override the values of p_emp_id and p_commission, but just want to pass a default value for the middle parameter, p_dept_id? We can do this using the name notation, so we declare l_emp_id of type NUMBER and give it a value of 20, l_commission of type NUMBER and give it a value of 5. In the execution section, using named notation, we map p_emp_id to l_emp_id, and p_commission to l_commission, thus letting p_dept_id get the default value of 1. Let us run it. As expected, we overrode the default value of p_emp_id to 20, p_dept_id got the default value of 1, and p_commission got the overridden value of 5, and 1 row was updated. So this is how named notation gives us flexibility of passing default values of parameters, irrespective of which order they are in the parameter list.

Summary

Oracle provides us with the ability to pass parameters to procedures and functions, which extends the reusability of stored subprograms and allows customization. IN, OUT, and IN OUT are the parameter modes, IN being read only, OUT passed back from the subprogram to the client, and IN OUT allows both the value to be passed in, as well as value to be returned back to the calling client. Passing parameters by reference, or as pointers, can enhance the performance of subprograms, especially when we are passing large collections, but can have side effects of OUT and IN OUT parameter modes being modified in the case of exceptions. IN parameter is by default passed by reference and OUT and IN OUT parameters by default passed by value. Positional notation helps keep our code compact. Named notation provides greater flexibility when the API is changing in terms of position of parameters, as well as when we want to pass parameters in the middle or beginning by default value. Default parameter values help provide meaningful values when omitted. The formal parameters get their constraints from actual parameters, or from table column %TYPE declarations, or from subtypes, something to be aware of and account for in the code in order to prevent runtime exceptions

Local Subprograms

Introduction

Procedures, functions, and packages are stored subprograms, as these can be stored in the database by name, and then can be called and consumed by many different client applications. Oracle also provides the ability to provide local subprograms. These are procedures and functions local to another stored procedure or a function, or an anonymous block. Creating modular pieces of code avoids repeating the same lines of code at several places; a single call to a modular program will execute the same logic consistently at all the places. Sometimes when the code is unique to a program, it might make sense to create a local modular unit to be used within the program only. Of course, there might not be many situations of this sort, but still it is important to know how to create such programs if the need arises, and to maintain existing pieces of code that might have local subprograms. In this module, we will see how to define local functions and procedures, as well as the scope and visibility of variables, and exception propagation when local subprograms are involved. Local subprograms are procedures and functions local to another procedure and function, or an anonymous block, declared in the declaration section. So, you can think of them as nested procedures and functions. These, however, are visible only to the block or stored subprogram in which they are defined, and their scope starts from the time you declare them in the declaration section to the end of the block or stored subprogram. So they lose their advantage of stored subprograms is being visible to any database application. I generally use them only if the code is unique to a block or subprogram and it will not be used anywhere else. Otherwise, if there is a need for a subprogram, I would rather define them as a stored subprogram like a procedure or a function visible to the entire database, allowing reusability across many client applications. The stored subprograms can also possibly be pinned in the shared pool and cached if they are used very often, and can improve performance. However, the local subprograms cannot be pinned. One thing to take care of is the location of these local subprograms; they need to be at the declaration section or be the last objects to be declared, otherwise Oracle will raise errors. These subprograms, like nested blocks, described in Oracle PLSQL Fundamentals Part 1 course, can access the parent variables, and can read and write to them. The variables defined in them override the visibility of variables of the same name in the parent block. If you have repeated lines of code in your block or program, which are called at many places within the program, then you might want to centralize them as a local subprogram. Then, instead of writing these lines over and over in several places, you just call the local subprogram. That way a consistent piece of logic is called at all the places, so they help in reusability, but only within the block or subprogram they are defined in. You can define multiple local subprograms and also overload them. We will talk about overloading in a later module, where we will have examples of this. Let us now take a look at an example to understand local subprograms better.

Defining Local Subprograms

You can define a local procedure or a local function, or both, inside both a stored procedure or a stored function. Here, let us take a look at an example of defining a local procedure within a stored procedure. It is the same procedure update_dept we looked at earlier. Here, we have a local variable, l_dept_id as departments.dept_id%TYPE, declared first, followed by a local subprogram displayed message. It takes in two parameters, the location of type VARCHAR2 to indicate the location when it is called in the code, and p_msg parameter, which is the message passed in. Notice, that it is the last thing to be declared, and also notice we do not have the CREATE keyword, but just start the declaration as PROCEDURE display_message within that parameter. Inside display message, we are just doing some fancy output of the location, followed by the passed message. This is probably not a good use for a local procedure, but I just wanted to show you the concept. From this point on, display_message is another identifier in the code, which has visibility from here to the end of the procedure. Later in the execution section, we execute all these lines by a single call to display_message. In the beginning, we call it the p location as before updating, and p_msg as Input Employee ID coordinated with the past employee ID. We do the update and then again execute those lines by a single call to display_message, this time with a location After Updating and p_msg as SQL%ROWCOUNT or the number of rows updated. So it helps avoid repeating the same lines of code over and over again. If we execute this procedure with an Input Employee ID of 10, the first call to display_message will print Before Updating Input Employee ID: 10, and the second call will print After Updating, Rows Updated: 1. Here is a code snippet where we'll define the same local procedure but now defined as a part of an anonymous block. Here the only difference we have made is that instead of passing p_emp_id, we have declared l_emp_id and given it a value of 10.

Demo: Local Subprograms

Let us look at the same example in action now. So here, we have the PROCEDURE UPDATE_DEPT, which takes p_emp_id as input parameter of employee.emp_id%TYPE. We declare a local variable, l_dept_id, and give it a value of 2. Now we start the definition of our local procedure as PROCEDURE display_mesage, with input parameters p_location of type VARCHAR2, and p_msg of type VARCHAR2 again. Inside of the procedure, we are just displaying using the output first, the p_location, and next the p_msg input parameter. We end our procedure with the END display message statement. And next, we begin our BEGIN procedure with the BEGIN keyword, and call the display_message local procedure passing in before Updating as the first location parameter, and Input Employee ID concurrently with p_emp_id as the second p_msg parameter. This will execute our local procedure and should display the formatted message. Next we update the employee table, setting the emp_dept_id to l_dept_id for the passed p_emp parameter. We call our local procedure again, this time passing the parameter as After Updating, as the p_msg parameter as Rows Updated concurrently with SQL%ROWCOUNT. Let's compile this. The procedure was successfully compiled. Now let us run our procedure, passing in employee ID 10 as an input parameter. As expected, we see the local procedure printing the two sets of messages. First, Before Updating Input Employee ID: 10, and the next says call at the end of the procedure as After Updating Rows Updated:1.

Exceptions, Scope & Visibility of Variables

Let us take a look at defining a local function inside a stored procedure. Here is a function called determine_tiers, which, for a given salary, gets through 11 tiers. We define the local variable, l_salary of type NUMBER, and give it a value of 50,000. We define l_tier to hold the tier information. Next, we define the local function, get_tier, which returns a number. Note, there is no creator or place in the beginning of the declaration of the function; we declare l_return of type number. Inside, it refers to the l_salary variable of the BEGIN procedure, and if it is less than 40,000, then l_return is assigned a value of 1. If l_salary is less than 60,000 then l_return is assigned a value of 2, and for all other cases a value of 3, then l_return is returned back from the function. This is followed by the EXCEPTION block where we have a WHEN OTHERS handler, where we print the error message and the FORMAT_ERROR_BACKTRACE, and then RAISE the exception. With the local function being the last thing to be declared, we start the execution section of the parent procedure, and here we assign the value returned by get_tiers to l_tier. It will assign it a value of 2, as the l_salary over here has a value of 50,000. Next, we change the value of l_salary to 120,000, and again call the local function get_tier and assign the value returned by it to l_tier. This time, the call will return a value of 3. So all the logic does not have to be repeated, and is just executed with one line to call the function. What if an exception is raised inside a local function? It will follow the same rules of exception propagation as followed by a nested block, which we saw in the exception module of department course. So say here, instead of assigning a value of 2, we accidentally assign a value of B to l_return. Now, when the procedure determine_tiers is executed, it will start off with a BEGIN keyword, and then go to the statement where we are assigning l_tier the value returned by get_tier. At this point, it will call the function get_tier. Inside the function, it will start evaluating the if clauses. If l_salary less than 40,000 will be false as the salary is 50,000, the ELSEIF clause of l_salary less than 60,000 will be true where it will try and assign a character value of B to a numerator type l_return. This will cause the ORA-06502 character to number conversion error. Since we have defined a WHEN of the EXCEPTION handler, the execution will jump there. Inside, we are putting a DBMS_OUTPUT statement, and then from there we are again raising an exception using the RAISE keyword. The RAISE keyword makes it jump to the EXCEPTION handler section of the outer block, where block, where again we are printing the ERROR and the ERROR_BACKTRACE, followed by another RAISE to raise the exception to the calling client. What if we have a variable with the same name inside the local subprogram? It will override the visibility of the parent variable. Here, we have declared a variable, l_salary, also inside the FUNCTION get_tier, which overrides the visibility of l_salary variable defined in the parent procedure. So the call to the function will always return 1 as it does not see the l_salary variable in the outer procedure, and l_salary of 30,000 in the inner block will satisfy the first IF of l_salary less than 40,000, returning a value of 1. This is a condition you need to be careful about. We saw earlier that the local variable of the parent subprogram is in scope for the inner subprogram. The local subprogram variables are out of scope for the outer procedure. The inner subprogram can read as well as write to the outer program variables. Here, we have returned the same procedure but made the local subprogram, get_tier, as a procedure instead of a function. Inside get_tier procedure, we directly assign a value to l_tier of the parent variable; it will again give us the same results when executed.

Demo: Exceptions, Scope & Visibility of Variables

Let us now see the concepts of exception and visibility of variables in action, with respect to local subprograms. Here is the same procedure we talked about, determine_tiers, which has two variables, l_salary of type NUMBER, given the value of 50,000, and l_tier is a tier in which the salary falls. We then define our local function, get_tier, which returns NUMBER, and inside it declares l_return of type NUMBER, which will be returned back. Inside the EXECUTION block, we check if l_salary is less than 40,000, then l_return is assigned a value of 1. ELSEIF l_salary is less than 60,000, then l_return is assigned a value of 2, otherwise, a value of 3. So, our local function can see the l_salary in the outer parent procedure; we return l_return. In the exception block, we have a WHEN OTHERS exception handler, where we are outputting SQL ERROR message and the error is stacked using the DBMS_UTLILTY.FORMAT_ERROR_BACKTRACE function. And then, we further raise the exception. We start the EXECUTION block of our main procedure, determine_tiers, where we assign the call of get_tier to l_tier, with the current l_salary value of 50,000. We print the value of l_tier. Next, we change the l_salary to 120,000, and again call get_tier, assigning it's value to l_tier and printing it again. Finally, we have the EXCEPTION block of the main procedure with a WHEN OTHERS exception handler, where we'll print the error message and exception stack, and further raise the exception to the calling client. Let's compile this. Let's run this procedure. As expected, we see l_tier with a value of 2 for the first call of 50,000, and 3 for the second call of 120,000. Let us now override the visibility of l_salary on the parent procedure by declaring it again inside the inner function. Now, it should override the visibility of the parent l_salary variable. Since it would satisfy the condition of l_salary less than 40,000, both the calls to get_tier should give us a value of 1. Let us run this procedure. Now we see both times a value of 1, as l_salary variable of the parent and exchanges are not visible to the local function. Finally, let us see how an exception raised inside a local function will propagate. Let us assign a return value of A for the first IF. So now, the first call to get_tier with an l_salary of 30,000 will evaluate to the first IF. Assigning A to a number variable will raise ORA-6512, character to number conversion error, causing it to go to the exception handler in the inner function. It will print the error message, the exception BACKTRACE over there. The raised statement will then take it to the outer block's WHEN OTHERS exception where again it's going to print the error message and the ERROR_BACKTRACE. Let's compile this function first. The function got compiled successfully. Now let's run the procedure to confirm. As expected, the assignment of a character to a number caused ORA-6512 to be raised at line 9 of the inner function, that raised the exception to the outer block's exception handler, where again the error message in the BACKTRACE was printed at line 23. So, the local functions and procedures follow the same rule of exception propagation as in the case of nested blocks.

Summary

Local subprograms can help in creating reusable logic unique to a procedure, function, or an anonymous block. If there is a possibility of it being used by other program units, then it is better to create stored subprograms instead. Exceptions in local subprograms propagate to the parent subprogram and follow the same rules of propagation as nested blocks. The scope and visibility rules of variables are the same as for nested blocks, and you should be careful not to create a variable with the same name inside the local subprogram overriding the one in the parent, as it can give you incorrect results.

Package Specification

Introduction

Hi. Welcome to Pluralsight. My name is Pankaj Jain, and welcome to this module on Package Specifications. Having the ability to group things based on functionality or a common theme is not only good from an organization perspective, but also allows better manageability and retrieval of items. When you walk in the library or the grocery store, imagine the amount of time it might take you to find something if things were not organized based on sections or categories. Similarly, in the database, when you have a large number of compiled PLSQL units, you need to organize them so that you can easily find them when needed, and reuse them. Oracle provides us this functionality in the form of packages, which allow logical grouping of related items, along with mechanisms to maintain session state and global variables. In this module, we will take a look at the structure of a package, see how to define and execute a package specification, as well as understand how package specifications provide global variables and session state. We will further continue the discussion about packages in the next module, where we will talk about package body, overloading concepts, packet state, etc. Let us jump right in and start looking at this very important programming construct.

Why Use Package Specifications?

Packages, as we discussed, facilitate a logical grouping of items based on functionality or need. For example, you might want to create a package consisting of procedures and functions related to order management, like creating, modifying, or deleting orders, or, maybe to keep all the constants used in your system in a separate package, or to create a utility package to keep all the general purpose utility subprograms. The variables, constants, etc, which you define in your package specification, are visible to other packages, procedures, functions, and anonymous blocks in the system. This global visibility allows you to define these constants or variables once centrally, and then to refer to them from different client applications. Along with providing global visibility, Oracle maintains the state of the data for the variables, collections, etc, declared in the package specification for the duration of the session, allowing you to maintain your session data without any other session being able to see and modify it. Some of you coming from Java or C# background know that it takes some effort to achieve safe data, which is provided easily in the Oracle database using package specifications. Package specifications are like interfaces in Java or C#, exposing public APIs available for other clients to consume. However, using packaged bodies, you can create additional private subprograms available only to the other members of the package. So, it gives you the ability to selectively expose only the functionality element to other clients and hides from public view what is not needed to be exposed or should not be exposed. You can create package specifications consisting of public APIs, without having to define their implementations right away. So from a design perspective, it gives you the flexibility of architecting your code and APIs without worrying about the fine implementation details right away. Packages, like procedures and functions, are named program units, so they have all the benefits of a named program unit where they are compiled and stored in the database and can easily be reused. Packages offer further performance optimization in that when you reference a package for the first time, Oracle pulls all the membership programs into memory at the same time, preventing further disk I/Os for subsequent users. When program units call each other, they create dependency links, causing the dependent program units to be invalidated and recompiled every time a reference program in it changes. However, in the case of packages, if you do not change the public APIs, you can change just the implementation in the body without invalidating the consuming clients, another additional benefit of using packages. There are not many instances when you should not use packages and should create standalone procedures or functions instead. The only instance I can think of is when the specification is constantly changing; in other words, the business needs require you to change the name or the subprogram parameters, or add or remove some programs constantly. As soon as you make the change in the specification, Oracle will immediately mark all the client programs referencing them as invalid, and will try and automatically recompile them the next time they are called. So, say in the package specification we have two procedures, A and B. Procedure A's definition changes frequently, and B is relatively steady. So even though procedure B does not change, all client applications referencing it will be marked invalid and recompiled every time procedure A changes. In such situations, it is better to pull out the frequently changing subprogram A and create it as a standalone procedure. You should only keep the subprograms whose definitions are relatively steady as a part of a package specification. You can still continue to modify the implementation or the body for these package programs, as just changing the body or the implementation does not cause the invalidation of the dependent units.

Package Structure & Contents

As we referred to a few times earlier, a package structure consists of two parts: A package specification, and a package body. A package specification consists of all the public APIs or declarations of procedures and functions, variables, and types you want to expose publicly, which other program units can access. They do not consist of the implementations of the program units. They can exist independent of the package bodies as valid named objects in the database. You do not need to necessarily define the package body for the specification. One example of this use is, say if you want to create a package specification consisting of just global constants to be used throughout the system without any subprograms. The other part of the package is the package body, which consists of the implementations of the procedures and functions declared in the specification. In addition, they can contain additional procedures and functions not declared in this specification, making those only available to be consumed by other members of the package; kind of like private methods in Java or C#. Similarly, you can define additional variables, types, cursors, etc., only available to the package body members over here. Unlike package specification, you cannot create a package body without a specification, and you have to implement all the public declarations of the functions and procedures in the specification at the least for a package body to compile. They cannot exist independently without specifications on their own. The contents of the specification and the body of the package can be procedures, functions, cursors, making them reusable by other program units, types, variables, and constants, records and collection types, and other items like exceptions, call specs, etc. Call specs allow us to publish Java and C program calls in Oracle. These are the contents which can be declared both in the specification and the package body. The only difference is, that if defined in the specification, they are publicly available, but if defined in the body they are private, available only to the package body members. Again, it is unnecessary to define all of them in a package. You can define only the items you need; say a package consisting only of procedures, or one consisting only of global constants.

Defining Package Specification

The privileges needed to create packages are the same as needed for creating procedures or functions, namely, CREATE PROCEDURE or CREATE ANY PROCEDURE to create them in another schema. Let us see how we can define a package specification. The syntax, like procedures and functions, is CREATE OR REPLACE PACKAGE. OR REPLACE will replace any existing definition; otherwise, it will create a new one. Let me specify schema_name.package_name. If you do not specify the schema, it will default to the current schema or user. This is followed by the IS or AS keyword. After this, the declaration sections starts, where you can declare all the member or content types we talked about. There is no execution or exception section in a package specification, because, as we talked about earlier, it is more often an interface or a public contract. Here is an example of a package specification. It starts with CREATE OR REPLACE PACKAGE, followed by the package name hr_mgmt AS. I have defined some global constants, g_active_status as a constant of the value of A, and g_inactive_status with a value of I. These are now global constants, which can be accessed by other PLSQL program units. Notice, I have named the global constants as g_active_status and g_inactive_status. I have put the g prefix to distinguish them in my code from local constants; that helps me understand their usage and locate these constants much faster. This is just a naming convention I follow for fixing my cursors, variables, etc, I declare in the package specification with a g prefix. You can have a naming convention of your own, but I just wanted to highlight again the importance of standard naming conventions to help with the availability and maintenance of your code. Next is a global variable, g_bonus_pct, which holds the bonus percentage. We can also define exceptions to be referred by other program units over here. For example, dept_not_found_EXCEPTION. You can also define records. Here is an example of a record definition, TYPE g_rec IS RECORD, consisting of two fields, p_profit of type NUMBER, and p_dept_name of type departments.dept_name%TYPE. After this, I have defined a cursor, gcur_get_deptid, which takes in a parameter p_dept_name of type VARCHAR2. This cursor selects the department ID from the department's table where the department name is the passed p_dept_name. This cursor is now available to be used across the package body of HR management, as well as other packages, procedures, and functions in the system. This way, you do not define it at several places, and the definition of cursors stays consistent across all consuming clients. Changes to the cursor definition needs to be made at one place only. Then there is a function, calc_bonus, to calculate bonus for an input p_profit NUMBER and p_dept_id of type NUMBER again. It returns a bonus amount, which is of type NUMBER. Next is a procedure, update_emp, which updates the department ID of an employee. It takes the p_emp_id and p_dept_name input parameters. We end the package specification with ENT hr_mgmt. This is just a sampling of the type of information you can have in the package specification; you can have as much or as little information and content types in here as you want. The only thing to take care is if an item is referenced by another item, say as in this code snippet, g_active_status is referenced by the CURSOR gcur_get_sal. So g_active_status needs to be declared before the cursor, otherwise, the package specification will error out and not compile. This is the only thing to take care of, otherwise, there is no specific rule regarding the order of declaration. However, as a general coding practice, I like to declare all my variables, types, exceptions, and constants first. Then, I declare any cursors, and finally, the program units like procedures and functions. Doing it this way keeps the content types logically grouped, as well as also takes care of most dependency problems.

Compiling Package Specification

Compiling a package specification is pretty much like compiling a procedure or a function using SQL+ or SQL Developer. You can type in the specification in SQL+ and hit Enter, or in the SQL worksheet in SQL Developer, and click the run script button. You can save it in a file if you are checking in or out of a source control system. So say this content is saved in the file, hr_mgmt.spc. I like to put the .spc extension at the end to indicate that it is a specification, but you can name it with a .txt or a .SQL extension if you want. If it is stored in the SQL and demo directory, then you can compile it as @C:\hr_mgmt.spc. If you need to recompile a specification already compiled, you can use the ALTER PACKAGE hr_mgmt COMPILE SPECIFICATION syntax to just compile the specification. Compiling package specifications can result in errors and warnings, as we have discussed for procedures and functions. You have to fix errors in a code for it to be executable, and should keep warnings at the informational, severe, and performance category enabled as a good practice. Just like procedures and functions, compiling the package specification in the native mode can result in increased performance, and if a slightly longer compile time is not a concern, you should compile the code in the native mode. The syntax to do it is ALTER PACKAGE hr_mgmt COMPILE SPSECIFICATION PLSQL_CODE_TYPE=NATIVE. PLSQL_OPTIMIZE_LEVEL is another parameter which can help increase performance of your code, by making the Oracle compiler do the optimizations for the code at compile time. It can have values from 0 to 3. The higher the level the better it is, but you should keep it at least at a level of 2. One way to do it is by issuing the ALTER SESSION SET PLSQL_OPTIMIZE_LEVEL=2. Using ALTER PACKAGE hr_mgmt COMPILE DEBUG SPECIFICATION, you can compile your code in the debug mode, in order to set breakpoints and debug the code. You can check the current compiler settings for your package by issuing the command, SELECT PLSQL_WARNINGS, PLSQL_OPTIMIZE_LEVEL, PLSQL_CODE_TYPE, from ALL_PLSQL_OBJECT_SETTINGS, WHERE NAME=HR_MGMT, where HR_MGMT is the name of your package.

Executing & Dropping Package Specification

How would we execute a procedure or a function declared in the package specification? The first thing I should point out is that you cannot execute a procedure or a function declared in the specification without its implementation in the body. If you try to do so, you will get an error of the type ORA-04067:not executed, package body "DEMO.HR_MGMT" does not exist. We will talk about how to create package bodies shortly. But once you create the implementations in the package body, you will execute the subprograms the same way as you would do a normal procedure or a function, the only difference being that you would prefix the name of the procedure or the function with the package name followed by a dot. For example, if there was a procedure called updated_emp declared inside a package specification hr_mgmt, which while sticking in two parameters, employee id and department name. Then we declare l_emp_id, give it a value of 50, l_dept_name, give it a value of IT, and then call the packaged procedure as demo.hr_mgmt.update_emp, passing in the two parameters. Note here, demo is the schema name, and hr_mgmt is the package name. Providing the schema name is optional and if omitted it will default to the current schema. Similarly, to execute a function calc bonus, which returns a number and is declared inside of the package specification hr_mgmt, we will define local variables, l_profit of type NUMBER and give it a value of 100,000, l_dept_id NUMBER with a value of 1, and l_bonus to hold the result returned from the function, and call the function as demo.hr_mgmt.calc_bonus, and pass the two parameters, l_profit and l_dept_id. Again, the schema name is optional here, and if not specified defaults to the current schema. The types, variables, cursors, constants, etc, declared in the package specification, can be accessed from other clients by prefixing them by the optional schema name, package name, and a dot. For example, demo.hr_mgmt.g_bonus_pct accesses the g_bonus_pct variable declared in the hr_mgmt package in the demo schema. And we can refer to a cursor declared in the package hr_mgmt as hr_mgmt.gcur_get_deptid, and work with it as a regular cursor. I have omitted the optional schema prefix here, indicating that the package is in the current schema. This is one of the benefits of packages, allowing central cursor definitions used at several places, without having to define them over and over again. The command to drop a package specification is DROP PACKAGE, optional schema_name, followed by the package_name. For instance, DROP PACKAGE demo.hr_mgmt, this command will drop the package specification and also the body if it exists.

Global Variables & Session State

Let me now talk about one of the major benefits of a package specification, to provide global constants and variables, which help in maintaining session state. So, say we have our package, hr_mgmt, which we saw earlier, having g_active_status as a constant, with subtype VARCHAR2(1) and assigned a value of A. Then I can refer to it from any other procedure, function, package, or anonymous block in my system as demo.hr_mgmt.g_active_status. And say I have a global variable called g_bonus_pct declared in the package specification, then within my session, once a program unit or anonymous block can set the value of it, another one can access its current value. Each session gets its copy of the session variables which other sessions cannot see. These global variables maintain their state and data for each session and do not interfere with each other. This is one of the greatest benefits of using package specification in providing threat safe session state with such simplicity.

Demo

In this demo, let's take a look at how to define and compile a package specification, and understand the importance of the order of declaration, then we will demonstrate how package level variables can help with the session level data persistence and maintaining a global state. Here in this code snippet, we are declaring a package specification for hr_mgmt. It starts with CREATE OR REPLACE PACKAGE hr_mgmt AS. We first declare two constants of type VARCHAR2(1), g_active_status with a value of A, and g_inactive_status with a value of a I. These two can now serve as global constants in the system. Next, we have global variable g_bonus_pct of type NUMBER initialized with a value of 0. This will hold the bonus percentage for the session and provide session data persistence. Next, we have an exception, dept_not_found_ex, which can be referred by other program units. TYPE g_rec IS RECORD, consisting of two fields, p_profit of type NUMBER and p_dept_name of type departments.dept_name%TYPE. Following that, we have a CURSOR gcur_get_deptid, which fetches the department ID from the department ___ for the input p_dept_name. Next, is a function, calc_bonus, which takes a p_profit and p_dept_id, both of type NUMBER, and returns the bonus as a NUMBER. Lastly is a PROCEDURE, update_emp, which updates the department for the input employee, p_emp_id, with the department of the input p_dept_name. So, we see how to define various components in a package specification. Let us compile this by hitting the run script button. The package got compiled successfully. If we expand the package node now, we will see our package shows up over there. If you already have the package node expanded, then you might have to right-click and choose Refresh to see your package over here. You can also create a new package by right-clicking on the Package node and choosing New Package. This brings up a window with a dropdown for the schema where we want to create this, and an input box to type the package name. Let us leave them to the default values and click OK. It brings up a new window with a basic structure of a package specification, where now you can fill in the details. Let us click the compile option from here. It creates a package, which now shows up in the tree. Notice, we did not put anything in the specification, but still it got created, demonstrating the different content types that are optional. Let us now click and open the HR_MGMT specification. It opens up a window where you can further make changes and then choose the compile option from the top to compile it. Notice, that there is also a Compile for Debug option over here; now a green icon shows up on top of the package specification, showing that it is compiled in the debug mode. We can recompile a package specification in the debug mode by typing ALTER PACKAGE hr_mgmt COMPILE DEBUG SPECIFICATION. We can compile it in the native mode by typing in ALTER PACKAGE hr_mgmt COMPILE SPECIFICATION PLSQL_CODE_TYPE=NATIVE. Let me now demonstrate how package specifications help in providing global constants and session level data persistence. I'm currently in a session logged in as a demo user. In this anonymous block, I'm accessing the hr_mgmt.g_active_status and printing it using DBMS_OUTPUT.PUT_LINE. Then I'm setting hr_mgmt.g_bonus_pct value to 10. Let's run this block. So I can access the global constant and see its value. Next, let me run another anonymous block in the same session. It could have been another procedure or function or a package too. Here I'm printing the current value of hr_mgmt.g_bonus_pct. Let's run this. I see the value of 10, which was set earlier in the session by the first anonymous block. So Oracle maintains the value of the package specification for the session. Let us say we have user test in our database. Let's give the user test execute privileges on the hr_mgmt package. Now here is another session where I'm logged in as user test. Here again, I have an anonymous block, where using DBMS_OUTPUT, I'm printing demo.hr_mgmt.g_active_status value. I have to fully qualify the package with the owner's schema demo to resolve it. Next, I am printing the value of g_bonus_pct. After that, we set its value to 20. Let's run this. Running the block we see that we can access the g_active_status constant from user test also. G_bonus_pct value at the beginning of the block is 0, with which it was initialized. Even though we have set the value as 10 in the demo session, this session cannot see that change. Here, we have our second block. Here, we are printing the current value of g_bonus_pct for this session, which should be 20, as set by the block before. Let's run this block. It comes up with a value of 20 for g_bonus_pct, which was set earlier. So each session maintains the state of data in the session using package variables. In this demo, I have the second session as user test, but even if I have the second session as user demo, the first demo session would not have seen the changes of the second demo session in a similar fashion. Finally, we can drop the package specification by using the command, DROP PACKAGE hr_mgmt. Let's run this. The package specification is dropped now, and if you come to the Package node, right-click and Refresh, you'll see that our package is no longer there.

Summary

In this module, we talked about the need and benefits of package specifications, how they allow grouping, and accessing related items. They have all the performance optimization benefits of a named program unit. However, if your subprogram definition changes often, then it might be better to create it as a standalone program unit. You can have procedures, functions, types, records, cursors, exceptions, etc, as a part of package specification, and you can have as many and as few components as you need. Order of declaration is important where say your cursor is referencing a variable declared earlier in this specification. Packages have the great benefit of providing mechanisms for maintaining session data and global variables with great ease. They are a very useful and powerful programming construct, which you should take advantage of while writing PLSQL code.

Package Body

Introduction

Hi. Welcome to Pluralsight. My name is Pankaj Jain, and welcome to this module on Package Bodies. In the last module we started our discussion about packages. We talked about the differences between package specification and package body. In this module, we will take an in depth look at package body, where we will provide implementation details for the subprograms defined in the package specification. Along with talking about how to define, compile, and execute package bodies, we will also talk about important concepts related to stateful and stateless packages, and overloading subprograms. There is a lot of exciting stuff to cover, so let's get started.

Defining Package Body

As we talked about in the last module, anything declared in the package body has a private scope within the package body versus the declarations in the specification which have a public scope. The syntax of creating a package body is the same as the specification, just that we put the BODY keyword in addition. So, it starts with CREATE OR REPLACE PACKAGE BODY, schema_name.package_name, followed by the IS or AS keyword, the schema name being optional, and if not being specified it defaults to the current schema. We can declare variables, types, constants, records, etc, all the items we talked about earlier, the only difference being that these have a scope only within the package body, and cannot be seen by outside subprogram units and anonymous blogs. We declare and implement procedures and functions local to the package body over here, along with the implementations of the procedures and functions we have declared in the specification. We have to implement all the procedures and functions defined in the specification, otherwise the body would not compile. The package body can also have an optional execution section which starts with the BEGIN keyword. This is executed just once when the package is loaded for the first time in the session; we will talk about it later. And then, it can also have an optional exception handling section. The package body ends with the END keyword followed by the package_name. Let us see how we can define a package body for this specification we had looked at earlier. There are a few constants defined, g_active_status with a value of A, g_inactive_status with a value of I, a global variable g_bonus_pct, dept_not_found_ex EXCEPTION, a record g_rec, consisting of p_profit and p_dept_name, a cursor to get the department id for a given department name, but, we will be taking a closer look at implementing the body for the FUNCTION calc_bonus and the PROCEDURE update_emp. Here, I will show you a sample implementation of the package body for the specification we just saw, and in the process, I'll demonstrate to you how global cursors and variables can be accessed and used, how we can declare extra program units in the package body, and the implementation of the program units we defined in the package specification. We start our implementation of the package body with CREATE OR REPLACE PACKAGE BODY hr_mgmt AS. The package body name has to be the same as the specification name. We have declared a CURSOR, cur_get_sal, which takes in a department ID, p_dept_id and finds the sum of the salary of the employees for that department ID and where the employee status is, g_active_status. If you recall, g_active_status is one of the constants we have defined in our package specification, and this shows how this can be used as a global reference, not only in this package, but in other program units and anonymous blocks in the system, providing a consistent definition. Also, if it has to be changed, it can be changed in the package specification, with all the consuming client units then seeing the new value. Since we are accessing it inside the same package body as that of the specification, we need not qualify it as hr_mgmt.g_active_status, though we can certainly do that if we want to. But, if accessed outside this package, we will have to prefix the package name, followed with a dot, for it to be a valid reference, and this goes for all the objects and items defined in the package specification. Next, we are defining a PROCEDURE, set_bonus, taking in p_profit, a NUMBER parameter. Notice that this procedure was not defined in the package specification and is defined in the body only. As a result, only the package body members can refer to it, but not the program units outside. The set_bonus procedure has a DBMS_OUPUT printing inside set_bonus. Next, we have an IF clause, where if the p_profit is less than 100,000, we set the g_bonus_pct to 1; otherwise to a value of 2. Next is a FUNCTION, get_bonus, which takes p_dept_id and NUMBER, and this again was not in the specification, and can be referenced only within the body. L_sal is a local variable of type NUMBER. We open the cursor, cur_get_sal defined at the package body level, passing in p_dept_id, fetching the resultant l_sal, and then close the cursor. This shows how a cursor at the package body level can be used and shared by the program units without having to repeat the definition each time. We multiply l_sal with g_bonus_pct and return the result. So, whatever is the g_bonus_pct value at this time will be taken for the calculation. Since I cannot show the entire code in one slide, we will continue with the rest of the code in the next few slides. Next, we implement the function and procedures as they are declared in the specification. The function and procedures have to be implemented exactly as they are declared in the specification, with the same parameters and the same name, otherwise the package body will not compile. First is the FUNCTION to calculate bonus, which takes in the profit, p_profit, and the department ID, p_dept_id. Inside we call the procedure set_bonus, which we had declared earlier in the body, and so is accessible to all the members of the package body. This procedure, as we saw, will set the g_bonus_pct based on the profit. Then the next function, get_bonus, we will return the bonus for the passed department ID, and the g_bonus_pct calculated and set by the first procedure. It is always a good idea to break the functionality into smaller modular procedures and functions, like setting and getting bonus here, giving the consuming clients the flexibility to call only the functionality they need, and then call them in the required sequence to get the work done. Here, calc_bonus calls them in order. Calc_bonus is exposed as a public API in the specification. The outside clients need not worry about unit tasks and their order, as calc_bonus provides the necessary abstraction. Then, we have the exception section with the WHEN OTHERS handler. Next is the update_emp procedure declared in the specification, which takes in p_emp_id and p_dept_name. We declare l_dept_id as a number. Inside of the execution section, the cursor declared in the specification, gcur_get_deptid is used. We pass the p_dept_name and get the fetched department ID into l_dept_id, and close it. If the department ID is not found, which is indicated by the value of l_dept-id, unchanged from its initial value of null, we raise the exception, dept_not_found_ex, again an exception we declared in the specification and available to everyone to use. If you are able to find the department ID, then the IF clause will value to false, and we will come to the UPDATE statement, where we are updating the emp_dept_id to l_dept_id for the given p_emp_id, and then commit the change. This is followed by the EXCEPTION section. We completed our package body with END hr_mgmt keyword. So this is how a package body is created, implementing the subprograms defined in this specification, along with optionally some of its own.

Package Initialization

Oracle also allows an initialization section for the package body, which called in the package and is first loaded into memory for the session. It will not recall for subsequent calls in the same session. The kind of things you will do here is typically initialize the package variables. This section, along with the exception section which goes along with it, is optional. This has to be placed at the very end, after the last subprogram definition ends. For instance, here in this code snippet, after the last procedure update_emp ends, we start the initialization section with a BEGIN keyword. Inside, we initialize the package variable g_bonus_pct. Then we have the EXCEPTION handler section, having the WHEN OTHERS exception handler, and hr_mgmt ends the package body. The exception handler section for the initialization section, will only handle errors which occur within the execution section after the BEGIN keyword. But, if an error is raised, say in the package declaration section, where we are assigning a two-digit number to a number 1 data type, it will make the exception jump out to the calling client. Upon the first execution of this package in the session, the error, ORA-06502 for a numeric or value exception will be thrown to the client application. However, on the second execution, no error will be raised. This seems like a strange behavior, but knowing that a package is initialized only once in the session, it makes sense. Even though there was an exception the first time, the variable gets initialized, not as 12, but as null. Unless the package is recompiled in the session, Oracle will not try to initialize the package body again upon subsequent calls in the same session, so the second time, no error is raised. So, if you notice the first execution of a package raising errors, which are not appearing on subsequent calls, it might have to do with the variable declaration problems. You can understand it better knowing how a package is initialized in a session. Generally, I like to put all the initialization in a separate procedure, and then call that as the first thing in my main procedure. That way, the error will not go unnoticed after the first execution, and I will be able to correct it. So here, instead of initializing them over in the beginning, I've just declared them. Then, I create a separate procedure, call initialize, where I assign initial values, and then call initialize as the first thing of the main procedure called. That way, if there is an exception, it will be raised every time.

Compiling & Executing Package Body

Compiling a package body is quite similar to compiling a specification. You can type it in SQL+ and hit Enter, or in SQL Worksheet in SQL Developer and click run script. You can save it in a file like hr_mgmt.pkg. I put the .pkg extension as a naming convention so that looking at the file name I know it is a package body. But, if you want you can save it with a .txt or a .SQL extension. If it is saved in the SQL and demo directory, I can run it as the @C:\Demo\hr_mgmt.pkg. I can compile an existing package body by typing ALTER PACKAGE hr_mgmt COMPILE BODY. Compiling a package body can result in errors and warnings like the specification. You can compile it in the native mode using the syntax ALTER PACKAGE hr_mgmt COMPILE BODY PLSQL_CODE_TYPE=NATIVE. You should keep PLSQL_OPTIMIZE_LEVEL at a value over 1. You can compile just the body in the debug mode by using the command, ALTER PACKAGE hr_mgmt COMPILE DEBUG BODY. If we want to compile both the specification and the body in one go, then we can do it as ALTER PACKAGE hr_mgmt COMPILE PACKAGE. So here, instead of body or specification, I use the term PACKAGE while compiling. Similarly, to compile the entire package in the native mode, I will use ALTER PACKAGE hr_mgmt COMPILE PACAKGE PLSQL_CODE_TYPE=NATIVE. For debug mode it will be ALTER PACKAGE hr_mgmt COMPILE DEBUG PACAKGE. For executing procedures and functions declared in the specification and implemented in the body, you will call them as you would normally call a procedure and a function, by putting a prefix for the package name. I'm not going to repeat the various ways a procedure or a function can be called, but we'll just quickly review calling them from an anonymous block. So, for a procedure, you call it as demo.hr_mgmt.update_emp, passing in the parameters. And for a function, you invoke it as demo.hr_mgmt.calc_bonus, passing in the parameters and holding the result back in l_bonus declared locally. Demo is a schema name, and if not specified will refer to the hr_mgmt package in the current schema. Procedures and functions local to the package body cannot be called from outside clients, but only from internal subprograms as we saw in the package body example. For local types, variables, constants, and cursors, they cannot be referred by outside clients, but only by internal members of the package body.

Order of Subprograms & Forward Declaration

Just like a package specification, all referenced items, like variables, types, etc, should be declared before the referring items like cursors. Similarly, referenced subprograms should be declared before referencing subprograms. The subprograms declared in the package specification are already known to the public environment, so they can be implemented in any order inside the body, and the consuming subprogram can see it, even though it was implemented later in the body. But, for local subprograms declared just inside the package body, the order is important. So, in this code snippet, the local procedure, set_bonus, and the local function, get_bonus, are declared before the consuming function, calc_bonus; this way, calc_bonus can see them. What if the calc_bonus function was declared before the local subprograms? In that case, there would be an error during compilation that the subprograms are not declared in the scope, as they're declared later, and calc_bonus does not know about them. In this case, there are two solutions. If it is appropriate, declare and expose these subprograms in the specification, so that they get a global view. But, if that is not appropriate, then you can do Forward Declaration. The forward declarations happen before the consuming subprograms, typically in the beginning of the package body. It is just a declaration like in the package specification, without the implementation. Now the consuming subprogram knows about them, even though they are implemented later, and Oracle does not raise a compilation error.

Stateful & Stateless Packages

As you know, packages help us maintain session data or session state. When we have variables, constants, and cursors in a package, either in the package specification or body or both, that package is said to have a state, as the values assigned to these in the session are kept in a memory area private to the session and maintained for the session. These kinds of packages are stateful packages, as they maintain the session state. However, if the package specification and body, both of them, do not have any variables, constants, or cursors in them, then these are stateless packages, as they are not providing any global placeholders for sessions to maintain data. So the package, hr_mgmt, we created earlier has a few constants, a variable, and a cursor, which have place holders for a session to maintain data or a state; thus it is a stateful package. But what happens when the package specification or body or both is compiled? In that case, all other sessions referencing the package, whereupon the next execution, get an error message, OR-04068: existing state of packages has been discarded. As Oracle does not know how the change is going to affect the session variables, it discards the data to be on the safer side. The next call to the package will re-initialize the variables to all of our values they were declared with in the package; null if no value was assigned during declaration. So, if a variable, g_number, was declared with a value of 2, it will be re-initialized to 2. And if there was an initialization section for the package, where it was again assigned a value of 4, then that will run, giving it a value of 4. But what if we do not want our running sessions to have the least impact of code changes? We might have a 24/7 system, and we do not want any interruptions. Or, we might have just made the changes to the package body. Or, just because it had global variables and global cursors, all clients will get the ORA-04068, and then lose the session data and get re-initialized. One strategy is to separate all the global variables, constants, and cursors in a package of their own. For instance, we have removed these from hr_mgmt package, and moved these constants, variables, and cursors to their own package called global_state. You will have to do the same for any package body variables, constants, and cursors also, and move them all to over here. Local variables, constants, and cursors declared inside of procedures and functions are fine and need not be removed. These changes would make hr_mgmt as a stateless package, and so now, the referencing client sessions do not receive the ORA-04068 error.

Overloading Subprograms

Many of you from the Java or C# background are familiar with the concept of overloading program units. Overloading helps us build a friendly suite of APIs with the same name. Based on the context of data passed into them, the runtime engine invokes the correct implementation. This makes it easy for the consuming clients to call these subprograms. Oracle allows overloading of subprograms as long as the parameters are in order, or the number of parameters are different, or the name of the parameters are different, or the Datatype Family of the parameters are different. You can create overloaded subprograms only as part of a package or a local subprogram. You cannot overload standalone procedures and functions, and trying to do so will only override the previous implementation with the same name. Here is an example of overloading local subprograms. Inside the main procedure update_dept, we have defined two local subprograms with the same name, display_message. One takes in two parameters, p_location of type VARCHAR2, and p_msg of type VARCHAR2, both in the IN mode. The other subprogram takes in only one parameter, p_msg of type VARCHAR2 in the IN mode. Later in the execution section, when display_message is called with two VARCHAR2 parameters, before updating an input employee ID coordinated with p_emp_id, the first implementation is invoked. Later, towards the end when display_message is called with just one VARCHAR2 parameter finished successfully, the second implementation is called. Here is an example of overloading package subprograms. So here in the hr_mgmt package specification, we have defined FUNCTION calc_bonus with three overloaded definitions; the first taking p_profit NUMBER type and p_dept_id NUMBER type; the second taking p_profit NUMBER type and p_dept_name of type VARCHAR2; and the third, p_rec of record type. It is of type g_rec declared earlier in the specification. So here, based on the number and return type of parameters, the runtime can call the appropriate implementation. Here is the package body implementation. We are just showing the relevant section of the package body to show the function implementations. The first function takes in p_profit and p_dept_id, and calls set_bonus, and returns get_bonus, passing a property of parameters. The second implementation, taking in p_profit NUMBER type and p_dept_name VARCHAR2 type, declares l_dept_id of type departments.dept_id%TYPE. It opens a cursor to face the department ID for the input department name, and then calls the first implementation for the two NUMBER input types, and returns the result from it. The third one takes in the record parameter type and calls the second implementation, passing in the appropriate record fields for the p_profit and p_dept_name. The runtime will automatically resolve it to the second implementation, and return its result. So here we see how to use records as parameters and procedures, as well as how overloading helps us reuse and extend the implementations, quoting only what is different, and reusing the code logic of the first calc_bonus implementation. Let us talk about the rules for overloading. You can overload subprograms if the Datatype family is different. A Datatype family is a Datatype and its subtypes. For example, here is a package inside which we have defined update_emp with two parameters, p_emp_id of type NUMBER, and p_dept_name of type VARCHAR2. You can overload it by creating another procedure, update_emp, which takes p_emp_id of type BINARY_INTEGER, and p_dept_name of type VARCHAR2. Here the second parameter is the same, but since the Datatype is numbered for the first procedure, and BINARY_INTEGER for the second, and even though both are numeric, they belong to different Datatype families, and so can be overloaded. In the third implementation, the first parameter is the same, but the second parameter is a number. So, the first parameter of type BINARY_INTEGER and the second parameter of type NUMBER, is different from the previous two implementations, and so this overload is also valid. The next implementation is exactly the same as the second one, and the compiler will catch it and give you an error, PLS-00307: too many declarations of UPDATE_EMP match this call. In this case, the compiler catches the error during compilation. In some cases, the code will get compiled but you will get runtime errors later on. The next implementation keeps the first Datatype the same, but for the second one makes it a CHAR. This is not valid, as it matched the second implementation where the second parameter is VARCHAR2, and you cannot overload VARCHAR2 and CHAR. The last implementation puts the first Datatype as integer, which is a subtype of NUMBER and the second type as VARCHAR2. This is invalid, as it conflicts with the first implementation as NUMBER and INTEGER both belong to the same Datatype family. You can also overload if the order of the parameters is different. Here, even though there are two parameters of type NUMBER and VARCHAR2, this overload is valid, as the order is swapped in the two implementations. If you have the same number, type, and mode of parameters, but if one is a procedure and the second is a function, then you can still overload them. You can also overload if everything else being the same, the parameter name is different. Here, both the update_emp procedures contain two parameters; the first being a number and the second a VARCHAR2. But, you can still overload them, as the second parameter is named differently for the two of them. However, for the runtime engine to understand which one you intend to invoke, you need to use named notation in this case. For instance, the invocation, passing p_emp_id=>1, and p_dept_name=>IT will match the first implementation. If position notation is used, the runtime engine cannot determine which one we intend to call and will give a runtime error if too many declarations match this call. You cannot overload if only the mode of the parameters is different. For example, here both update_emp procedures take p_emp_id of type NUMBER, but the first one is in the IN mode and the second one is in the OUT mode; Oracle will give you a runtime error in this case. Let us analyze what happens when default values come into play. You can overload two procedures as shown here where the first parameter of p_emp_id of type NUMBER is common to both. The first procedure has an additional parameter, p_dept_name, with the default value. So, if you had planned to pass only the first parameter and use a default value for the second, we have to use named notation. Calling it with p_emp_id with a value of 1 will resolve to the first procedure. But, if you pass it with positional notation, then again, Oracle has no way of figuring out which one you are trying to call, and will give you a runtime error of too many declarations match this call.

Overloading Considerations

Let us talk about some considerations when using overloaded subprograms. Try and be explicit when specifying the parameter Datatype when calling the subprograms, and do not leave it to implicit conversions of the actual parameters with the default parameters by Oracle. That will lead to an incorrect implementation being executed. In the case of numeric parameters, if the actual parameter type is different than the former parameter type, Oracle will apply the following rule: Oracle will try and match it to the next highest data type, the order being BINARY_INTEGER or PLS_INTEGER first, followed by NUMBER, followed by BINARY_FLOAT, and lastly, BINARY_DOUBLE. So let us say we have a package, hr_mgmt, where we have four procedures by the name overload, taking in p_emp_id of each of these numeric Datatypes, BINARY_INTEGER, NUMBER, BINARY_FLOAT, and BINARY_DOUBLE. So which implementation will we call when we call the hr_mgmt.overload procedure with a numeric literal of 1? Oracle will resolve it to BINARY_INTEGER, which is at the lowest level. If you call the overload now with a literal value of 1.1, it will call the implementation of NUMBER type, as this is the lowest type which will satisfy a number with a decimal point. Now it may be so that you wanted to call the BINARY_DOUBLE implementation for getting better performance. In order to call the right implementation, you will have to explicitly declare l_numeric of type BINARY_DOUBLE, and then call the overload procedure. Now, since there is no ambiguity, Oracle will resolve it correctly to the BINARY_DOUBLE implementation. You will have also used explicit conversion functions like TO_BINARY_DOUBLE to convert the literal TO_BINARY_DOUBLE, in which case also it will be resolved to BINARY_DOUBLE. This shows the importance of being explicit with the Datatype specification. Let us also examine a situation where we are having the actual parameter of a different Datatype than the former parameter, and when there is more than one parameter. So just for our reference, I have shown the order in which Oracle will try to match the numeric Datatypes. So here there are two overload procedures, the first overload procedure taking in p_first as NUMBER and p_second as BINARY_DOUBLE type. The second overload takes p_first as a NUMBER and p_second as a BINARY_FLOAT type. Let us say our anonymous block declares two variable, l_first and l_second, both of type NUMBER. When the hr_mgmt.overload is called, which procedure will be invoked? Since l_first is of type NUMBER, Oracle will search for an implementation where the first parameter is a number, and will match both the procedures. Since there happens to be no procedure with a second parameter as a number, it will convert it to the next highest type, which is BINARY_FLOAT and searches for a match. This will match it with the second implementation, which will be called. Now, if we pass the numeric value as a character literal, then Oracle will again have to do implicit conversions. However, in the case of character conversions, it will not consider BINARY_INTEGER, and will start with NUMBER, then go up to BINARY_FLOAT, and then to BINARY_DOUBLE. So, if we execute the hr_mgmt.overload with a character literal of 1, then Oracle will match it with the 1 of type NUMBER. If the implementation, which took NUMBER, was not present, then it will go to the next highest type, and will match it with a 1, which takes BINARY_FLOAT. I just wanted you to be aware of these conversions and rules surrounding them. But your effort must be to avoid these implicit conversions totally, by being explicit in specifying the Datatypes during the subprogram call. That way, you can be confident that the right implementation will be called.

Demo: Compiling & Executing Packages

In this demo, we will create the package body for the package specification we created earlier. We will see how to do forward declarations, overload subprograms, compile, execute, and drop package bodies, as well as understand stateful and stateless packages. Let us quickly review this specification again. We have defined a couple of constants, g_active_status with a value of A, and g_inactive_status with a value of I. Then, there is a g_bonus_pct of global variable. Dept_not_found_ex is an exception. We have then defined a record type, g_rec, which has two fields, p_profit of type NUMBER and p_dept_name of VARCHAR2. This is followed by a cursor, gcur_get_deptid to get the department ID from the department's table for an input department name. Then we have three ordered definitions of the calc_bonus function, the first one taking p_profit and p_dept_id, both NUMBER types, the second taking p_profit of NUMBER, and p_dept_name of VARCHAR2, and the third taking in a record type, p_rec of type g_rec. Finally, we have a procedure, update_emp, taking in p_emp_id of type NUMBER and p_dept_name of type VARCHAR2. Let's compile it again. Let us start the package body as CREATE OR REPLACE PACKAGE BODY hr_mgmt_as. Notice the BODY keyword to specify the body. First we have a cursor, cur_get_sal, which takes in p_dept_id and returns the sum of the salary from the employee table for that department, where the emp_status is g_active_status, which gets a value of A from this specification. This cursor has a scope only within the package body. Next is again a package body procedure, set_bonus, which takes in p_profit, making this as g_bonus_pct = 0. Next, using the IF clause, if g_profit is less than 100,000, then we assign g_bonus_pct a value of 1, otherwise a value of 2. Next is the function get_bonus, which takes in the p_dept_id parameter. It declares l_sal as the NUMBER variable. Inside, it refers to the cur_get_sal cursor we declared earlier, passing in p_dept_id to fetch the sum of the salary. It returns the set salary multiplied by the g_bonus_pct value in the session at this time. Next is the implementation of the specification function, calc_bonus, which takes in p_profit and p_dept_id, both of type NUMBER. Inside it first calls set_bonus, passing in p_profit to set g_bonus_pct, and then calls get_bonus to get the bonus using g_bonus%VALUE. It has an EXCEPTION block, where it prints the error and raises it further. Next, is the overloaded version of calc_bonus, which takes p_profit NUMBER and p_dept name of type VARCHAR2. It declares l_dept_id of departments.dept_id%TYPE. It reuses the cursor declared in this specification, gcur_get_deptid, passing in p_dept_name to fetch the department ID in l_dept_id. Then it calls the first ordered version of calc_bonus, passing in p_profit and dept_id, both numbers, and returns the result. Next is a third overload of calc_bonus, which takes in p_rec of type g_record. Inside it calls a second overload by passing in p_rec.p_profit, a number field, and p_rec.p_dept_name, a VARCHAR2 field. I want to show you how to record types as parameters, especially when the number of parameters becomes too many. Next is the update_emp procedure, which takes in p_emp_id and p_dept_name. We declare l_dept_id of type departments.dept_id and reuse the cursor, gcur_get_deptid defined in the specification, passing in the department name to get department ID in l_dept_id. This is how you can declare a cursor once and reuse it several times in different subprograms, without redefining them again and again. If the l_dept_id IS NULL it raises the exception, dept_not_found_ex, which it can see as it is declared in the specification. Finally, it updates the employee table, setting the department ID to l_dept_id for the given employee ID. It commits the change. Then there is an exception handler section where we are catching the dept_not_found_ex, printing a message, and raising it again. Finally is the package initialization section, which begins with the BEGIN keyword, where we are initializing g_bonus_pct to 0. This will be executed only the first time this package is loaded in the session, and hr_mgmt will end the package body. Let us click on the run script button to compile it. Now if we refresh the Packages node, you will see our package over here; you further expand it to see our body over here. You can double-click to open the body. Over here you can make further changes and then you can compile using the compile button on top. If you notice, there is also a Compile for Debug option; if you use this, then you can compile your package body and debug more. Here's how you can compile an existing package body in the debug mode by issuing ALTER PACKAGE hr_mgmt COMPILE DEBUG BODY. ALTER PACKAGE hr_mgmt COMPILE BODY will compile the body. ALTER PACKAGE hr_mgmt COMPILE BODY PLSQL_CODE_TYPE=NATIVE will compile the body in the native mode. You can remove the BODY keyword to compile both the specification and the body in one go. For example, ALTER PACKAGE hr_mgmt COMPILE DEBUG to compile both specification and body in the debug mode; similarly, ALTER PACKAGE hr_mgmt COMPILE to compile the entire package. ALTER PACKAGE hr_mgmt COMPILE PLSQL_CODE_TYPE=NATIVE to compile the entire package in the native mode. You can check the current settings of the package by issuing SELECT TYPE PLSQL_WARNINGS, PLSQL_OPTIMIZE LEVEL, PLSQL_CODE_TYPE from ALL_PLSQL_OBJECT_SETTINGS, WHERE NAME= HR_MGMT. As you can see, here there are two entries, one for the package and one for the package body, and that both have warnings enabled for them. PLSQL_OPTIMIZE_LEVEL is set to a value of 2, and PLSQL_CODE_TYPE is native. Here I want to illustrate to you the importance of the order of declaration. So here is the same package but I've changed the order of the procedures. Calc_bonus has moved ahead. Set_bonus and get_bonus have been moved after it. Let us try and compile it. Since these are local subprograms where the compiler is trying to compile calc_bonus, it does not know of these as they come later and gives the error of SET_BONUS and GET_BONUS not declared in this scope at lines 9 and 10. So either we can move the declarations before calc_bonus, as we had done earlier, or we can do forward declarations. This way, by compiling calc_bonus, because of the forward declaration, the compiler will know of these and will not error out. Let us compile it again. This time it got compiled successfully. Let us modify calc_bonus, and let us rename p_profit to pprofit without the underscore. Let us compile it again. We get the error that subprogram CALC_BONUS declared in the package specification must be declared in the package body, even though the number, order, and Datatype of the parameters was the same, but since we modified a name of one of the parameters, it was not an exact match. This highlights the importance of specifying the subprograms exactly as they appear in the package specification. Also, all subprograms in the specification have to be implemented; otherwise, Oracle will give compilation errors.

Demo: Stateful & Stateless Packages

Let us see how we can execute a subprogram defined in a package specification, which has been implemented in the body. Of course, you cannot call subprograms private to a package body from outside, but you can only call the subprograms which have been defined in the specification. Here in this code snippet we have declared l_emp_id and given it a value of 50, and l_dept_name with an initial value of IT. Inside the execution section, we call the procedure as demo.hr_mgmt.update_emp, passing in these two parameters. Here, demo is the schema name and is optional, and since we are running it from the demo schema itself, we could have actually omitted it. Let's run this. We see the result, Updated Rows: 1. So calling a packaged procedure is similar to a standalone procedure, except that you have to prefix the package name. Now, let me demonstrate for you, stateful and stateless packages. The way that packages are defined now, they are stateful, since we have a few constants and cursors at the package level, as well as g_bonus_pct, which is a global variable, which can hold the session data and hence session state. In the demonstration, let's first grant execute on hr_mgmt TO test, to allow test to execute as package. I've got another session over here logged in as user test. Here is the same anonymous block we just ran; let's try and run it again. We get the same result, Update Rows = 1, as we expected. Now let us go back to our demo schema. Over here, let us compile the package using ALTER PACKAGE hr_mgmt COMPILE. The package got altered successfully, and since this is a stateful package, Oracle would have discarded the state of this package in other sessions. Let's go back to our test session, and let's try and run this block again. We see a message, ORA-04068: existing state of packages has been discarded, since hr_mgmt is a stateful package, and Oracle, to keep everything accurate, discards the existing stage upon compilation. This would be true if we would have compiled just the body or the specification. Let us see how we can make our package stateless. We are back in our demo session. We have created a package specification, global_state, where we have taken out all the constants, the global variable g_bonus_pct, the cursors declared at the package specification, and the body level from the hr_mgmt package. Let's compile this. So here is our stripped down package specification for hr_mgmt; all it is now is the global EXCEPTION, THE TYPE definition, and the subprograms definitions. Let's compile this. And here is the package body for hr_mgmt. Notice we have removed the cursor from the top, and all references to the global variable, constants, and cursors have been prefixed with the global_state prefix. Now let us compile it again. I started a new test session, and now, let us run the anonymous block again. It comes back with the expected result. Let's go back to our demo session, and let's compile this package over here again. We can compile the specification or body of both, and since we removed all the constants, variables, and cursors, it's a stateless package. Let's go back to our test session, and let's try and run the anonymous block again. It runs just fine, and the package state is now discarded. This demonstrates one way of keeping your package states from being discarded, by separating the constants, variables, and cursors in a separate package of its own, and thus making our package a stateless package. Using the statement, drop package body hr_mgmt, you can drop just the package body. Using drop package hr_mgmt, you can drop both the specification and the body in one go.

Summary

In this module, we talked about the package body structure and its initialization section. The initialization section is just called once in the session. The order of declaration is very important in the package body. Local procedures and functions do not have public visibility and you need to implement the referenced subprograms before the referencing subprograms or make use of forward declarations. Adding global variables, or cursors, or constants, can lead to a package having a state, which causes the package state to be discarded in consuming sessions, as soon as it is compiled. So our effort should be to move these global variables, constants, and cursors out in a separate package of their own, so as to reduce such instances and to provide high level ability. We looked at overloading, which is a very useful mechanism of building friendly APIs, where Oracle runtime decides the implementation to call based on the Datatypes passed. However, you must take care that you explicitly specify the actual Datatypes and not leave it to Oracle to perform implicit conversions, which might lead to an incorrect implementation to be invoked.

Calling Functions from SQL

Where Can They Be Called?

Hi. Welcome to Pluralsight. My name is Pankaj Jain, and welcome to this module on Calling Functions From SQL. Oracle allows us to call a PLSQL function from SQL. This can help extend our functions and make them more useful. In this module, we will take a look at the usage and restrictions of calling functions from SQL statements. So why should we call functions from SQL? Your SQL function can do a lot of filtering of the result set. In the absence of using the function, the alternate approach would be to fetch the entire DataSet, and then using the logic used in the function, filter the DataSet, which will be not that efficient; or, write a very complex query to achieve the same results, which makes it difficult to maintain. It also makes your SQL more powerful, as now you can do so much more with it by leveraging the PLSQL functions. Some SQL statements can run in parallel. So when you call function and SQL statements, you also enable the SQL statements inside the function to run in parallel. However, there is a small performance cost of context switching from SQL to PLSQL when you use functions in SQL, something you should be aware of. However, with each version of Oracle, this cost is going down. You should use the functions in SQL where the benefits we talked about outweigh the small context switch cost. Where Can They Appear? They can be called to fetch a value as a part of the select list. For example, in this code snippet, we invoke the Oracle built-in function UPPER to convert the passed character string test to uppercase, and next is an example of calling a user-defined function, get_dept_name inside of SELECT. SELECT emp_id, get_dept_name(emp_dept_id) FROM employee. Here I'm passing the call emp_dept_id to the function, and so it will get called for each emp_dept_id fetched by the select statement. The functions can appear as a part of the conditions in the WHERE clause or the HAVING clause. It can appear as conditions, as a part of the select, update, delete, or insert statements. Here in this code snippet, I'm selecting count(*) FROM employee, where the value returned by the function, get_dept_name, for each emp_dept_id fetched by the SELECT statement is compared to the value of IT. You can similarly use it in a rare condition of an update statement to update the employee location to Washington, with the get_dept_name function, taking in empt_dept_id, returning the value of IT. They can appear as a part of the VALUES clause of an insert statement. Here in this code snippet, I'm inserting the emp_dept_id using the value returned by the function, get_dept_id, which takes the department name ID as an input parameter. They can appear in the SET clause of an update statement. Here we are updating the employee table, setting the emp_dept_id to the value returned by the function, get_dept_id, taking in the parameter IT for employee ID 10. Some other places they can appear are in the ORDER BY, GROUP BY, CONNECT BY, AND START WITH clauses. For example, here we are seeing it used in the GROUP BY clause, where we are getting the count of employees and the department name returned by the get_dept_name function, taking in emp_dept_id from the employee table, and grouping it by the return value of the function. Some places where they cannot appear are to specify the DEFAULT value of a column in a table declaration. As well as to specify the CHECK constraint values of a column in the table definition. This is because we want values which would not change in these cases.

Restrictions

Let us talk about some of the restrictions in calling functions from SQL statements and SQL expressions. First of all, we can only call functions declared at the schema level or in the package specification, as they have visibility to other objects in the database. For this reason, you cannot call local functions declared within another subprogram or an anonymous block. These functions can only take formal parameters in the IN mode. Functions having parameters in OUT or IN/OUT mode are not eligible. Both the formal parameter and the return value should be an Oracle built-in Datatype, and not a PLSQL only Datatype, like say a Boolean. However, there is an exception here. You can pass a PLSQL only Datatype, for example, a binary integer, which can be implicitly converted to say a number, as long as it is within the range of the accepting Datatype. A function can have side effects where it can modify the state of the data in the database tables or a package. In that case, it becomes ineligible to be called from a select statement. Let us see the restrictions when using functions in a select statement. Here in this code snippet, we have a function, get_dept_name, which takes an input parameter, p_dept_id and returns a VARCHAR2. Inside the function, we open a CURSOR to fetch the department name for the passed department ID. We declare l_dept_name to hold a value returned by the cursor. Inside the function, we open the cursor, fetch the department name, and return it back. So this function is eligible to be called from a SELECT statement, SELECT emp_id, get_dept_name for emp_dept_id from the employee table. You cannot do an alter system or session inside this function, which will make it ineligible. If you try and issue a DML inside this function, Oracle will raise an error, ORA-14551: cannot perform a DML inside a query, because if a query changes data, it might lead to unexpected results. If this function tries to issue a commit, or a rollback, or a save point, which are transaction management statements, then again, it will be ineligible to be called from the SELECT statement. A SELECT statement is supposed to return data and not that transaction to cause commits or rollbacks, which most likely was not the intent of the calling client. The calling client needs to have that control. If you try and do that, Oracle will raise an error, ORA-14552: cannot perform a DDL, commit, or rollback inside a query or DML. Let us take a look at the restrictions when a function is used in the DML statement. Here is the implementation of a function which returns a department ID for an input department name. Again using a CURSOR, it gets the department ID from the department's table for the given department name. We have declared a variable, l_dept_id to hold the result of the CURSOR. So, inside the execution section, we open the cursor and fetch the result in l_dept_id and then close it; then we return it. Here is the code snippet where we are issuing an UDPATE on the employee table to set the emp_dept_id with a value returned by calling get_dept_id function with a parameter of IT, for an employee ID of 10. This update would execute just fine. Again like for SELECT statements, the functions called in DML statements cannot issue alter sessions or system commands. A DML statement called in parallel, cannot issue a DML statement inside the function, as the statement running in parallel in another session would not be able to see the changes. However, if the DML is not called in parallel, then doing a DML inside the function is allowed, as long as it is not on the same table on which the insert, update, or delete is done by the parent DML statement. So here, since we are updating the employee table in the parent DML, we cannot issue a DML on employee table inside the function. If you try and do so, Oracle will raise an error, ORA-04091: table EMPLOYEE is mutating, trigger/function may not see it. However, if you are doing a DML on any other table, simply insert a lock table inside the function, and that would be okay. Again, no transaction management statements are allowed. For instance, if you try and issue a COMMIT inside it, Oracle will raise errors.

Demo: Functions in SQL Statements

Let us take a look at a demo to understand how functions can be used in SQL statements, and their limitations. Let us first start by taking a look at a simple function called get_dept_id, which takes in the department name and returns the department ID. Inside, we declare l_dept_id of type NUMBER. Then we have a CURSOR, cur_get_dept_id, which fetches the department ID for the input p_dept_name. Inside of the execution section, we open the cursor, fetch its result in l_dept_id, close the cursor, and then return l_dept_id. This is followed by the EXCEPTION section with a WHEN OTHERS handler. Let's compile this. Let us now issue a SELECT as select get_dept_id with a parameter IT FROM DUAL. Since the function is not doing any DML inside it, it should work fine. Let's run it to confirm. It returns back DEPT_ID 1 for department name IT. We can use the function as a part of the WHERE clause, as shown here, where we issue SELECT * FROM employee WHERE emp_dept_id = get_dept_id ('IT'). So, it should return all the employees which have a department ID as 1. Let's run this. We see employees in department ID 1. What if we try and issue a DML statement inside it? Let us issue an UPDATE statement, updating the employee table, setting emp_dept_id = l_dept_id. Let's compile this. Now let's go and try to run this SELECT statement again. We get an error, ORA-14551: cannot perform a DML operation inside a query. Let us now go back to our function again, and let's commit this first. How about if you try and issue a commit inside of our function? Let's compare it again. Let's go back to our worksheet and run the select again. This time, we get an error message, ORA-14552: cannot perform a DDL, commit, or rollback inside a query or DML. So functions used in SELECT statements do not allow DML or transaction management statements. Let us go back, come in the commit, and compile it again. We can use the function as a part of the DML statement also. For example, here we updated the employee table where we set the emp_dept_id with a value returned by the get_dept_id with a parameter of IT, which we know is 1 for employee ID 15. Let's run this. It says, 1 row was updated. Now let us run this SELECT again to see the employees in department ID 1 returned by the function. We see EMP_ID=50 shows up over here. Let us go back to our function, and let's try and issue a DML inside the function. If you try and modify the same table inside the function that we are working on in the parent DML statement, then we will have an error. Let's uncomment the UDPATE, and let's compile it again. Now, let's go back to our other session, let us try and run the DML statement within the employee table using the function again. This time we get an error, ORA-04091: table EMPLOYEE is mutating, trigger/function may not see it. So this is one of the restrictions where we are working on the same table in two places in one DML statement, which might lead to an inconsistent state. Let us go back to our function. Let us comment the update and let's uncomment the commit. Let's compile it again. Let's go back to our other session, and let's run the UPDATE again. When we updated this time, it gives us an error, ORA-014552: cannot perform a DDL, commit, or rollback inside a query or DML. However, DML on other tables will be fine. Let us create a log table with two columns, log_msg and log_time. Now let us go back to our function, let's comment the commit, and let's put an INSERT INTO the log table. Let's compile this. Let's go back to our other sessions, let us run the update again. This time, there is no problem, as we are doing DML on a different table inside the function. Let us select from a log table. Let's run this SELECT. The data did indeed get successfully inserted.

Deterministic

Let us now talk about Deterministic Functions. Deterministic is a keyword you can specify while creating functions, which is an optimization hint. This helps the compiler not to execute a function multiple times and use the results from the last execution with the same input parameters. This, however, is only possible if the function solely deals with the input parameters inside it, and always returns the same return value for the same input values. So inside the function it does not alter or access any package level variables or database tables; it only does save some computations or logic processing based on the input parameters to return the result. For instance, the output function we talked about earlier, takes in the character string and returns the uppercase representation of it. So if the input value is the same, it will always return the same output value. What if a function is not truly deterministic? Say it alters the data in some tables or package variables; but, you have marked it as deterministic. In that case, if the compiler chooses not to execute that function again for the same input value, it might lead to incorrect results, so you have to take care that if you are marking a function to be deterministic, then it truly is, and it is not modifying any package or database state in any way. This restriction is in place for any other subprograms, which might be called from inside the function. Only deterministic functions can be used with function based indexes and materialized views. We haven't talked about function based indexes; we will talk about it in a later course, but what it is, is that if you put a function on a column in the WHERE clause, then Oracle will ignore any indexes on that column, and will do a full table scan where it could have done an index scan otherwise, thus reducing performance. Function based indexes helps you create an index on that function, thus allowing Oracle to use an index scan versus a full table scan. Materialized views allows you to run complex queries and aggregations, re-compute and store results for really fast response times. You can only declare a function defined at a schema level or declared in the package specification, or in a type specification as deterministic. We haven't spoken about types, as it is an advanced topic, but I just wanted to mention it here for completeness. You cannot declare functions local to a procedure or function or anonymous block or local to a package body as deterministic. In order to understand the performance gain using deterministic keyword, first, let us take a look at a function defined without using it. So here's a regular function, get_tier, which takes in p_sal NUMBER parameter and returns the tier in which the salary falls. Inside it compares if p_sal is less than 40,000 then assigns a return as 1. If p_sal is less than 60,000, then l_return is 2; otherwise l_return is 3. We will print p_sal for parameter and return l_return. Now in this code snippet, we select emp_id, emp_sal, and get_tier, passing in emp_sal as the parameter FROM employee table, ordering it by emp_sal. This is what you get back. So, we have two employees with a salary of 40,000, for which it calculated a tier of 2, and two employees with a salary of 70,000, for which it calculated a tier of 3. Also, if you run it as a script in SQL Developer, you would notice the DBMS output statements from the function; we see four of these, two for 40,000, and two of them for the two 70,000 rows; so the function got executed for each row. However, this function is a perfect candidate for being a deterministic function as it only deals with the input parameters, does not modify any package or database state, and would return the same output based on the input value. Let us see how we can make it deterministic. Here is the same function. The only difference is the DETERMINISTIC keyword we have added after the RETURN and before the AS keyword to make it deterministic. Now when we run our SQL we get the same result, but at this time, when we observe the DBMS_OUTPUT statement in the console, we notice that it ran the function just twice; once for each unique input parameter value, 40,000 and 70,000. For the second run for each of these values, it did not re-execute the function, but used the computed value from the last time. So this function was operating over say hundreds or thousands of employee records, you can imagine the amount of cost savings of resources and performance gains which you will get, all by specifying an extra word in the function declaration.

Parallel Enable

PARALLEL_ENABLE is similarly a performance optimization hint, which works based on the divide and conquer strategy. Oracle database allows parallel execution of queries, which allows dividing the work of running the queries among several processes, and if these queries have function calls within them, then these functions will run in several processes, each having a copy working on a subset of rows handled by that process. Each function run will be as if running in a separate session, with package variables initialized and maintained for each session. But since the package variable changes and one session cannot be seen by other sessions, if these functions are allowed to read and modify them, and use them for computations, that may lead to incorrect results. So functions, which can be parallel enabled, cannot read or modify package variables or database state. They have the restrictions which are applicable to functions run from SQL statements as well. As we talked about earlier, functions run in parallel DML cannot do any DML inside them. If these functions call other subprograms inside them, then these restrictions apply to them also. Here is an example of the same function which is parallel enabled by using the PARALLEL_ENABLE keyword again after it returned Datatype and before the AS keyword. One thing to note is that a function without explicit declaration, might still run in parallel if Oracle compiler can determine that it is safe and meets the restrictions. Oracle database also allows running Java programs and C functions from inside PLSQL by creating PLSQL wrappers for them, but these will not be considered safe to run in parallel, unless we explicitly specify PARALLEL_ENABLE to indicate to the compiler that it is safe to run; but again, like specifying the deterministic, we need to be careful specifying a function to be parallel enabled, as if it is not truly parallel enabled, and Oracle chooses to run it in parallel based on our declaration, it might lead to incorrect results. One way to make a query run in parallel is if the table it accesses has parallel specification in its definition. For instance, we can specify the parallel degree with an alter table as ALTER TABLE employee PARALLEL 3. One way to check the parallel degrees set for a table is by issuing the command, as in this statement you can also make a query run in parallel by specifying the parallel hint, as in this statement where we are asking to run the query in parallel with a degree of 4 on the employee table. That way, the function called in the query also runs in parallel. Once Oracle decides to execute a query in parallel, it decides the degree based on the definition of the tables involved in the query, and chooses the highest value, and then it checks the statement for a parallel hint, and if found, it overrides the parallel degree found earlier.

Demo: Deterministic Functions

Let us take a look at how to create a deterministic function and how it helps improve performance. We will also look at how to parallel enable a function. Here is a function, get_tier, which takes in a salary parameter, p_sal, and returns as a number. It checks and sees if p_sal is less than 40,000, then it assigns a return value of 1. If it is less than 60,000, then it assigns a value of 2, otherwise a value of 3. Then, using the DBMS OUTPUT.PUT_LINE, we print p_sal. Let's compile this. Now let us run the statement, SELECT emp_id, emp_sal, get_tier, passing in emp_sal to it, and giving it an alias of tier from the employee table ORDER BY emp_sal. Let us run it as a script so that we can see the DBMS OUTPUT statements. So as you can notice from the output statements, it calls a function for each row; since we had four rows, it outputs four p_sal statements. Now let us make this function deterministic by adding the deterministic keyword before AS. Let's compile this. Now let us run the same SQL statement. Notice this time we get just three output statements, one for each unique salary value. This shows the power of deterministic functions to reduce function executions when the parameter values aren't the same, thus increasing performance. Finally, let us make this function enabled for PARALLEL_ENABLE by adding the PARALLEL_ENABLE keyword. This can go along with the deterministic keyword, or be the only one to be specified. Let's compile this. Executing ALTER TABLE employee PARALLEL 3, we can assign the employee table a parallel degree of 3. Let's run this. We can change this by issuing SELECT degree from user_tables, where table_name is EMPLOYEE in uppercase. It now has a degree of 3. You can specify it as a hint, as in this SELECT statement. You have to use the \+ to start the hint, and *\ to end it. We make it run in parallel with a degree of 4 for the employee table. Let's run this.

Pragma Restrict References

Prior to Oracle8i, PRAGMA RESTRICT_REFERENCES was used to assert the purity levels of the subprograms to determine their side effects, like whether they modify the database state or a packet state. Specifying the PRAGMA is still available with later versions for backward compatibility. However, use DETERMINISTIC or PARALLEL_ENABLE instead to specify purity levels when you write new code. So, I will not go in much detail over here, and I'll just give you a broad overview of these. There are four values you can specify for theses PRAGMAs. WNDS stands Write No Database State, which means not updating, or deleting, or inserting data in tables. RNDS stands for Read No Database State, which means the subprogram does not read from the database. WNPS, or Write No Package State, means the subprogram does not write to the package variables, and RNPS, or Read No Package State, is where it does not read package variables. Finally, TRUST means that a subprogram can be trusted not to violate one or more rules, and is especially useful in situations where methods written in Java or C code are called from PLSQL and the compiler cannot determine the purity levels of these programs. You can specify this PRAGAMA with the subprograms at the package specification level. You should not put it in the subprograms and the package body level. The syntax to specify is PRAGMA RESTRICT_REFERENCES bracket, followed by the Function_Name,WNDS, WNPS, RNDS, RNDS, RNPS, TRUST. You can specify only those values which are applicable. For instance, here is a package, hr_mgmt, which has two functions in the specification, get_tier and get_diff, so, if we specify the PRAGMA for each following the function declaration. For instance, for get_tier we specify it as PRAGMA RESTRICT_REFERENCES get_tier, WNDS, WNPS, RNDS, RNPS. For get_diff, we specify just WNDS and RNDS. So inside the package body, and I'm just showing a snippet of it, if you try and issue a DML, the compiler will catch it by raising an error, PLS-00452: Subprogram 'GET_TIER' violates its associated pragma.

Summary

Functions are very useful programming constructs, which when called from SQL can extend the SQL, enabling it to do easily what otherwise would not be possible or would be very complex to do. There are restrictions when calling a function from a select or DML statement, like not issuing transaction control statements, etc, which you must be aware of. Deterministic functions can optimize your function calls from SQL by not executing the function again for the same input values. This, however, is only possible if the function works on the input variables alone, and does not access or modify the database or package state. So be careful in marking a function as deterministic, because, if it is not truly deterministic, it may give unexpected results. Parallel Enable is similarly an optimization hint to the compiler, indicating that the function is safe to use in parallel query or parallel DML. However, it should not read or modify the database or package state. PRAGMA RESTRICT_REFERENCES was used to indicate purity levels in the Oracle version prior to Oracle8i, and is available for backward compatibility. You should use deterministic and parallel_enable instead to indicate the purity levels in new code.

Roles & Privileges With Subprograms

Subprogram Resolution

Hi, welcome to Pluralsight. My name is Pankaj Jain, and welcome to this module on Roles and Privileges with Subprograms. In this module, we will talk about how resolution of tables, functions, and other objects happens at runtime when we have these defined in our own schema, as well as have been granted access to the objects with the same name in another schema. Further, we will talk about the AUTHID clause used during the definition of a stored subprogram, which decides the schema context and the privilege set it runs under, the definer of the procedure, or the executor of the procedure. These are very important concepts you need to know to properly understand the execution flow of your code and how it affects the results you get. So let's get started. Name resolution of an object is very important to understand when you have multiple objects of the same name and you have access to all these objects. Many of you coming from Java or C# background are aware of the concept of namespaces. Namespaces allow you to define objects of the same name and parameters as long as they are in different namespaces and do not conflict with each other. An equivalent way to understand this in Oracle is that whatever you define in your own schema is in a local or schema namespace, which you can refer to directly. The same object with the same name in another schema can be accessed by prefixing it with a schema name and a dot to indicate the namespace where that object can be located, and an object we define in a package can be referred by schema name dot package name prefix, schema name being optional if referring to the object in the current schema. For instance, consider that we have the procedure update_emp in our schema demo. Say we have a procedure by the same name in a package hr_mgmt. When logged in a session as a demo user when you issue exec update_emp, it will resolve it with the standalone procedure update_emp. If you want to access the packaged procedure, then you have to fully qualify it as exec hr_mgmt.update_emp for it to be resolved to the packaged procedure. Hr_mgmt acts as a namespace for this procedure. We can have the same package procedure in multiple schemas and we can access each one by prefixing the right package name followed by a dot. Now say we have another schema or user, test, to whom we are granting execute on this procedure using the statement GRANT execute on update_emp to test. So if a session is logged in as user test, it has to issue exec demo.update_emp to be able to access this standalone procedure. Using the schema prefix or namespace, it can resolve it and find the procedure. Let us add synonyms also to this mix. Synonyms help us assign a name of our choice to any object, kind of like an alias. So say in the test schema, we create a public synonym, CREATE PUBLIC SYNONYM update_emp for demo.update_emp. To create a public synonym, you need to have CREATE PUBLIC SYNONYM privilege assigned to you, or you need to log in as a DBA user to run this. So now update_emp public synonym is a public alias to the update_emp procedure in the demo schema, and anyone with the execute writes can use it. The order of resolution is always from the lowest level up, so local objects will always be resolved first, and only if they are not found will Oracle go to the next level. This is true for all object types we define in the database, like tables, functions, procedures, etc. So now when the test session issues exec update_emp command, it'll first go and look in the schema and when it will not find it over there, it'll go one level up and find a public synonym with the same name. Using that, it will be able to resolve demo.update_emp. Let us say we also create a procedure, update_emp, in the test schema. Now when the test session issues exec update_emp, which procedure will it see? The local objects always take precedence and only if there is no local object will Oracle go a level up and try to see if there is one which exists over there. Since there is a local update_emp procedure, it will resolve to it and then not go to the next level of public synonym update_emp. So to sum it up, local objects get resolved first before Oracle will go to the next level. The schema name and the package name serve as namespaces for us to define and invoke multiple objects with the same name.

Demo: Subprogram Resolution

In this demo, we will take a look at how namespaces are used for subprogram resolution, as well as the precedence Oracle uses in choosing subprograms. So here I am logged into demo session. Let us create a procedure, update_emp. It is an empty procedure with just a DBMS_OUTPUT statement indicating its location as I just want to focus on the concept of subprogram resolution over here. It prints Inside Standalone Procedure update_emp in demo schema. Let's compile this. Here again in the demo session, let us create a package specification, hr_mgmt, with a single procedure update_emp inside it. In the package body definition for hr_mgmt, we implement the procedure update_emp, again outputting its location as Inside Packaged Procedure update_emp in demo schema. Let's compile this. Let us first run exec update_emp in the demo session. Without any qualification, it will get resolved to the standalone procedure in the demo schema. Let us now run hr_mgmt.update_emp. Qualifying it with hr_mgmt, which is the package name, provides the correct namespace resolution to run the packaged version of the program. Let us grant execute on update_emp to the test user. Let's run this. Now here is a session running as user test. Let us execute demo.update_emp from here. Prefixing demo, which is the schema name, helps Oracle resolve it to the standalone procedure update_emp in the demo schema. Here I'm logged in as a dba user. Let's create a public synonym update_emp for demo.update_emp procedure. Now in the test session let us run exec update_emp. It will first look locally and then not find any procedure with this name, then it will go a level up and it will find a public synonym with the same name. The public synonym points to the demo.update_emp procedure, and since the user test has execute rights on it, it will be able to execute it and it will print Inside Standalone Procedure update_emp in demo schema in the DBMS_OUTPUT. Finally, in the test session, let us create a procedure with the identical name, update_emp. Inside it, we print Inside Standalone Procedure update_emp in test schema to indicate its location. Let's compile this. Now let us run exec update_emp again in the test session. It prints Inside Standalone Procedure update_emp in test schema. This indicates that a local subprogram with the same name takes precedence, and only if it is not found will Oracle go a level up to find something with the same name.

AUTHID DEFINER

We have seen this warning several times during this course in the earlier modules, unit subprogram_name omitted optional AUTHID clause: default value DEFINER used. So what is this AUTHID clause? AUTHID clause defines the privileged set under which a subprogram runs and the schema context in which external references in the subprogram as resolved. It has two values, DEFINER is the default. DEFINER is the same as the owner of a program. It means that the subprogram is going to run under the permission set of the definer of the subprogram and the definer's schema would be used for resolving external references. The other value is CURRENT_USER, which is the invoker of the program. An invoker is not the owner, but just the user of the program. It indicates that the subprogram will run under the privileged set of the executor of the program, and the invoker schema would be used to resolve external references in certain kinds of statements. So even if update_emp was created or defined by user demo, if it is defined with AUTHID CURRENT_USER clause, when user test runs it, it will run under user test's permission and user test's schema object context. Let us understand this in more detail. First, let us see the syntax for specifying the AUTHID clause. It has AUTHID DEFINER or CURRENT_USER before the IS or AS keyword while defining a subprogram. It can be defined for standalone procedures. Here is an example of the header declaration section of update_emp procedure defined with a default DEFINER AUTHID clause. If we had omitted the AUTHID clause, as we were doing so far in our examples, it was defaulting to the AUTHID DEFINER clause. It can be defined for standalone functions. Here is another example where we are defining get_count function as CREATE OR REPLACE FUNCTION get_count RETURN NUMBER AUTHID CURRENT_USER IS to define it as an invoker's right subprogram. It can be defined at the package specification level. All the subprograms under the package will follow the AUTHID clause, and you cannot specify a different value for each one. So here we are defining the package specification hr_mgmt as CREATE OR REPLACE PACKAGE hr_mgmt AUTHID CURRENT_USER AS. Now both the FUNCTION get_tier, as well as the PROCEDURE update_emp, will be defined with AUTHID CURRENT_USER. You cannot put the AUTHID clause in the package body. AUTHID DEFINER is a default value when it is not specified. When a subprogram is compiled with the AUTHID DEFINER clause, all references to tables, views, unqualified references to subprograms, like procedures, functions, packages, etc., are resolved in the schema of the definer, or the owner of the subprogram. Let us understand it with an example. So here is a function update_emp declared as CREATE OR REPLACE FUNCTION update_emp, which takes in p_dept_id NUMBER and p_location VARCHAR2 input parameter, then there is the AUTHID clause of AUTHID DEFINER, followed by the IS keyword. It has a local variable l_count of type NUMBER. Inside, it first updates the employee table, updating the location to p_location for emp_dept_id equal to p_dept_id. It then returns the count of rows updated. Let us say we compiled this in the demo schema where it operates on the employee table in that schema. When user demo logs in and starts a session and calls the function update_emp, it resolves to the update_emp function in the demo schema. The function operates on the employee table in the demo schema and then returns a number of rows updated. So far so good. This is what we have been seeing so far with the default AUTHID behavior. Now let us say we give privs to user test to execute the update_emp function in the demo schema. Let us say that user test also has an employee table in its own schema. Now when we run, another session logged in as user test and call the update_emp function in the demo schema, would it operate on the employee table of the demo schema, or would it update the employee table in its own schema? Since the update_emp function is a definer's right function, even though user test is executing it, it will work upon and update the employee table in the demo schema. Demo user is the owner or definer of the function and references to external objects inside it will be resolved in the demo schema. What if our intent is to update the table in the test schema when user test is executing the function? In that case we will have to create a copy of the function in the test schema also. Then, when user test executes a function update_emp, it will resolve it to the function in the test schema, which will then operate on the employee table in the test schema the owner of the function in that schema. So with the definer's right subprogram, a subprogram is bound to the schema it is defined in in order for the function to operate on objects. In another schema, it will have to create a copy of it in the other schema as well as we saw. This leads to a duplication of code. Typically you will not have multiple schemas owning the objects. It is generally one schema, which owns the objects, and other users just have appropriate rights to use the object in that schema, and so this problem should not arise. However, one great benefit the definer's right subprogram provides is that it provides a mechanism to have controlled access to sensitive tables to the subprogram without giving the end user direct access to the tables. So here if we do not want to give the user test direct access to the employee table in the demo schema, then just by giving the execute privileges on demo.update_emp, it can still execute the required functionality in a controlled way. So it gives us a better control of database access.

AUTHID CURRENT_USER

AUTHID CURRENT_USER allows the resolution of external references to happen based on the privileges of the user calling the program. So here's the same function update_emp in the demo schema, but now it is defined as AUTHID CURRENT_USER. The demo schema contains the employee table. Here is the test schema, but this time it only has the table and the function has been removed from here. Now when the demo session issues the update_emp call, as before, it goes to the update_emp function where the update to the employee table acts on the employee table in the executor schema, or demo schema. But when the test session runs the demo.update_emp function, it calls to the update_emp function in the demo schema as before, and here the update to the employee table resolves it to the employee table in the test schema as it is the caller or executor of the program. Here we have defined the function in the demo schema, but you may as well define it in the test schema or another central schema from where everyone can call it. So this is how the invoker's right AUTHID clause can help in removing duplication of code in cases where identical table structures exist in multiple schemas and the same subprogram is to be used for all. However, since Oracle has to do a runtime resolution of external references, there is a slight performance hit, something you must be aware of and so create subprograms with AUTHID CURRENT_USER only when you have a real need for them. The other risk, creating an invoker's right subprogram is of trust. If the definer of the procedure puts malicious code in the procedure, at runtime it is going to be executed on the invokers tables and may cause malicious updates over there, or the owner may create a subprogram initially as a definer's right subprogram, and later without the knowledge of the executor, recompile it as an invoker's right subprogram with some malicious DML statements inside it. Now when the executor runs the procedure, it'll cause unintended updates, which the owner of the subprogram may not have the privs himself of doing, one of the risks you need to be aware of. In most organizations, there is a better configuration process with multiple levels of testing, so hopefully the chances of this kind of thing happening is very low. Now the AUTHID DEFINER clause resolves everything in the definer's schema, but the AUTHID INVOKER clause checks the privileges of the current user at runtime and resolves external references to tables, views, etc. in the schema of the invoking user. However, there is a limitation in terms of what operations are eligible for such resolution, so it can resolve external references only in these operations. DML statements are select, insert, update, and delete statements. So as we saw, it could resolve the employee table reference in the update statement in the last example in the calling user's schema. It can similarly dissolve external references to say tables in the open and open for cursor statements. If you need to review cursors, please refer to the Part 1 course. We haven't looked at dynamic SQL yet, but dynamic SQL lets you build SQL statements, which are built and evaluated at runtime as opposed to compile time. We will not go in much detail over here, but again use execute immediate statements open for using or DBMS_SQL.parse statements for running dynamic SQL statements. These are also eligible for the invoker's right resolution for external references. For the sake of completeness, let me also mention that lock table transaction control statements, which allow you to specify locks yourself, can also be used to resolve external references when used in invoker's right programs. For all other statements, the privileges of the owner are checked at compile time and external references are resolved in the schema of the owner. So if you're directly calling another procedure or function or package in your invoker's right subprogram, the reference to these will be resolved like definer's right subprogram in the schema of the defining user. Let us understand it with an example. So here is the same function we looked at defined with the invoker's right class. Along with issuing the update to the employee table, our function update_emp also calls another function called get_emp_count inside it. The function is present in the demo schema. Let us say get_emp_count function exists also in the test schema. Here is our demo session. Now when from the demo session we call the update_emp function, the employee table reference in the update statement gets resolved to the employee table in the demo schema as before. Get_emp_count function also gets resolved to the get_emp_count function in the demo schema, as demo schema also happens to be the owner schema of the update_emp function. Let us say we have another session running as user test. Inside the anonymous block, it calls the demo.update_emp function, then as before, employee table reference gets resolved to the employee table in the test schema as it is used in an update or a DML statement, but the call to the get_emp_count function will resolve to the schema of the owner, which is demo in this case. This is one thing you need to be aware of. So there is a direct subprogram call as the function call in our example, which is not a part of the DML statement, but as a part of a SQL expression, it will always get evaluated to the subprogram in the schema of the owner. If you want it to be evaluated in the particular schema, then you have to qualify it like in our example test.get_emp_count to make it go to the get_emp_count function in the test schema. If you do not qualify it, then it will get resolved to the schema of the owner. However, if you invoke the function as a part of the SQL statement instead of calling it directly in an expression, you write it as SELECT get_emp_count into l_count FROM dual. Now since it is a part of a DML statement, references to get_emp_count will get resolved in the invoker's schema. So when demo session calls it, it'll get resolved to the function in the demo schema, and when test session calls it, then it will get resolved the function in the test schema. So this way both the update statement call and the function call get resolved to the invoker's schema. However, not all functions can be called from SQL statement, and it has to qualify the restrictions we talked about in calling functions from the SQL module.

Execution Flow Between Invoker & Executor

Let us now understand how the execution will flow when an invoker's right subprogram calls a definer's right subprogram. As a rule of thumb, remember that the definer's right subprogram has higher precedence than the invoker's right subprogram. Let us say we have again the two schemas demo and test. The demo schema has the employee table and the update_emp function, which is defined with invoker's right. Inside the update_emp function, it further calls a function get_emp_count, which is defined as definer's right. The function is directly called as an expression, which will always get resolved to the get_emp_count function in the demo schema. The test schema also has the employee table. It has the execute privileges to call the update_emp function in the demo schema. Let us say we have a session running as the user test where it calls the demo.update_emp function, the update_emp function being an invoker's right function runs under the privileges of the test session, and the update to the employee table will get resolved to the employee table in the test schema. Next it will call the get_emp_count function, which is defined with definer's right. I have just shown a small snippet of the get_emp_count function where it is getting the count from the employee table. The call to the employee table inside it will get resolved to the employee table in the demo schema since get_emp_count function is defined as a definer's right. So, when the test sessions calls an invoker's right program, the program will run under the privilege set of the test user and will resolve the external references in the DML statements and the dynamic SQL statements in the test schema, but when the invoker starts a program in turn calls a definer's right subprogram, it runs under the privilege set of the definer, which is demo, and the external references will be resolved in the demo schema. Let us now talk about the case when an invoker's right subprogram in turn calls another invoker's right subprogram. The update_emp function was defined as an invoker's right subprogram that called to the employee table and the update statement will get resolved to the test schema as before. Call to the function get_emp_count will get resolved with a get_emp_count function in the demo schema, but this time the call to the employee table inside it will also get resolved to the employee table in the test schema. So, when a session calls an invoker's right subprogram, it will run under the privilege set of the test user and external references will get resolved in the test schema, and, when the subprogram calls another invoker's right subprogram, then it will run under the privilege set of the invoker and external references in the DML statements, as well as the dynamic SQL statements will get resolved in the invoker's schema. And how about when the definer's right subprogram calls an invoker's right subprogram inside it? In that case, even the invoker's right subprogram will be called as if it was the definer's right subprogram, so a definer's right subprogram blankets everything under it to run as a definer's right. A definer's right always has precedence over invoker's right. Here, now we have defined the update_emp function to be a definer's right subprogram and get_emp_count, which it calls as invoker's right. If demo session calls update_emp, then since it is both the definer and executor, both the functions will operate up on the employee table in the demo schema, but say we have a test session, which calls the demo.update_emp function, which is definer's right, so instead of the update_emp function, the call to update employee will resolve the employee table of the definer, which is demo. Then the update_emp function calls get_emp_count, which is invoker's right, but since it is invoked from a definer's right subprogram, it will run under the privileges of the definer and external references to the employee table inside it will get resolved to the employee table in the demo schema. So when the test session calls a definer's right program, the program is run under the privilege set of the demo user and will resolve the external references in the DML and dynamic SQL statements in the demo schema, but when the definer's right subprogram calls an invoker's right subprogram, it runs under the privilege set of the definer, which is demo, and the external references will be resolved in the demo schema.

Demo: AUTHID Clause & Execution Flow

In this demo, we will take a look at how to define subprograms with AUTHID DEFINER and CURRENT_USER clauses, and examine their effects as far as privileges and external references are concerned. We will also examine the effects of an invoker's right subprogram calling a definer's right subprogram, and vice versa. I am currently logged in to the demo schema. Here I am showing the definition of the get_emp_count function, which takes in p_dept_id and returns a number. It is defined with AUTHID DEFINER clause. We first print using DBMS_OUTPUT inside the get_emp_count in the demo schema. Then we SELECT COUNT * INTO l_count FROM the employee table to pass to dept_id, fetching the count and l_count, which then we RETURN. Let us compile this. Here, we have a function update_emp, which takes in p_dept_id NUMBER and p_location, a VARCHAR2 variable. We have defined it with AUTHID CURRENT_USER clause. We define l_count, a local number variable. Inside the execution section, we update the employee table, setting the location to p_location for emp_dept_id equal to p_dept_id, using DBMS_OUTPUT.PUT_LINE to print the number of rows updated. We COMMIT a transaction, then we call the get_emp_count function, which we just took a look at, which returns the result, an l_count variable. We finally RETURN l_count. Let's compile this. Now here is another worksheet where I'm logged in as a demo user. Let's first see the count of employee table in the demo schema with dept_id 1. There are two rows. Now here is an anonymous block where we will declare l_count as a number. Inside the execution section, we'll call the update_emp function, passing in dept_id 1 and location WA. We then print Rows in dept_id 1 is, and then concatenate it with the value in the l_count variable. Let's run this. Update_emp, being an invoker's AUTHID clause function updates the count in the employee table printing Rows updated for dept_id 1 is 2. Then it runs the get_emp_count function in the demo schema, showing the function gets resolved in the definer's schema, which is demo. It returns the count of dept_id of 2 as expected. Let us GRANT the execute on update_emp to test. Here I'm in a session logged in as a user test. Let's first create the departments and employee table in this schema also. Let's not insert any row for dept_id 1, and insert for dept_id 10 and 20 instead, and _____ in those departments. Let's run this. Everything went through successfully. Here again I am in a session logged in as the user test. Let's also create an identical function, get_emp_count, in the test schema. Here we are printing inside get_emp_count in test schema to identify that it is the function in the test schema being called. It operates on the employee table in the test schema. Let's compile this. Now here is another test session. First, let's check how many rows are there in the employee table in the test schema where dept_id is 1. There should be no rows. As expected, there are 0 rows for dept_id 1. Now let us run this anonymous block where we call demo.update_emp function passing in dept_id 1 and location WA. Let's run this. Demo.update_emp is an invoker's right function, and so the update to the employee table happens in the invoking schema, which is the test schema in our case. Since there are no rows for dept_id 1, the number of rows updated for dept_id 1 is 0. Next, the get_emp_count function gets resolved in the demo schema from the output. It runs as definer's right and counts the employee in the demo schema for dept_id 1, which will return Rows in dept_id 1 is 2. So only the external references in the DML and dynamic SQL statements get resolved in the invoker's schema, but direct calls to the unqualified subprogram names always gets resolved in the definer's schema. Now back in the demo session, let us change the get_emp_count function to be an invoker's right function by using the AUTHID CURRENT_USER clause. Let us compile it. Running it in the demo session will give us the same results as before since both the definer and executor of the functions is demo and the employee table in the demo schema will be operated upon by both the functions. Let's run it. We see the same results as before where rows updated and selected in dept_id 1 is 2. Let us run it from the test session now. Since demo.update_emp is an invoker's right function, as before, Rows updated for dept_id 1 is 0, as there are no rows with dept_id 1 in the test schema. As before, the get_emp_count function inside demo.update_emp will get resolved to the function in the demo schema. However, since it is now also defined as an invoker's right function, inside it works upon the employee table in the test schema, which is the invoker, and now gives us the result of Rows in dept_id 1 is 0. So the external reference to a function in a standalone call always gets resolved to the one in the definer's schema, here demo, but the function is also an invoker's right, then it again looks up in the table of the invoker as here in the test schema. Now here in the demo session, let us modify the update_emp function so that instead of calling get_emp_count as a standalone function, we call it as a part of a SQL statement. So we call it here as select get_emp_count p_dept_id into l_count from dual. That will make it evaluate the external reference in the invoker's schema. Let's compile it. Now we are back in the test session. Let's run the anonymous block again. This time, as before, Rows updated for dept_id 1 is 0, as demo.update_emp is an invoker's right function, but now since get_emp_count is called as a SQL select statement, it gets resolved in the schema of the invoker, which is test, as indicated by the Inside get_emp_count in test schema DBMS_OUTPUT statement. There, as expected, it will find rows in dept_id 1 to be 0. Now back in the demo session, let us modify the update_emp function to be defined as AUTHID DEFINER. Get_emp_count is defined as an invoker's right function. Let's compile this. Let us now see how the resolution happens when update_emp, a definer's right function, calls get_emp_count, which is an invoker's right function inside it. Let us now go to the test session and run demo.update_emp function. Since demo.update_emp is a definer's right function, the employee table in the update statement will get resolved to the employee table in the demo schema, printing Rows updated for dept_id 1 is 2. Even though the get_emp_count function is defined with AUTHID CURRENT_USER clause, since it is called by a definer's right program, it will also run as a definer's right and will get resolved to the demo schema where it reads the employee table in the demo schema printing Rows in dept_id 1 is 2.

Direct Grants vs. Roles

Let us talk how roles and direct grants come into play when compiling subprograms. Let us first briefly talk about direct grants and roles. Direct grants is what we have been using so far to assign privileges to a user. Using direct grants, we explicitly specify privileges to a user directly. So let us say user test is trying to create a procedure using the employee table and get_emp_count function of the demo schema. Direct grants to these objects can be assigned to the test user by either a DBA or by user demo. GRANT SELECT, UPDATE, INSERT, DELETE on demo.employee to test will grant the necessary privileges on the demo.employee table to the test user. GRANT EXECUTE ON demo.get_emp_count to test will grant the execute privileges on the get_emp_count function to the test user. A role is a mechanism through which you grant multiple privileges to users in the database using a role name. A role can be granted to another role. These are typically created based on the functions users perform, or based on their business roles. For instance, you may create a role named accounting, grant to the accounting role appropriate privileges on the accounting tables and procedures, then, instead of providing direct grants to each and every employee in the Accounting Department, you just assign them the one accounting role. That way, if you add or remove privileges from the role, it reflects on all the users having that role, so it allows managing privileges at a group level. Continuing with the previous direct grant example, let us see how we can give the user test the privileges now using a role. A DBA will issue these statements. CREATE ROLE human_resources creates a role named human_resources. GRANT SELECT, UPDATE, INSERT, DELETE on demo.employee to human_resources grants the necessary privileges on the employee table to the human_resources role. GRANT EXECUTE ON demo.get_emp_count to human_resources grants the execute privileges on the get_emp_count function to the human_resources role. This way, grants for the table employee and function get_emp_count is given to human_resources role. Then the statement GRANT human_resources to test grants the role to test, thus assigning the privileges now using a role. When compiling subprograms using the AUTHID DEFINER clause, roles are disabled and only direct grants would work inside the subprogram. So here, user test starts a session and tries to compile a function, update_emp, referring to the demo.employee table and demo.get_emp_count function. If the privileges are granted through a role, then there will be compilation errors as Oracle will not be able to resolve the external references to the demo.employee table and demo.get_emp_count function. Only when data grants are made will user test be able to compile the procedure successfully. This is a very important concept to understand, and oftentimes developers stumble upon this. I think the rationale behind this is that typically there is one owner schema, or just a few of them, which contain objects, but there can be hundreds or thousands of users who could be calling or using these objects. Typically you would manage these consuming users en mass by using roles and would grant specific privileges only to the schema owners. This is because if we make changes to the privileges to a role, all effected subprograms would be marked invalid and would have to be recompiled. This is not a very efficient model for compiled ones and reused many times for subprograms. That will create a lot of overhead for Oracle to recompile these subprograms every time changes are made to the role. So that is why roles are disabled and only direct grants are used for compilation inside the subprogram with the AUTHID DEFINER clause. This allows you to make changes to the privileges assigned to the roles without effecting the subprograms, which is much more efficient. For invoker's right though, since a runtime evaluation of the privileges of the calling user is done, roles are enabled at runtime for privilege checking. Note this is a runtime check only and is not done at the compilation time. So for compilation, the compiling user will still direct grants in order to resolve references in the subprogram in order to compile it. So here, the user test is given direct grants to the demo.employee table and the demo.get_emp_count function, and it is able to successfully compile the update_emp function and its own schema. Now let us say we create a role hr_role to which we GRANT SELECT, UPDATE, INSERT, DELETE on the demo.employee table. Say we have another user dev in our system to whom we assign the execute privileges on the test.update_emp function. We also grant the hr_role to dev through which it gets the privileges on the demo.employee table. Now if user dev starts a session, it will be able to successfully execute that test.update_emp function. At runtime, Oracle will evaluate the privileges assigned to it via the role and apply them. This way, the user dev can still execute the update to the demo.employee table using its privileges it got via the role. As we noticed in this example, user dev was given direct privileges on just the update_emp function. Through hr_role, it got privs on the demo.employee table, but it was not given any privilege on the demo.get_emp_count function directly or indirectly, but it was still able to execute the demo.get_emp_count function through the update_emp function indirectly. However, if user dev tries to execute the demo.get_emp_count function directly, it will not be able to do so. This illustrates an important fact that only the privileges on the external references in DML, or dynamic SQL statements, are checked at runtime. For all other external references, like direct function calls, the privileges are checked at compile time, but not at runtime, and so for these the privileges of the compiling user are used to execute them. This gives you a fine-grained control of providing direct execution rights to a user on just a few appropriate subprograms, and allow only indirect access or execution on some of the programs through the direct access ones.

Demo: Direct Grants vs. Roles

In this demo, we will take a look at how roles and privileges come into play when we are trying to compile subprograms. Here, I'm logged in as a dba user. I'm first creating a role, HR_ROLE. Next, I GRANT select, update, insert, delete on demo.employee to hr_role. After that, I GRANT execute on demo.get_emp_count to the hr_role. Finally, I GRANT the hr_role to the test user. Now here I'm logged in a session as the user test, but I'm trying to create a function update_emp, which is invoker's right. Inside the function I am first trying to issue an update to the demo.employee table, and then later execute the demo.get_emp_count function, and this time the user test has privileges on these objects assigned to it via the hr_role. Let us try and compile this. We get an error at line 6 that table or view does not exist. Because the privileges were not directly granted, and as inside a subprogram roles are disabled, Oracle cannot resolve the references to these objects. Now let us grant these privileges to the user test directly and try compiling the function again. So I'm back in the dba session. Here I'm granting select, insert, update, and delete to user test directly, as well as granting execute privileges on demo.get_emp_count to user test directly. Let us run these statements. Now let us go back to our function and try and compile it. It compiles successfully this time. So to compile a subprogram, the compiling user needs direct grants to the referenced objects, and indirectly assigning the privileges through roles would not work. Now let me illustrate to you how roles are evaluated at runtime for invoker's right subprograms. The update_emp function we created in the test session is an invoker's right subprogram. Here again I'm logged in as a dba user. I create a role dev_role. To this role I am granting select, insert, update, delete on the demo.employee table. I then GRANT this role to the dev user. Finally, I GRANT execute on the test.update_emp function to the dev user directly. Let's run these statements. So looking at the function in the test session, we see that the dev_role has direct execute privileges to the update_emp function, but it has been indirectly assigned privilege on the demo.employee table through the role, and it has not been assigned any privilege to the demo.get_emp_count function, either directly or indirectly. Now I am in a session logged in as a dev user. If you previously had a session opened as dev, you would have to log out and log back in. Here, I have an anonymous block where I'm trying to execute the test.update_emp function and holding the return value in l_count. Let's run this. The anonymous block completes successfully, so even though user dev was not granted direct access on the demo.employee table, it was able to execute the update on it using the privileges it got through the role. It had no direct or indirect rights on the demo.get_emp_count function, but was still able to run it under the update_emp compiler's privilege. If you revoke the dev_role from the dev user and try and execute this anonymous block again, then you will run into errors with Oracle not being able to resolve the demo.employee table. So for compilation, be it invoker's right or definer's right subprogram, the compiling user needs direct grants to the referenced objects, but in case of invoker's right subprogram, during runtime, the invoker can execute DML statements on tables based on the privileges it acquires on those tables through a role. In the case of the definer's right subprogram, as long as it has execute privileges on the main subprogram, it will be able to call it, and once inside the subprogram, it'll always run with the privileges of the definer or owner of the subprogram. If user dev tries to execute the demo.get_emp_count function directly, it cannot do so as it does not have direct execute privileges, so this demonstrates how you can be selective in granting direct execute privileges. User dev was able to execute the same function indirectly via the test.update_emp function, but it cannot do so directly. This gives you a more fine-grained control in deciding how you want to grant access to subprograms whether directly or indirectly.

Summary

In this module, we looked at the important concept of name resolution. Using schema or packaged namespaces, you can create multiple subprograms with the same name. The order of resolution is always from the lowest level up, looking first in the local schema and then going up to the next level only if the object is not found there. AUTHID clause has two values, CURRENT_USER, and the default value of DEFINER. It recommends the privilege set under which a program is executed and the schema context for the resolution of external references in DML and dynamic SQL statements. The definer's right subprogram has a higher precedence than the invoker's right subprogram. During compilation, roles are disabled and only direct grants are allowed. For invoker's right subprogram, rules are enabled to check privileges on external references in DML statements at runtime.

Course author

    
Pankaj Jain
Experienced technologist, with expertise in various aspects of software development lifecycle, architecting software solutions and software development.
Course info

LevelIntermediate
Rating
(152)
My rating
Duration5h 10m
Released14 Jun 2014
Share course

