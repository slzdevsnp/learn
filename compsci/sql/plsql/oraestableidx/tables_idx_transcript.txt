
Code School
Oracle Developer Essentials: Tables and Indexes
by David Berry

This course covers the essentials of creating and managing tables in your Oracle database, including naming tables, defining columns, creating constraints and granting permissions. It also covers the basics of indexes, which are essential for...

Resume CourseBookmarkAdd to ChannelLive mentoring
Table of contents
Description
Transcript
Exercise files
Discussion
Learning Check
Recommended
Introduction

Course Overview

Hello, my name is David Berry. Welcome to this course on Oracle Essentials covering Tables and Indexes. In this course, we're going to primarily focus on how to create and maintain tables in your Oracle database. We'll talk about how to define tables, what are the naming rules you need to know, and what attributes can be used on your columns, like allowing or disallowing null values and specifying a default value for the column. We'll then move into a discussion about constraints that you can use on your tables. Constraints include primary keys, foreign keys, and check constraints, which are all important when it comes to maintaining data integrity in your database and throughout any applications that might be using your database. We'll then move into a discussion of the storage options for your table and this is where we start talking about how Oracle actually stores your data on disk. Depending on what type of data you have in your table, you may want to instruct Oracle to use some different options in terms of storing your data in order to achieve better performance. Next we'll discuss how to manage existing tables, like adding a column to a table or renaming a table or a column. Most databases are around for long periods of time. We will need to make changes to our table in order to support new functionality that is added. So we'll talk about how we do that. We'll then discuss some special table types in Oracle. The first is global temporary tables, which are Oracle's implementation of temporary tables, but they do function a little bit differently than temporary tables in other database systems. We'll also talk about external tables, which is a way that Oracle can read a flat file of data on your Oracle server and allow you to access that file from SQL just like it was a table in your Oracle database. Next we'll discuss indexes in Oracle. While most people think about databases as a way to store their data, what is also important is to be able to rapidly access the specific piece of data that need at a later time, and indexes are the structure that allow you to do this. So we will introduce what an index is, how it works, and how you build indexes for your tables. We'll then move into a discussion about how to secure your tables in assign permissions to different users by using privileges and roles in Oracle. This is not a course on Oracle's security, but you do need to understand the basics of how access controls work in Oracle and be thinking about these issues while you are designing your database. Finally, we'll discuss some good practices for building tables in your Oracle database. This course is actually the first course in a three-course series and, as we just discussed, we'll cover tables and indexes in this course. The second course is about data types in Oracle. As you build your tables in Oracle, you'll need to know what data types Oracle makes available to create your columns with. So that's the focus of the second course in the series. The third course in the series deals with other object types that you might find useful, and these are object types like views, synonyms, sequences, and triggers. Together, these three courses will provide you a solid foundation of what structures you can create in Oracle and how to interact with them.

Motivation

I always think it's a good idea to take a couple of moments at the beginning of a course and help you understand why it's important to invest a few hours of your time in taking that course. So let's do that and we'll start by understanding how a database like Oracle fits into your technology landscape. More often than not, data in any database will need to be accessed by multiple applications within the organization. These may be a mix of line-of-business applications, applications used by end customers like your website, or programs that extract data for additional analysis in reporting. In over the life of the database, it's highly likely that new applications will emerge that need access the data in your database, so in this way, your database becomes a hub of activity within your technology architecture, but you have all these different applications needing the access to data. The second point to consider is that data and the database they are contained in usually have a fairly long life span, often five or more years. Companies like to keep data for a long period of time and in many cases, this is important for regulatory reasons or a need to analyze and track data over that period of time. If you want an example of this, I just checked my amazon.com account and sure enough, they have a history of every order I've placed all the way back to 1998. So what do these considerations mean in terms of motivation for taking this course? First, by understanding the building blocks Oracle gives us, we can make sure to choose the right options when we are creating our tables. This makes us more efficient because we are not spending our time reinventing a piece of functionality that Oracle already provides. It also makes our database easier to work with, because functionality built into Oracle is already well-documented, well-tested, and well-understood. Creating databases that are easy to use is the second motivation for this course. This is an important consideration because our database will be used by multiple applications over its lifetime. We want to have a database that efficiently stores our data but is also easy for our colleagues to understand, so they can invest their time in building their applications and not deciphering how we chose to store some data or enforce a constraint. Finally, by understanding a little bit about how Oracle works, we'll make sure that we're getting the best performance possible out of the database. This is not a course on performance tuning, but the topic of performance will come up during the course and when it does, I'll help you understand what your options are so you can make the best decisions from a performance perspective amongst the options that you're presented with. If after this course, you have a continuing interest in performance tuning, we do have other courses here on Pluralsight that cover that topic in depth, including another course that I have authored.

Terminology

Before we dive in full force, I want to take a few minutes and define some terms that are commonly used when working with Oracle, so that as these terms come up, whether in this course or other reading that you may do on Oracle, you'll have a clear picture in your mind what these terms mean. The first term that I want to define is the term database object. When we say database object, we're using this term to generically refer to any structure within an Oracle database that can be created or owned by a user in Oracle. So what structures are included in this? These include tables, views, indexes, synonyms, sequences, store procedures, functions, packages, triggers, and about 10 more types of different objects in Oracle. So we just use the term database object to refer to all these different types of objects generically. That's a lot easier than having to spell out table, index, view, store procedure, and so on like I just did, each time. Saying database object isn't nearly as much of a mouthful. Another set of terms you want to be familiar with are users and schemas. A user is just a user within an Oracle database. Just like an operating system has users, so does Oracle. In almost all cases, you're going to have multiple users set up in Oracle and much like an operating system, you'll need to set up appropriate permissions, if you want these users to share data. In Oracle though, you're going to have a couple of different types of users. One is a user that corresponds to a person. For example, I might need the user ID dberry to login to Oracle, but I need to do some work and this is an Oracle user that's intended just for me to use. We will also have users though that are associated with applications or business processes, and these users are really centered around supporting just that particular application. For example, in this course I frequently will be logged in as a user named student, which represents an Oracle user that is responsible for owning and maintaining all the tables in a fictional university schema that we'll be using throughout this course. The user student is one of these application-type users. It makes more sense to have all of our tables and data owned by this application user student, than by an Oracle user associated with an individual person. Further, I will probably want to define some additional Oracle users for each application that accesses the data in my database, so I have a nice, clean separation between the user that owns the data and each user that needs to access the data. For example, if I have a web application that serves as a student portal, I'll probably define a second user, call this user student_web that will be used by my web application to login to Oracle and access this data. Again, this makes more sense than having the user of an individual person used by the web application and it also allows me to lock down some of the permissions on the user used from the web application, if there are activities that I don't want that web application to be able to perform. Now that we understand what a user is in Oracle, let's take a look at the term schema. The term schema refers to all of the database objects that are owned by a particular database user. These objects in a schema usually form some sort of logical grouping, like all of the tables, views, and other objects that are needed to support a particular application. So if I refer to the student schema, I am talking about whatever tables, views, procedures, and so on that are owned by the student user and all of these objects work together to support the process of registering students in courses at our fictional university. We could and most often do have multiple different schemas within the same Oracle instance. So, for example, we might also have an HR schema to support human resource functions, a facility schema to support various buildings on campus, and so on. Each schema is owned by a different user and forms a logically separate group within our Oracle instance. If you want to access an object that is in a different schema, first of all, you'll need to have appropriate permissions to that object. Second though, you will need to qualify the name of the object you are trying to access with the name of the schema. So I am logged on as the user dberry, and I want to access the courses table in the student schema. I need to write my SQL query like this, as shown on the screen, where I refer to the fully qualified table name student.courses. What this is driven by is the fact that the table I'm trying to access is owned by a different user and is in a different schema. There are some other approaches that you can take, as well, and we'll get to those later in the course. For now, the important thing to remember is that when you see or read the term schema, what someone is referring to is the collection of database objects that are owned by a particular Oracle user.

Course Conventions and Resources

For this course, you will see me primarily working in SQL Developer, what is a free Java-based SQL editor that is available from Oracle. If you have a different editor that you like to use like Toad or PLC Developer or even SQL*Plus, you'll be fine using those tools if you want to try to repeat any of the demos that I do or experiment on your own. I'm simply using SQL Developer because it's freely available and it's something that everyone has access to. You will also see me focus on the actual SQL syntax used to create and manipulate tables in Oracle. Most tools today do have a GUI editor where you can point and click in order to create or modify objects in your database. However, I believe understanding the actual syntax of the SQL is a more effective way to understand what the different options are and how you might want to apply them in the tables that you create. I also believe that if you understand the underlying syntax in what Oracle is doing, you'll have no problem transitioning to a GUI tool at some point if you decide to. Finally, there are going to be cases where you're probably going to want to script a lot of the commands that you see in this course or you're going to need to interpret a script given to you by one of your colleagues. And again, you're going to be better off if you understand the actual SQL statements that are being run by Oracle and how they behave. During this course, I will primarily be using a sample database of a fictional university for the examples. If you want to see the ER diagram of the complete schema, you can do so by going to the link on your screen. For those of you with a Plus membership, you can download the complete schema with sample data in the demos of this course so that you can load that data into a development copy of Oracle and experiment with it as you choose.

Oracle Resources

There are two sets of Oracle resources that you should know about as you are working with Oracle. The first is that Oracle provides extensive documentation for all of its products. The main page that you can get to all the documentation for Oracle 12c is provided by the link that you see on your screen and we'll explore that link in a moment. The second resource that you should know about is that Oracle makes available a few developer virtual machine images and these are available at the second link on your screen. These are very useful for when you're learning Oracle and you need a personal sandbox to play around in and not have to worry about breaking anything important. So let's take a look at these sites. I'm here at the page the first link on the slide takes us to and this is the home page for all of the Oracle 12c documentation and this is a page you probably want to bookmark. In this main panel on the right, we have the most frequently used documentation, but over here on the left we can expand out some of these nodes and we find there's a lot more documents that we can take a look at. So for someone like me who's primarily a .NET developer, we see by Clicking on this link this takes me to more documentation on using Oracle with .NET. While it's true that some of this documentation is pretty dry reading, it's also very extensive and Oracle does provide us lots of samples. So generally, it is pretty helpful to know about this site. If we go back to the main page, we'll see that there are two documents on this main page you probably want to check out to supplement your studies in this course. The first is the Oracle Concepts guide which is right here and if you're looking for a good general overview of Oracle, then this guide is a great place to start. The second manual that you want to be aware of is the Oracle SQL Language Reference. A lot of this course focuses on how to create objects in your database. There are, however, many more options than I'll be able to cover in this course and in that case, the definitive place to turn is the SQL Language Reference. So let's Click on the HTML version of this guide and go into it, and we can see the table of contents here. I'll open up one of these items and we'll see that we have the create table syntax, so we'll go take a look at that and we'll see the general documentation here. If we scroll down, we'll see these diagrams here and these are what Oracle calls snake diagrams. They do take some getting used to in order to read, but what they do is they give you the syntax of the statement and all the options that are available. So what we see here is that we have the basic format of the create table and if we continue to scroll down, we'll see all of the options and we can understand what the syntax is that we need to use in order to utilize those options. There's one last thing that I want to point out on this page and that's if we scroll back up to the top, we see up here that this document is available in not just PDF format, as well, but also Mobi and ePub format, so if you want to download this and put it onto your favorite eReader or tablet, you can do that and that's pretty useful in some scenarios. Let's jump over to the page with the virtual machines, which I have right here and what you'll see here is that we have a number of different virtual machines that you can download and the one you probably are going to be interested in for this course is the Database Application's Developer VM. The advantage here is that you can just download this VM, fire it up, and you're ready to go, and you don't have to worry about trying to go through the Oracle installation process. You can just utilize this VM. There are a couple of rerequisites. You're going to need to have Virtual Box installed. Virtual Box is a piece of virtualization software. This is available also from Oracle as a download and it is free, so you'll need to get that and put that onto your machine if you don't already have it, and then the second thing you'll need to do is you'll need to join Oracle technet in order to get these machines. That's a free membership again. All you need to do is go through and sign up. As long as all you're doing is using these machines for personal learning, there's not a cost to this and so this is a great way to gain some experience with the Oracle database products and also it's great just to have a sandbox environment on your local workstation for those situations where you just want to try something out and see how it works.

Summary

In this introductory module, we've covered the course outline and discussed some of the reasons why it is important to invest time in a course such as this. We also covered some basic Oracle terms that will come up through this course so you'll be familiar with those terms when you hear them, and, finally, I've shown you where there's some additional resources available directly from Oracle that can help to complement your learning, both in this course and as you move forward working with Oracle. In the next module, we'll dive into how to create tables and start covering some of the many options that are available to you.

Table Basics

What Is a Table?

Hello. My name is David Berry. Welcome to this module on Table Basics in Oracle. A table is the most fundamental data structure in Oracle, as tables provide the mechanism to store data in your Oracle database. So what is a table? Basically, it is a rectangular data structure designed for holding data. The columns of the table define the data elements that are stored in the table and each row represents one item in the table. So in this example, we need to store data about students in a fictional university. The columns represent the attributes that we need to keep track of for our students, their first and last name, their contact information, what they're majoring in, and so forth, and then each row in the table represents a single student. Any database that you work with is going to contain multiple tables that each store data for a specific type of entity or process in your application. For example, in the fictional university schema you see on your screen, we have tables that contain data on the courses that are offered, which courses are offered in a particular term, what degrees are available, and what courses are required to complete each degree of study. Each of these tables in our database not only stores data but maps to a concept or process within the business domain that we're modeling. Where the real power of a relational data model comes in is that we can define relationships between these tables, and then walk the tree, if you will. Starting from a department, we can see what degrees that department offers, then what courses are required for a degree, and finally, get a description of each course that a student must complete in order to earn that degree. Now this is not a course about data modeling, but what we do need to understand is how to translate what we have on our ER diagram into some real concrete tables in Oracle that we can use to store our application data. It's these tables that will serve as the foundation for everything else we do in our Oracle database. Tables are a big topic and it will take more than one module to discuss all of the aspects of tables you should be aware of. So let's take a moment to provide a breakdown about what will be covered in this module, as well as the following modules on tables. In this module, we're going to focus on the essentials of defining tables, including the basic syntax and the rules for naming tables in columns. We'll also look at your options around null values and default values for columns in your table. Then we'll wrap up with a discussion about when it's appropriate to use a null value versus a default value for one of those columns. In the next module, we'll talk about constraints, like primary keys, foreign keys, and check constraints. And finally, in the following module, we'll dive into some of the storage characteristics and options around tables. For now though, let's get started with the basic syntax of how to create a table.

Creating Tables

The first thing you need to be able to do in any database is to be able to create some tables, and what you see on your screen is the basic syntax for doing so. At the very top we have our create table syntax, followed by the name of a table that we want to create. There are rules about how and what you can name a table, and we'll get into those rules in detail in a moment. The next major section is the column definition section. This is where we tell Oracle the column names we use to identify each element of data and the type of data that we're going to store. We'll also let Oracle know if we can accept missing data for the column or if data in that column is required. The third major section of the table definition defines constraints on the data in our table, and there are three main types of constraints we'll define in this section. The first type of constraint is the primary key of the table. The primary key of the table is a column or combination of columns that will uniquely identify each and every row in the table and while you are not technically required to have a primary key, most experienced database professionals strongly recommend that you do have one on each table. The second type of constraint is a foreign key and foreign keys identify how data in this table relates to data in other tables. You may have a table that has no foreign keys, one foreign key, or multiple foreign keys, just depending on the role of that table. In our table here, we see one foreign key to the departments table and what this is telling us is that every course offered in our university needs to have a department associated with it and that makes sense. We can't just have courses existing out on their own. A course is offered by the physics department, or the chemistry department, or some other department on campus. The last type of constraint you're going to deal with are constraints on the data in your columns. You may wish to enforce a constraint like making sure that a certain number is in a certain range or making sure that an end date occurs after a start date, and these types of constraints are your opportunity to do just that. The final section of the table definition comes after the closing parentheses, and this section mostly deals with how Oracle's going to physically store your data on disk. Now this action is not required. If you omit it, Oracle will use some default values for all of the required parameters and in many cases, that is just fine, but there are situations where you want to provide your own values for some of these parameters to achieve better performance or perhaps save some space on disk. So we'll talk through these scenarios. Now there are a plethora of options when it comes to creating tables in Oracle, but we'll concentrate on the most important and most common ones that you're likely to encounter.

Naming Tables and Columns

Naming your tables and columns is a very important yet often overlooked activity. Good names clearly communicate intent, while poor names lead to confusion and can make your database much harder to work with. So what are the rules that you need to be aware of when naming a table, a column, or for that matter, any object in your database? First of all, the name of any object in Oracle can be a maximum of 30 characters long. When we say any object, we mean this applies to the name of tables, columns, views, indexes, and any other structure you might need to name in Oracle. Oracle also recommends that you stick to the ask key character set when naming items in your database, because this allows for the maximum compatibility across different platforms. Second, the names of Oracle objects must be unique within the name space of the object. For objects like tables, views, store procedures, and sequences, each object needs to be have a unique name within a user schema, so this means that for any given user, you can't have two tables that have the same name or a table in a view that have the same name. If you try to create a second object with the same name, Oracle will give you an error. Likewise, within a table each column needs to be uniquely named. You can't have two columns in the same table that have the same name. Finally, while it's technically possible to have an object name, like the name of a table or a column name, be a SQL user of the word, Oracle strongly recommends against this practice. It just doesn't make much sense to have a table named select or a column named insert, and all this is going to do is cause confusion. Now this doesn't mean that you can't use these terms in a compound word in a column name, say insert_date. It just means that you don't want to have anything in your database name using just the bare SQL keyword. When you name your database objects, you can do so in an unquoted or a quoted fashion. Any of these objects in an unquoted fashion is by far the most common and it is probably what you are used to and that's what we see in this slide. What you see here is that the name of the table and the names given to each column, we're not enclosing those names in any sort of quotes or anything like that. The reason why we can do this is because we have limited the characters we're using in the names of these objects. As long as you only use characters in the set of alphanumeric characters, the underscore character, the dollar sign character, or the hash sign character, you don't have to enclose the name in quotes. As we'll see on our next slide, it is possible to use other characters in the name of Oracle objects, but if you do so, you must quote the names. Another artifact of using unquoted names is that unquoted names are case insensitive. That is, it doesn't matter if I enter the name in lower case, upper case, or mixed case. Oracle interprets all of these as the same name and all of these statements will work together. Internally, what Oracle is doing is converting all the unquoted names to upper case, thereby removing any case sensitivity from the names, and what this means is that when you type your SQL statement, you don't have to worry about what case you're using. You can also choose to enclose the names of your identifiers in quotation marks and in doing so, there's more options available to you. As you see in this slide, I surround the name of the table in quotes, and now I can have a table name that is in mixed cased. By virtue of the name being in quotes, Oracle will then require this table be referred to in mixed case in any other SQL statements that I have. Also, I can include a space in the name of an identifier as you see that I'm doing here for the zip code column, and this is true not just for columns, but for the name of any object. I can even include punctuation characters in the name of an identifier, like I'm doing here with "city.name" and I'm not just limited to the period. I can also use a comma, a question mark, or even special characters like the percent sign. There is a down side to this though, and that is that if you choose to use these special characters or choose to use these mixed case names, you need to make sure that identifier is enclosed in quotes, not just in your create table statement, but in any other SQL statements that use that name or identifier. So you can see here in my select statement at the bottom of the screen, I've done this. If I did not put quotes around these names, then Oracle would return error, because it either wouldn't be able to locate the table or one of the columns in the table. This is a requirement, not just when you're working with tools like SQL Developer or Toad, but for whatever this SQL statement is being used. So if I was running this statement you see on your screen in a language like C# or Java, I would still need to have all of these names in quotes as shown here, but then, I would also need to escape those quotes within the string of the SQL statement in my programming language like C# so that these quotes would get passed along to the database. Let's take a look at some examples.

Demo: Naming Tables and Columns

Let's do a quick demonstration around some of the naming rules. First, we'll create a table using unquoted identifiers for the table name and all of the column names. This is probably what you're used to and what you're going to see most often. So let's go ahead and create this table and let's also put a little bit of data in this table so our select statements will return something. There we go. I'll clean this up here. Now we can use the following query that happens to have the same casing as our create table statement and as we would expect, running this query's going to work just fine and indeed, we get some data back, but we don't have to have the same casing in our SQL statements. So here, I'm going to bring in another query and you can see that we have one column in mixed case, we have a column in all upper case, one in all lower case, and then our table name is in all upper case, but if we run this query, this also works fine, as well. The reason is because when you're using unquote identifiers like this, Oracle removes any case sensitivity from the names of the tables or the columns, and this is true for other object types, as well, like views, or sequences, or store procedures, and so that advantage of sticking two unquoted identifiers or unquoted names like this is that you have this very simple syntax you can use in your SQL statements. Everybody says that the database world is a little dull, so let's get a little crazy with this next create table statement. Here you notice that all of our identifiers are quoted and this is because we're using some special characters in our column names and we want our table name to be in mixed case, so let's go ahead and create this table, and we see that indeed this does work. Oracle's created our table for us and so now we can insert some data like we had before. Notice here though that I needed to quote the names of my tables in columns, just like I did in my create table's statement and this is very important. When we're using special characters like what we have here, we have a space and a name, a period and a name, a percent sign, and then we also quoted the table name and that's in mixed case, and we have to make sure that our names match exactly what we had in our create table statement, including the quotes and all of that syntax. The same thing is true in a select statement. We can run this statement and we can see indeed that that does work, but if I come in here and I remove the quotes, and now if I'd run this statement again, we see that Oracle doesn't find a table and so I have to have the quotes on that table for this to work. The same is true if I come up here and I remove the quotes around one of these columns, again this doesn't work because Oracle's not able to figure out where this column is. Since the column contains a space in it, we've got to quote this column for Oracle to be able to be able to recognize it and that same thing would be true here for the other columns that we see. So I want to show you one more thing with quoted names and that's what you need to do if you have a table that you have to access data like this from an application programming language like C# or Java. So I'm going to bring up Visual Studio here and I have a C# program, which is going to access our zip codes table and we can see I have both ways of defining a string here in C#, both on a single line and a multi-line syntax, but what I have to do is I have to quote all those columns in Oracle, because otherwise we're not going to find our data, but then, because those columns have to be in double quotes, I have to escape those double quotes here in C#, and so now, I could run this program, and I'll bring the window back into where you can see it, and indeed, the program does work, but you're starting to see some of the issues with these quoted names. Yes, they do open up a larger character set for you to use, but at the same time, this comes at a cost of simplicity, so it's my recommendation that you steer clear of these quoted names in your database, if at all possible.

Defining Columns

The primary reason for having a table is to store data and at the heart of storing data is the definition of the columns that represent each data element that you can store in a row. You see on your screen the basic syntax for defining a column in a create table statement. We first have the name of the column, followed by the data type of the column, and then a clause indicating if the column can contain null values. We also see in the status_code column definition that we can specify a default value for a column that can be used if a SQL statement does not provide a value for this column. The maximum number of columns that you can have in any one table is 1,000, but for practical purposes, every table you work with will have far fewer columns. There are also good reasons from a performance standpoint to stay well below this limit. If your table has more than 255 columns, then Oracle will do something called row chaining, meaning the data from your row will be stored across multiple blocks, not just one block. What this means is that to read each row from your table, you will now need to incur a minimum of two IO operations rather than just one and that obviously has a negative impact on performance. Again from a practical point of view, almost any table you come up with will have far fewer than 255 columns, but do keep these limits in mind and regard this 255 number as a sort of soft limit that you really don't want to exceed. As for naming, the column needs to follow the naming rules that we just talked about in the section on tables. That is, a maximum of 30 characters and if you have any special characters, those will need to be quoted. In addition, be aware that column names need to be unique within a table, but you can reuse the same column name in different tables within your user schema. In fact, this is quite common amongst foreign key columns to have the column, in both the parent and the child, have the same name. At a minimum, you'll need to include a name and a data type for each column. The null clause and the default value are optional. Understanding how your database deals with null values though is an important aspect to consider when designing your database, so let's move into a discussion about null values.

Null, Not Null, and Default Values

For each column you create in your table, you can specify whether or not Oracle should allow a value of null for that column. You do this by specifying a clause of either null or not null in the column definition for each column. On the slide, you see that the student ID, first name, and last name columns are all specified as not null, meaning that these columns must always have a value. The column city and state have the null clause specified, so these columns can contain null values. Notice though that for the date_of_birth column, we aren't specifying any information about whether that column should accept null values or not. In this case, the column will allow null values. If you do not specify a null or not null clause, the default in Oracle is to allow null values. There is one special situation with null values that you should be aware of. For columns with the character data type, meaning CHAR, VARCHAR, VARCHAR2, and NCHAR, NVARCHAR and NVARCHAR2 counterparts, an empty string value is considered the same as a null value. So if you attempt to put an empty string value in one of these character type columns, Oracle will actually store this as a null value. This also means though that if a character type column is specified as not allowing nulls, you will get an error if you try to insert an empty string into this column, because for these columns types, empty string and null are one and the same. You can also define default values for columns. The syntax to do so is to use the default keyword, followed by what the default value is. Also note that the default keyword in the value needs to perceive the null or not null clause in the syntax, as shown here. Otherwise, you'll get an error. So you can see in this example, you added a column for enrollment status, and if we insert a record into this table and we don't include a value for enrollment status, either by not including that column in our insert statement or by specifying a null value, Oracle instead inserts the value of E into the table, because that's what we've specified as the default value in our table definition.

Demo: Null and Default Values

Let's do a quick demonstration of some columns that are defined as null, not null, and a column that has a default value. We have a simple table here and as you can see, we have three columns that require values, student_id, first_name, and last_name, as these columns are marked as not null. We then have three columns that will access null values, date_of_birth, city, and state. Remember if you don't specify a null clause in a column definition, like we've done here for date_of_birth, then the column will allow nulls. Finally, we have a status_code column and this column is not null, but more importantly for our demonstration, we have a value of A defined. As we'll see, this value is only used if a value for the status_code is not supplied. So let's go ahead and create this table, and now let's try an insert statement, but we'll deliberately leave out the last_name column, which is required, and so running this statement, we see that Oracle returns to us an error saying that last_name is required. We can't have null in this column and that's exactly what we would expect. So let's clean up our script window here and then we will fix out insert statement and we'll run this again, and now our insert succeeds, so let's take a look at that data in the table. And so there's our data. We see the DATE_OF_BIRTH, CITY, and STATE are all null because we didn't provide values and because these columns allow null values in the database. However, we do have a value in the STATUS_CODE column, even though we did not supply one, and this is because of the default value that we define for the status_code column. If we don't provide a value, we'll get this value of A inserted into this column for us. As we talked about in the slides, for character fields, Oracle treats empty spaces as a null value, so let's see an example of this. I've got a different insert statement here and as you can see, I'm supplying a value of Los Angeles for the city column, but for the state column I'm supplying an empty string value, so let's go ahead and run this statement and see what happens. All right, we see that a second row was inserted and now we'll query the data back out of the table, and we see that for the second student that we've inserted, we do have a value of Los Angeles for the city, as we would expect. But notice the value for state. Even though we supplied an empty string value, Oracle interprets this as null and indeed, it's null that we have stored in our table. Let's do one last insert statement and notice this time we're supplying a value for the status_code, a value of G. So in this case, we should see Oracle use the value that we've supplied for the status_code and not fall back to the default value, so let's run this statement and verify that, and we see that our row is inserted. We'll get the data back out, and indeed, we see that Oracle has used the value that we supplied from our SQL statement, the value of G, and there wasn't a need to fall back to the default value that we specified in our column definition.

Choosing Between Null and Default Values

In the last couple of segments, we've covered the syntax on how to accept or not accept null values and how to specify a default value for a column, but there is a bigger question than just syntax. Syntax gives you the options available, but what you really need to think about is how your application deals with data that is missing or undefined that could result in null values, and I'll say there is no universal answer for this. In many cases, I think the better approach is to have a column that will accept null values rather than a default value, but there are other cases where a default value makes more sense. In the case where you do not have the data, I usually feel like a null value makes more sense. In this case, null indicates that there is data that is missing or that the user hasn't filled out, and I think a null value communicates this better than some sort of default value. In this example, the table you see on your screen is using null to represent data we don't have. In this case, we have some users who've not provided a phone number or a city where they live, and I think it's pretty clear what's going on here. Null means that we don't have that data. Now we could use default values as shown in the lower table. What I don't like about this approach to missing data is that someone has to know what the special values are that represent the missing values. So in this case, a phone number of all zeros or a city name of UNKNOWN means missing values, but someone has to know that. I always dislike when we have these magic strings that make their way into a system. Now everyone using the database has to know what the magic string is for each column. I don't think that's very clear in terms of design. Another issue is that now in our application logic, we have to handle these special string values. If we imagine some sort of user interface that displays this data, it probably makes more sense than a missing phone number or city. We just wouldn't display anything at all rather than a phone number of all zeros or a city name of UNKNOWN. But now, our application needs to know about these values and intercept them, and I feel like this is bad design and leads to brittle code. A null value, on the other hand, is much clearer, in my opinion. A similar example is when we have a column for an event that is yet to occur. Take, for example, the canonical orders table with the columns you see here. For orders that we have received but yet to ship, I think it makes the most sense to have the shipping date column as null. That clearly communicates that this order has not shipped. You will see database designs that use a default value and in this case, the lower table, you see we're using January 1, 1900 as this default value. Here again though, someone needs to know that January 1, 1900 is a date that really means, This order hasn't shipped yet and we don't have data. So it becomes one of these special values. To me, this just does not seem as clear as using a null value for this column. That doesn't mean that null is the right answer in all cases though. Today, we have many online services that offer a free tier and then paid tiers of service that offer more functionality. Think of a service like Hulu, for example. You can sign up for Hulu for free and watch a limited number of TV shows online at a certain quality, or you can pay a monthly membership fee and view more shows across a larger range of devices. So let's imagine a table that holds membership information for such a service and we'll, of course, have a member ID, the member's name, email, and a column to indicate the user's membership level. In this case, it makes more sense to me to provide a default value, so in this table, the value F would be the free membership level, which is the default. That makes more sense than a null value in this case, because really, every member needs to have a membership level. In this case, trying to remember null means the free membership level, does not seem to communicate our intent very clearly, so in this case, I would favor a default value. So when it comes to your database, how do you choose? Again, there is no universal answer, but start with knowing your data, know what your data means, how it's collected, and how it's used. Understanding what your data means will help you choose a strategy that best fits each individual column. The second thing to keep in mind is that we're always trying to clearly communicate our intent. If one of your colleagues was looking at your database, what data would they expect to see in various scenarios, like a user not supplying a piece of data or a piece of data not being available. In knowing your data and how people will work with your data, you'll be better able to understand if a null value or a default value better communicate the business scenario you are trying to model in your data and ultimately communicate to the users of your system.

Virtual Columns

All of the columns we have looked at so far are physical columns, that is, whatever value is stored in the column is actually stored on disk in Oracle. In Oracle 11G, virtual columns were introduced, which allow you to define a column whose value is not stored on disk but is computed from other columns in the table. On the slide in front of you, you see an example of where you might want to do this. In this very simple orders table, we have columns that represent an order subtotal, the amount for the tax on the order, and the amount for shipping. It's quite typical that we would also want to include a column that would represent the grand total or the sum of all three of those previous values, and we can see in this table we do indeed have a grand total column, but it's defined just as a normal column. However, we're now responsible for populating the value of this column, keeping the value of the grand total column in sync, should we update one of the other values in those other columns, it will be taking up space on disk to store this value, even though this is simply a computed value from those other three columns. This is a case where virtual columns provide a better solution that we can use. What we can do with a virtual column is define an expression that will produce the value we want, as we see here. In this case, we are simply adding up the three other columns in our table. So in this case, we have the name of our virtual column, the data type of the column, the keyword as, and then the expression used for the computed value. All this is followed by the keyword virtual. As it turns out, the data type for the virtual column and the keyword virtual are both optional. If you don't include these, Oracle will infer the data type for you and that you want a virtual column by the fact that you have an expression in the definition. However, I always think it's better to say exactly what you mean, so I suggest that you include these so that your intentions are clear to anyone else who might be reading your SQL. We're not just limited to mathematical expressions, as we saw on the last slide. We can also use the result of a function in a virtual column. In this example, you see that I am using a combination of the end string and substring functions. Look at the domain name portion of an email address and make it available in a virtual column. So what this would do within that virtual column, you would have values like gmail.com or yahoo.com. Using functions like this is also accepted and you can use either built-in Oracle functions, like you see here, or your own user-defined functions. One note, notice that the function is wrapped inside a set of parentheses, just like the expression was, and this is required. So when we create a virtual column, what's happening behind the scenes in Oracle? First, know that the value of this column is not stored on disk as part of the table. It is computed on the fly for each row in your result set and you execute a query against the table. As you might suspect, you cannot directly insert or update a value on a virtual column, because this is a calculated value. If you try to do this in one of your SQL statements, Oracle will give you an error. You also want to know that values in virtual columns can only depend on column values in the same table. Oracle does not allow you to reference columns that are in other tables. Finally, you want know that it is possible to include a virtual column in an index that you create on one of your tables. In this case, what happens is Oracle will create a function-based index, will compute the value of the virtual column, and then it'll store that computed value in the index. For this to happen, the expression or function used for the virtual column must be deterministic. That is, it always has to return the same value for a given set of inputs. Function-based indexes are covered in more detail in the module of this course on indexes, but for now, know that it is possible to include virtual columns in the indexes that you create. In summary, what virtual columns give us is a nice clean way to handle these cases where we need a computed or derived value in a table. We can simply write a function or an expression that creates that value. We don't have to worry about keeping columns in sync or anything like that. Oracle will produce the derived value for us on demand when we need it.

Summary

In this module, we've covered the basics of creating tables. We've looked at the basic syntax used to create tables, the naming rules that apply to tables and columns, and how you can specify if a column can accept a null value and how you specify a default value for a column. In the next module, we'll continue our discussion by diving into constraints that you can place on the data in your tables.

Table Constraints

Introduction

Hello. My name is David Berry. Welcome to this module on Table Constraints. Constraints allow you to define rules that the data in your table needs to comply with. By defining appropriate constraints, you can help enforce business rules around the data in your database and ensure that the data you are collecting is clean and meets some minimum quality standards. For example, we might need to make sure that no two students have the same ID number at our university, as this would be confusing. We also need to make sure that every course we offer is associated with a department. We can't just have courses out in our database on their own. Constraints help us do both of these. We'll look at three types of constraints in this module. First up, for primary keys, which help you uniquely identify a row in a table. Then we'll talk about foreign keys, which are used to enforce data integrity between tables in a parent-child relationship. And finally, we'll talk about check constraints, which can be used to place some validation around the values in the columns on your table.

Primary Keys

A primary key is a column or combination of columns that contain a unique set of values that, in turn, will uniquely identify each row in the table. Often times in business applications that we write, we are trying to locate and act upon a specific piece of data in the database. Having a primary key is important because it allows us to uniquely identify the specific row of data that we're working with. You can have a primary key that is just a single column or it can contain multiple columns. Regardless though, the combination of values in these columns must be unique. Also any column that is part of a primary key cannot contain a null value. Null is the absence of any value and that doesn't work when you're trying to uniquely identify a piece of data. Why else are primary keys important? Primary keys also form the basis of the parent-child relationships between data we so often see in a relational database. The primary key represents the unique value of the parent object and this key value will be present in a child table as a foreign key value. So in the example you see on your screen, each student has a student ID number that uniquely identifies the student and this was the primary key of the students table. For other tables that contain data about students, it is the student ID number carried forward into those tables, so we can identify what student that data's for, like in this case, where it is used in the course enrollments table to identify what courses each student has signed up to take. There are two types of primary keys that you will encounter--natural keys and surrogate keys. A natural key is when you have a column or combination of columns that naturally occur in your data that form a unique key for your data. An example of this in the university schema is the combination of department code and course number. The combination of these two columns always represent a unique course, like MA101 always represents the course titled Calculus 1. The other type of primary key is a surrogate key. A surrogate key is when you simply generate the unique value for each row, but this generated value doesn't have any relation to the row or the data in the row. Often times you'll see a sequential integer used in a table as a primary key and this is an example of a surrogate key. When a new row is inserted into the table, the database generates the next sequential integer in a sequence and this unique value becomes the key for the row. Sometimes a surrogate key is used because no suitable natural key exists on a table, so you need to generate a unique value that can be used as a primary key. Other times, people may just prefer using a surrogate key because it might be easier to use a single unique value like a sequential integer to identify a row, rather than a combination of four or five different columns in that table. On the other hand, there are people that believe that you should never use a surrogate key if a natural key is available. A quick Google search will reveal multiple blogs, posts, and articles on each side of the debate. In the end, the choice is yours and you'll be okay whichever route you choose. If you want to know my preference, I do tend to prefer creating surrogate keys using an identity column or Oracle sequence in the tables I create. I think it's a little bit easier to work with. The real reason is that I'm a terrible typist and using a surrogate key allows me to type less when I'm trying to write queries in my SQL editor.

Defining Primary Keys

Let's see how we define a primary key in one of our tables. If we have a primary key that is composed of just a single column, we can define our primary key in line with our column definition, like we see on the screen. Oracle will go ahead and create the primary key and associated index on this column and this works just fine. There are really only two down sides to this approach. First of all, I cannot use the syntax for multi-column primary keys; that is, I cannot have the primary keyword after two or more column definitions. If I do, Oracle will give me an error. The second downside is that we're not supplying a name for this primary key, so Oracle will just generate a name for this key. This is fine, but sometimes it is nice to name your primary keys so when you see them in an error message or an execution plan, you know exactly which primary key is being talked about. If you have a primary key that has multiple columns, you need to use the syntax you see on this slide for defining your primary key. You could also use this syntax if you have to say single column in your primary key though, as well. You use the keyword CONSTRAINT and follow that with the name of your primary key. You then use the keywords PRIMARY KEY and follow that with the names of the columns that compose the primary key surrounded by parentheses. The order that the columns are specified will be the same order that the columns appear in the resulting index that is created. Now technically in this syntax, the constraint keyword and the name of your primary key are optional. If you do not include these, Oracle will generate a name for you for your primary key. Generally, the Oracle-generated names are something will start with the prefix sys_ and then a seemingly random collection of numbers. By using the syntax that you see on this screen, you can specify what you want for the name of your primary key and hopefully the index. It is my opinion that naming objects in your database is important, because this just makes your database easier to work with in the long run. So I've gotten into the habit of naming my primary keys and the convention that I use is the prefix pk_ and then the name of table for my primary keys. The last way to add a primary key is through the alter table syntax. What you do in this scenario is go ahead and create your table without a primary key and then, after the table's been created, you run this alter table statement to add the primary key. If the table is empty, Oracle will go ahead and just create the primary key. If there are rows in the table though, Oracle will check to make sure that the values in the columns specify in the primary key are unique and don't contain any null values. If the values are unique, Oracle will go ahead and create the primary key, whereas if they're not unique or they contain no values, then Oracle will generate an error message for you. Again in this syntax, the constraint keyword and the name of the primary key are optional. Also, you can use the syntax to create primary keys with either one or multiple columns. When I'm creating primary keys, I most often use the syntax on the previous slide and just create my primary key right along with the table. I do see this syntax used a lot in tools that generate DDL in order to create a database schema, either from an ER diagram or from exporting an existing schema. In the end though, there's really not much of a difference, as the results are the same and your primary key will be created. That covers the syntax for creating primary keys. So what are some of the rules that you should keep in mind for creating primary keys on your tables? The first recommendation I have is to make sure that every table in your database has a primary key defined. At some point, you're going to need to be able to uniquely identify a row in a table, often times, to update or delete that row. By having a primary key, you'll always be able to uniquely identify that row and that is reason enough to include one. If no natural keys exist on the data, go ahead and create a surrogate key by just using a sequential integer from an Oracle sequence or an identity column. In the end, this will make the table easier to work with. The second rule to follow is that you want the values you choose for your primary key to be immutable. That is, those values should never change. Most likely, your primary keys will be participating in foreign key relationships. Let's say you have a table of users for your system and you make email address the primary key for the table. Off of this main users table, you have several other tables that store the users preferences and history all tied together using the primary key of the user table, which is their email address. But what happens when the user changes their email address? Now you have to update not just the main table, but all of the child tables, so now this task is a lot more difficult. So make sure that your primary keys are immutable and this will save you a lot of trouble going forward.

Row ID

A topic that often comes up when discussing primary keys in Oracle is the topic of row IDs. Every row, any table contains a pseudo-column called ROWID. A ROWID represents the address of the row within the table. Encoded within the ROWID is sufficient information that Oracle can directly locate the row on disk. As such, as ROWID is unique for each and every row. We can view the ROWID by including the ROWID pseudo-column in a query like you see here on the slide. The values over here, these are the actually ROWID values that represent where that row is stored. Because ROWID is unique, some people are tempted to simply use the ROWID as the unique key on the table and forego a primary key. This is something that you should not do. You don't ever want to create a column that contains the ROWIDs from another table or otherwise store ROWIDs with an expectation that they can be used to locate a specific row at some later point in time. The reason for this is that it is possible for the value of the ROWID to change. ROWID is intended to be used internally by Oracle. While it is visible as a pseudo-column and you can select it in your tables, it is really not intended to used as a replacement for a primary key or as a value to uniquely identify your rows in your application. So if you're tempted to use ROWID in this way, pass on this, and go ahead and add an actual primary key to your table.

Foreign Keys

Foreign keys put relational in relational databases. It is through foreign key definitions that you specify how data in different tables relates to each other. This could be a course offered by a university department, the line items for an order, or the securities that are held by a brokerage account. All of these describe relationships that are ultimately represented by a foreign key in a database. So what is it that a foreign key does? Quite simply, a foreign key is a type of data integrity constraint that will make sure a value exists in a parent table when you try to insert a row into a child table. Take for example the two tables on your screen. The table on the left is the departments table that lists all the departments in our university, like math, computer science, physics, and so on, and the table on the right is used to store all the courses that our university offers. The courses table has a foreign key to the departments table on the department code column. What this does is to say that any course in our university must be associated with a department in our university. We can't have a course that exists out there on its own without a department. We also can't put any old value into the department code column of the courses table. It has to be a value that represents one of the existing departments in our university. It's the foreign key that enforces this data integrity relationship between these two tables. You define a foreign key on the child table that will reference the primary key in the parent table, and you do that using the syntax shown on the screen. First, we have the keyword CONSTRAINT and the name of the foreign key. Just like in our examples in the section on primary keys, the constraint keyword in any of your foreign keys is optional. If you don't include this, Oracle will generate a name for you. However, I do strongly encourage you to name your foreign keys with a meaningful name. Many tables contain not just one but multiple foreign keys. At some point, you'll have an error in your application about being unable to insert some data due to a foreign key constraint. If you have meaningful names assigned to your foreign keys, you'll be able to quickly tell which foreign key is causing the problem, so I encourage you to name your foreign keys in a meaningful way. Next, we have the keywords FOREIGN KEY, which indicates to Oracle that we're defining a foreign key relationship and then we have the columns in the child table that participate in the foreign key relationship and these are always enclosed in parentheses. For each column in the key in the parent table, we'll need a corresponding column in the child table, and we need to list these columns in the same order, such as they correspond to the order that the columns are in the parent primary key. And we don't have to name our columns the same between the two different tables, although this is somewhat of a convention in the database world. You see the last part of the definition. We have the references keyword, the name of the table that contains the parent key that we're refer- encing, and the name of the columns in the parent key in the parent table. If the primary key that we're referencing contains multiple columns, then we need to list all of the columns that are in the parent primary key, and we need to list them in the same order that they're defined in that parent primary key. We can also add a foreign key to an existing table using the alter table syntax you see on your screen. This syntax is essentially the same as the syntax that we just saw; it's just in an alter table command. If your table has data, Oracle will check for referential integrity when you attempt to create the foreign key. That is, if I ran this statement that you see on your screen and I had a row in the courses table with a department code value that was not in the departments table, then Oracle would generate an error and not create the foreign key. Again though, whether you choose to create a foreign key in your create table statement or use an alter table statement, there is no difference in the resulting foreign key that ends up being created.

Demo: Primary and Foreign Keys

Let's do a quick demonstration on primary and foreign keys. You see two table definitions on your screen and these are slightly simplified versions of the two tables we've been dealing with throughout the slides containing departments and courses. For this demo, there are two important things to note-- number one, on the departments table we have primary key over the department code column and secondly, the courses table has a foreign key relationship back to the departments table again on department code. So let's go ahead and create these tables. There we are and I'll insert some data to get us started. All right, so now we have three departments in there. Now remember, a primary key value must be unique, so that's the first thing I want to demonstrate. I'm going to try to insert this record into our departments table for the management department, but notice that my department code is the same as the math department. They're both MA, so if I try to run this statement, we see that Oracle gives me an error and the reason why is because I can't have two values that have the same value in my primary key, so I need a unique department code for the management department, so I'll go ahead and I'll change this to MG and I'll clean up the window so we can see this a little bit better, and if I run this again, now my insert succeeds. Let's move on to foreign keys and what I'm going to do is I'm going to use an insert statement to insert Calculus 1 into our courses table, so I'll get rid of this and there's my insert statement and now if I run this statement, we see again, that succeeds. When we ran this insert statement, Oracle validated that there was a record in the departments table with a code of MA and since there was that record there, the insert was able to succeed. However, if we tried the following statement, we're trying to insert a general chemistry course here from the chemistry department and run this, we see that this statement fails. The reason why is because, as of yet, we haven't defined our chemistry department up in our departments table. So when Oracle went up there to look for the code CH, it didn't find that code. That would violate referential integrity and so Oracle returns us back an error. So what we need to do in this case is we need to first insert a record for the chemistry department up in the departments table, which I'll do right now, and that's succeeded we see, and now I can go back and I can run this statement again and we see that also succeeded.

On Delete Cascade and Deferred Constraints

There are two additional options you should be aware of when you create your foreign keys. The first of these options is to create the foreign key with an ON DELETE CASCADE option. Using this option, if you delete a primary key value in the parent table, Oracle will then automatically delete all of the corresponding rows in the child table. So any example you see on your screen, if I decided to delete the physics department in the departments table using the SQL statement, Oracle would automatically delete all of the courses offered by the physics department down in the courses table, as well. If I were to choose not to include the on delete cascade clause in my foreign key definition, what I would need to do is to first write a SQL statement to delete all of the courses offered by the physics department from the courses table and then execute a delete statement against the department table to delete the physics department. One of the attributes of primary keys is that you cannot delete the record in the parent table if there are any child tables that have rows corresponding to that primary key value and that's for any table that has a foreign key relationship back to that primary key value in the parent table. So on delete cascade makes these situations a little bit simpler to deal with. On the downside though, it becomes very easy to delete the bunch of records and this may not be what you really want to do. The second option to be aware of is to make your constraints deferred constraints. With this option, we can tell Oracle to defer enforcing the constraint until the transaction is committed, not as soon as the statement is executed. The DEFERRABLE keyword tells Oracle that we want to have the option to defer this constraint and then we follow that up with one of two other options. If we use INITALLY IMMEDIATE, we tell Oracle to enforce the constraint at the statement level like normal unless we specifically instruct Oracle to defer checking of the constraint inside of our transaction and we'll see how to do that in a moment. If we use the INITIALLY DEFERRABLE keyword, then Oracle will always defer checking this constraint until the transaction commits. Note this is not turning the constraint off. All we are doing is changing when the constraint should be checked. So let's say that for some reason I want to change the department code of the computer science department from CS to CO. The problem I run into is that as soon as I execute this update statement, Oracle will give me an error because I have rows in the courses table that have the department code CS, and now these rows will be orphan records and that's not allowed. If my foreign key constraint is a deferrable constraint, I can use that capability to accomplish the update that I want to accomplish. What I need to do is the following: First, if the constraint is deferrable but immediately executable, I need to tell Oracle that within this transaction I want this constraint to be deferred until the transaction commits and I do that with this set constraint command. If my constraint is initially deferrable, then I don't need to do this. Then what I can do is update my record in the departments table, then run another update against the courses table and execute a command and it's only at this point that Oracle will check and enforce the constraint. Now you might be thinking that you've worked with databases that offer an on cascade update option, such that when you update your record in the parent table, in this case the departments table, these changes would automatically be pushed down to the child table. That is true that this is an option in some other database systems, but this is not an option that is supported in Oracle, so in these cases, if we want to update a parent row like this, we need to have constraints that are deferrable and make use of that capability. These are both options within the Oracle database and are fully supported by Oracle, but again, beyond the syntax in the mechanics of how you perform these activities, I would encourage you to think long and hard about situations where you might have to delete a primary key or change a primary key. If you're doing this once in a while to clean up data, that is probably fine. But if your design relies on being able to change primary key values and cascade these changes down to child tables or to delete a primary key outright and therefore a bunch of child rows, you probably have an issue in your design. If you were deleting primary keys, I would ask if it's really the right business decision to delete all of the data underneath the primary key. Perhaps it would be better to include some sort of status column on the row in the parent table, so you could mark these rows as retired or inactive and avoid deleting all of this data. If you're having to update child records due to primary key changes, then consider a surrogate key. These are very low-cost in terms of storage and they have a potential to simplify your application design in business processes, because now you can freely update data in your tables as your business requirements demand without having to go through all the ceremony of updating both parent and child records.

Demo: Deferred Constraints

Let's do a quick demonstration around deferred constraints. You see the departments and courses table on your screen and in this case, I've already created these tables in the database and populated them with some data. What I want you to note though is that here in the courses table, I've declared my foreign key constraint as deferrable initially immediate. So what this means is that by default, Oracle will enforce the constraint at the statement level, but within a transaction, I can change this constraint to enforce when the transaction commits. So let's take a quick look at the data in both of these tables. In the departments table I have three rows and in the courses table I have six rows, and you can see that I do have some child rows for each record that is up in the departments table. Now what I'm going to do is I'm going to try to update the department code for the computer science department from a CS to a CO, so let's go ahead and try to do that. I'll use this update statement and I'll try to run it, and we see here that the statement fails. Looking at our message, we see that Oracle's complaining that we have rows in a foreign key relationship, we have child records that have been found, so changing this primary key value, that would violate referential integrity and therefore, we've gotten this error message. I'm going to go ahead; I'm going to clean up this window here to make things a little easier to read. What we can do though, since we defined our constraint as deferrable, we can tell Oracle to hold off on enforcing this constraint until we commit our transaction and only check the constraint at that point. To do so, we're going to use the SET constraint statement like this, so I'll go ahead and I'll run this statement here and we see that we get a message from Oracle that this statement succeeded, so now let's rerun our update on the departments table, and now, we see that that statement succeeded. We did update one row on the departments table. Our work though isn't finished. We need to update those child rows in the courses table before we can successfully commit our trans- action, so let's go ahead and do that. There we go. We've updated both of the computer science courses down in the courses table and now we should be able to successfully commit our transaction and we can see that that commit is a success. So let's go ahead and take a look at the rows in our tables. We see there that the computer science department now has a department code of CO and down in the courses table, we also see a CO value for the department code on those two computer science courses. So there you have it, an example of how you can use deferred constraints to update a primary key value. Again, this is something you don't want to be doing all the time, but there are some situations where this can be very helpful.

Check Constraints

Check constraints are another way that you can enforce data integrity on the data in your table. Check constraints can make sure that the value in a column is within a certain range, validate the relationship between values in two different columns, or even validate the format of data in a column via a regular expression. However, check constraints cannot validate a columns value against data in a different table and they can't validate data against Oracle values like Sysdate. Still though, check constraints tend to be very useful in order to enforce data integrity rules in your database. You create a check constraint on a table by using the check keyword and then spelling out the constraint. As you've probably come to expect by now, the constraint keyword and the name for the constraint is optional, but always a good idea, so that if your check constraint fails, you can quickly discover which constraint failed. To the right of the check keyword in parentheses, we have the actual constraint and this is any expression that evaluates to a Boolean. So here, I am making sure that the course number specified is between 100 and 999, as we don't need anyone taking Physics -101 at our university. Another common use of a check constraint is to enforce that a column is in a range of values as seen on the slide. Here, we want to assign each state to a region and we want to make sure that the code used for the region is one of the values that's listed in the check constraint. You will also see this technique used to effectively synthesis a Boolean column in Oracle quite a bit. What I can do is have a number column of just a single digit and then use a check constraint to limit the value that's going to be placed in this column to 0 and 1, and this effectively makes a Boolean column for me. Another common use of a check constraint is to enforce the relationship between two values. Here, we see a check constraint, but make sure the ship date comes after the order date, because, after all, we can't ship an order to a customer before they've ordered it. Now again, in these types of constraints, you can only reference other columns in the same table. You're not going to be able to query data from a different table and use that in your comparison. You can only use columns in the same table. This still turns out to be very useful. One of the overlooked features of Oracle is that it does contain a package for performing regular expressions. If you aren't familiar with regular expressions, a regular expression is a sequence of characters that can be used for pattern matching and as such, you can construct sequences that will do things like validate the format of a phone number or make sure that a text field only contains alphanumeric characters, but not any special characters. I'm not going to go into detail about how to write regular expression in this course, but I do encourage you to check our Dan Sullivan's course here on Pluralsight on regular expressions, if you're interested in the subject. What I'm doing here is I'm using a regular expression to validate that the zip code that is entered is exactly five digits and this will prevent anyone from accidentally leaving a digit out or including an alphabetic character in the zip code. As we have seen before, we can add constraints and not just at table creation time, but, also, after our table has been created by using the alter table syntax as shown here. If the table is empty, then Oracle will just add the constraint. If there is data in the table though, Oracle will first make sure that all of the data in the table passes the constraint and only if all the data is valid, can the constraint be added. For this reason, it's always good to add a constraint up front, to make sure that you have clean data from the start. Otherwise, you might find yourself needing to perform some data cleanup before that constraint can be added. This wraps up our discussion of check constraints, but keep this in mind, because these are another tool in your arsenal to make sure that you have good, solid, clean data in your database.

Disabling Constraints

Once you've created a constraint in Oracle, it is possible to disable that constraint, whether a primary key, foreign key, or check constraint. When we say disable, we're talking about just turning constraint off so it is not enforced, not dropping the constraint altogether. To do so, you use the alter table syntax with the DISABLE CONSTRAINT keywords followed by the name of the constraint to disable. To re-enable the constraint, I use basically the same syntax, just replacing the word DISABLE with the word ENABLE. I would encourage you though, to be very judicious when you disable your constraints. Remember that to re-enable the constraint, Oracle will check to make sure that the data in your table complies with the constraint. So if you disable the constraint, you're going to have to make sure that you've dealt with any invalid data before the constraint can be turned back on, and sometimes dealing with that invalid data can turn out to be a much larger task than you anticipate.

To Use or Not Use Constraints

We've covered a lot of ground on data integrity, so let's wrap up the discussion with a few thoughts on how to use constraints in your database. Using primary keys, foreign keys, and check constraints, you have quite a few tools at your disposal to enforce data integrity in your database, and I would encourage you to make use of these tools. Data in your database isn't simply data; it's data that captures important aspects of how your business functions and how you've modeled your business in your database. There are rules around this data and constraints can help make sure that you adhere to those rules that govern your business. The first reason we want to enforce constraints in our database is to try to ensure that we have as clean of data as possible. Again, this is our business data, data that we will use to make decisions and data that is used in our business processes. Enforcing constraint helps us deal with any errors when the data is being input into our system, when hopefully a user can correct this data so our business process can function as intended. Clean data is also much easier to work with from an application perspective. While I do a lot of database work, most of my time is spent writing software as a software engineer. Too often times in my career I have seen exceptions thrown and programs crash because the application received data that it wasn't expecting and didn't know how to handle. Maybe this was a null value where it shouldn't have been, a string in the wrong format, or data that was in some other way nonsensical and the application didn't know how to handle it. Enforcing constraints on your data helps to enforce some consistent standards on the data in your database and by having consistent standards that we can count on, we can focus more of our energies on building applications that are performing useful business functions and less of our time coding for problematic data. Enforcing data integrity in constraints within your database, make sure that no matter what applications access your database, the constraints are enforced. We would like to think that all applications that are developed follow good practices, like input validation and checking of all the business rules on their data, but we know that this simply isn't true. By enforcing these constraints in the database though, we can make sure that those rules are enforced, even if the application fails too. On the other hand, enforcing constraints in the database is not a replacement for validating input in checking data integrity in your application. Persisting data into a table is often one of the last activities in a process flow and if we wait until this point to start validating our data, that is almost certainly too late. If the user has entered an incorrect value, we want to try to give them that feedback and an opportunity to correct that value as soon as possible, as this is less frustrating to the user. It is also just a general good practice to validate any data we receive from any external source in our application, whether a user, a file, web service, or other source, as soon as we get this data. Bad data isn't just a problem when it gets stored in the database. Bad data can be a security risk or cause an application to crash long before the application tries to write that data to the database. So while we want to enforce data integrity in our database with constraints like foreign keys and check constraints, we should realize this can't be the only place that we enforce these rules. These are just additional tools available to us in our overall strategy to ensure good data in our system. For a good overall system design, we should be enforcing data integrity both up in our application and in our database. We enforce constraints in our application code because we want to be able to provide some immediately feedback to our user if they've made an error or entered an illegal value. We also enforce these same constraints in our database to make sure that they're applied equally across all of our applications and all of the data in our database. Some people are concerned about the performance impact of enforcing the constraints in both places. I would argue that if your application and database are properly designed and you're using good data access and performance practices, this is really a nonissue. On the other hand, cleaning up bad data is very expensive and time-consuming, so I believe that you are better off taking a few milliseconds to enforce your data integrity constraints rather than having to spend hours later cleaning up bad data.

Summary

In this module, we've talked about the various types of constraints in Oracle, including primary keys, foreign keys, and check constraints. These constraints help us enforce data integrity rules on the data in our database, which ultimately should result in cleaner data. We also wrapped up with a discussion about why it is important to enforce constraints both in your database and in the applications that use your database. In the next module we'll continue our discussion of tables by talking about some of the storage options that you can include when defining your tables.

Table Storage Options

Introduction

Hello. My name is David Berry. Welcome to this module on Table Storage Options in Oracle. In the last couple of modules, we've talked about a number of options you have in creating your table in a logical sense. In this module, we're going to turn our attention to how tables work in a physical sense, that is, how your data is actually stored on disk and what options you have when it comes to how your data is stored on disk. It is often tempting to think about your Oracle database as a black box. I run a SQL statement and I either insert some data, update some data, or get some data back. And in doing this, you don't really have to think a whole lot about Oracle internals or how that data is being stored on disk, but we should at least understand the fundamentals of how the data is stored in Oracle and what our options are so we can use this knowledge to design a more effective system. In this module, we're going to first talk about how Oracle stores data at the lowest level in database blocks. We'll also give an introduction to how Oracle accesses this data. We'll then discuss tablespaces, which are a logical container where the table that indexes you create will reside. Then we'll discuss a concept called the high water mark, which you'll want to understand when working with Oracle. From here, we'll move onto some storage concepts related more directly to the tables you create. First, we'll talk about the parameters PCTFREE and PCTUSED which control the fill factor that Oracle will use for each block before it stops inserting rows into that block and starts using a different block. We'll then talk about row migration and how you can make sure to minimize row migration in the databases you build. We'll follow this up with a discussion of Freelists and finally, we'll talk about a situation called row chaining and especially about how you can avoid row chaining in your database.

Data Blocks

When we write an application, we often think in terms of rows. My application issues a select statement and Oracle returned me these 10 rows or a new user has registered on our website and I need to insert a row into this table to reflect this. Pretty much everything we do we're thinking in terms of rows. However, in a storage sense, that's not how Oracle works. If Oracle were to read and write every individual row to disk, this would be incredibly expensive in terms of IEO. Instead, Oracle works in terms of data blocks. A data block is the most granular level of storage that Oracle can retrieve from and save to disk. Within a tablespace, and we'll talk about tablespaces in a moment, all of the data blocks are of uniform size, somewhere between 2KB and 32KB. Having each data block be a uniform size makes it much easier and much more efficient for Oracle to manage the process of loading and storing data to disk. If you want a real-world analogy, think of a shipping container and a container ship. Having every shipping container a uniform size makes it much faster to load and unload the container ship and it also results in less waste because everything is the same size and fits together nicely. We don't have to worry about how to fit together a bunch of oddly-sized containers. Much like the actual cargo we care about is transported and stored inside of a shipping container, our rows live inside of database blocks and it is these database blocks that Oracle is loading and saving to disk, but the cargo of these database blocks is the data in your table. So what does the inside of a data block look like? First, we have the block header. You can think of this like the manifest for our data block. The first piece of information in the header is an indicator of what type of block we are dealing with. Data blocks are used not just to store table data, but also for index data and many other types of objects in Oracle. So one of the pieces of information contained in the header is what type of block we are dealing with so Oracle knows how to process the rest of the data in the block. The header will also have information about what database object it contains data for. So for a table data block, this tells Oracle the name of the table that the data block contains rows for. A data block will only ever contain data for one object. Finally, if it is a table data block, the header will contain a directory of all the rows contained within the data block. Altogether, this information generally takes a little bit over 100 bytes in the block, but this number can vary. So again, the header is much like a manifest that you might expect to find on a shipping container. In this module, we are specifically talking about tables, so any table data block we're then going to have actual row data. How many rows an individual data block contains depends on the size of the data block, the average length of rows inside, and how much free space we've instructed Oracle to leave in the block. So you could have tens of rows or thousands of rows inside of a single block, depending on what your data looks like. Lastly, we'll almost always have some free space in our data blocks, even for data blocks that are considered full. The reason why is that if we need to update one of the rows contained in our data block and that resulting update causes that row to take up more space, we need to have some free space for that row to expand into. How much free space that we leave for a situation like this is parameter that we control and we'll talk about that parameter later in this module. Now it may be that the free space is altogether in one part of the block or that the free space is divided into smaller pieces throughout the block, as shown here. This is of no worry to us because if Oracle needs to coalesce all of this space together, it will do so automatically for us.

How Oracle Accesses Data

Now that we understand that the rows of data our application uses are stored inside of data blocks, let's take a moment to understand some basic concepts around how Oracle loads data off of disk when it is needed. There are two primary ways which Oracle will access data-- a full table scan or the combination of an index lookup operation and a row lookup in the table. Understanding what each of the data access paths mean will be important as we continue our discussion of physical storage characteristics, so let's dig into each one of these a little bit deeper. In a full table scan, Oracle is going to read every block in the table and look through all of the rows in each block, looking for rows that match the criteria you have specified in your where clause. You can think of a full table scan like a linear search on an array. Now Oracle may not read all of the blocks in order, as is shown in the slide, but it will have to read through each and every one, similar to a linear search over an array where you visit each object in a data structure. For a table of any size, a full table scan tends to be expensive. First, you have the cost of reading all the blocks off of disk and then the cost of searching through each and every row. If you actually need a high percentage of the rows in the table, then a full table scan may be what is really required. In most cases though, you're probably accessing a small fraction of the rows in the table, which is where our next data access path comes in. We'll talk about indexes later in this course, but at its most basic level, an index is a data structure that is a tree. If you've taken any computer science courses on data structures and algorithms, you know that a tree structure can be traversed very quickly to find a specific value. If you have an index on the columns you are searching on in your query, then Oracle can use this to its advantage. What Oracle will do is traverse the index to find the node or nodes in the index that match the criteria you specified. In these nodes will be the row IDs of the rows that correspond to the values in the table you're looking for. Oracle can then use the row IDs to directly look up the data blocks that contain the matching rows and go directly to where the data block is located on disk. So while this is a two-step operation, this is often times much faster, because Oracle only has to read a few blocks from the index and a few blocks from the table. So overall, the amount of IO is much less, as well as the amount of data that Oracle must look through in order to find the rows that you really want. So how does this fit in to our discussion of physical storage characteristics of tables? What we'll see as we go through this module is that there are some situations that we encounter that apply to one data access path and not the other. For example, the problem of row migration impacts the performance of queries that are doing an index operation and subsequent row lookup in a table, but has no impact on a full table scan. So as we talk about some of these situations, it is important for you to understand the principles of how Oracle accesses your data so you have a frame of reference for the discussions we'll be having.

Ordering of Data in Tables

There is one last point I want to make about how Oracle accesses data and that is, you cannot assume anything about the order of the data, either about how to store it in a table or how it will be returned to you as the results of a query. This is something a lot of people have a misunderstanding about. They think the data is stored in a table in the order that it was inserted and therefore, it will be returned to them in that same order. If you do happen to get data back in that same order, this is just a coincidence. Oracle inserts data where it has space and that may or may not be in the order that it was inserted. We'll also see when using automatic segment space management, Oracle doesn't always start inserting data in the first block in an extent. It randomly selects a block. So for all practical purposes, don't assume there's any order into how your data is stored on disk. Secondly, there's no predetermined order to which Oracle will return data when it is queried from a table. On visualizations in courses like this or in books, we often show these nice drawings of how blocks are read from disk and the pointer moves nicely across the screen from left to right, but these are just visualizations. In reality, Oracle may return some blocks first because they're in memory or because the disk head happens to be close to where the blocks are physically located. What order the rows are in in the table makes no difference. What order the data is returned to you is essentially random. If you need a specific order then you need to include an order by clause in your SQL statement.

Tablespaces Introduction

When you create an object in Oracle like a table or index that requires physical storage, you don't directly tell Oracle where to store this object on disk or even what data file to store the object in. Instead, you specify a tablespace of where your object will be stored and this tablespace will map to one or more data files in Oracle. In this way, a tablespace is a logical container for your database objects. Having this logical container gives us a lot of flexibility. For example, we can add storage to a tablespace by adding an additional data file to the tablespace. This data file may be on a completely different disk, but that's okay because we have this logical layer defined in between. We also gain some benefits in terms of manageability. We don't have to manage all the low-level details about what data files have space available and where exactly Oracle should allocate blocks when it needs to add an extent to one of our tables. Instead, we just manage what tablespace we want to put our database objects in and Oracle takes care of all these low-level details for us so we can concentrate on bigger picture things, like how we're going to store the data that our application needs. There are two main items that we need to understand about our tablespaces. First, we want to know the block size for our tablespace. This is the size of the data blocks, those shipping containers that are allocated in our database, and this is going to be a value between 2KB and 32KB. Knowing the block size in the average length of a row in a table, we can estimate how many data blocks the table will consume, which is often important for understanding performance and just to estimate how much space a table will take on disk. We also want to know the block size of our tablespace so we can avoid a phenomenon known as row chaining. Row chaining is when a row in a table is so long that it will not fit into a single data block, so Oracle has to chain the row and store it over two or more data blocks. This results in an increase in the amount of IO that Oracle has to perform when it needs to read the row and is generally something that you want to avoid. We'll talk more about row chaining and its effects later in this module. Second, we want to know if our tablespace uses manual segment space management or automatic segment space management. Manual segment space management is the original implementation of space management in Oracle and as its name implies, it is very manual. Basically, we have a number of parameters that we can specify for a table to control how much space Oracle will use in a block before it considers the block is full and how many lists of free blocks Oracle should maintain for each table to support concurrent transactions. Now Oracle does provide default for each of these parameters, but basically, in manual segment space management, it's up to us to make sure that each table is configured correctly for all these parameters. Otherwise, we'll have a degradation in performance. Automatic segment space management was introduced in Oracle 9i and was designed to ease the administrative burden of managing the physical aspects of our database objects and allow Oracle to manage some of the parameters needed for a highly-concurrent database. Today, you are most likely using a tablespace managed using automatic segment space management. In this case, you control one parameter PCTFREE. All the other parameters Oracle managed for you, so it's important for us to know what type of tablespace we're in.

Assigning Objects to Tablespaces

If you looked at your entire Oracle instance, it would contain a number of different tablespaces. Some of these are reserved for use by Oracle itself, like the system tablespace, which contains data used internally by Oracle to manage the Oracle instance itself. Every Oracle database will also contain a tablespace called temp, T-E-M-P, which is used for temporary tables in Oracle. The temp tablespace is also used when Oracle needs to perform large sort or join operations that will not fit into memory. Finally, your Oracle database will contain some user tablespaces, which are used to store the data for your applications. It is possible that there's only one of these tablespaces, but most likely, most Oracle instances will contain multiple user tablespaces. Sometimes you'll have a situation where the DBA has decided to assign each application the database supports to a separate tablespace. Sometime you might see where the DBA has broken things out, so the different object types are stored in different tablespaces, like tables in one tablespace and indexes in a different tablespace. In any case, there will be somewhere that your DBA wants you to place the objects that you create for your schema, so it's important to know what tablespace this is. Every user in Oracle is assigned a default tablespace. When you are creating a database object that requires storage, if you don't specify a tablespace in the create table or create index statement, then that object will be placed in the default tablespace assigned to your user. Now it might be that your DBA has a couple of tablespaces assigned for use by your application and they want you to put certain objects or types of objects in a tablespace other than the default tablespace. That is possible, so let's take a look at how to do that. To create an object in a specific tablespace, you will need to include the tablespace clause in the storage clause of your table definition, as you see here. If you do not include this clause, then the object would get created in the default tablespace of the user that is creating this object. You'll also want to know that you can't just arbitrarily create an object in any tablespace you want. You will have to have rights assigned by your DBA in order to create objects in a tablespace. Now it is possible to move a table between tablespaces once it has been created, but while the table is being moved, you won't be able to execute any DML statements against the table, and also, when you're finished, all the indexes on the table will need to be rebuilt. So you do really want to get this parameter correct upfront when we define our table.

High Water Mark

When working with Oracle, you're going to hear the term high water mark, so let's take a moment to understand what this term means. Let's envision a series of blocks in Oracle that are all allocated to a single table. The high water mark is the highest-numbered block that has ever contained data in the table. So for a newly-created table, the block is at the left of the table because no data has ever been inserted into the table, and that is represented by the orange pointer on the slide. As you insert data into the table, Oracle will start filling up the data blocks one by one and as such, the high water mark will move to the right. So we see here that as our blocks in the table are used, the pointer that represents the high water mark moves right along with them. The high water mark keeps track of the highest block that is contained any data, not just the blocks that are full. So in this case, if the blue block represents a partially-filled block, maybe a block that contains even just one row, that doesn't matter. The high water mark is still to the right of this block. Now let's imagine that we delete some rows from our table and in fact, we're going to delete a lot of rows from our table, such that we clear out several blocks so that they are empty. Notice the high water mark did not move. That is because the high water mark keeps track of any block that has ever contained data and since each of these blocks previously contained data, they are still below the high water mark. The prior slide showed how the high water mark works in a tablespace using manual segment space management. This is good to understand because it gives you a good introduction to what the high water mark is. When you are using automatic segment space management though, things are slightly different. A table will contain two high water marks--a low high water mark and a high high water mark. All the data blocked below the low high water mark contain data blocks that have been formatted in either contained data or at one time contained data. The blocks between the low and the high high water mark are available to be used if Oracle needs space to insert additional rows into this table. However, these blocks may or may not have been formatted yet. When Oracle does need an additional data block to write data to, it will randomly select one of these blocks, format the block, and begin using it. As Oracle needs additional blocks to support data storage in the table, it will format the other blocks between the low and the high high water mark and begin using these. Once all these blocks are full, Oracle will move the low and the high high water marks up to the next group of allocated yet unformatted blocks to start the process all over again. The reason this is done is so that Oracle can better manage and allocate free space in the table in cases when we have multiple transactions all inserting data into this table at one time. Oracle manages all of this internally for you, but this should give you a good feel for what's happening behind the scenes.

High Water Mark Impacts

So how does this affect you when you're building your SQL statements in applications that work with Oracle? If Oracle need to perform a full table scan of all the data in the table, it must do so by reading all of the blocks in the table that are below the high water mark. This is because Oracle doesn't know exactly which blocks contain data, so it needs to read every block that it knows has contained data at one point in order to look inside and see if there's data in the block. So if there are a lot blocks in the table that are empty, this could be a lot of wasted effort on the part of Oracle. So let's say we had a table where we inserted one million rows of data and this meant we were using 10,000 blocks to store the data in our table, then we deleted all of those rows and we inserted just a single row into our table where the data was contained in just a single block, a representation of such, which is shown on the slide. If we ran a query that required a full table scan, Oracle would need to read all of the blocks under the high water mark and as you see, it would be reading a lot of empty blocks in order to do this. Having to read all of those empty blocks would degrade performance, because Oracle's reading a bunch of blocks that ultimately are of no use. Now is this something that we need to worry about? In most cases, the answer is no. Some data will get deleted from your tables. This is natural. Sometimes there may even be some data blocks below the high water mark that are completely empty due to this delete activity. Again, this is okay as long as they're a relatively small number. Over time, new rows will get inserted into the table and these blocks will get filled up with data again. If you have a table though where you insert a large number of rows, subsequently delete them, and then insert many fewer rows, you could see the situation arise where you're reading a lot of empty data blocks below the high water mark. In these cases, you may want to consider using a truncate command rather than a delete statement to remove all the rows from the table, and a truncate will set the high water mark back to zero. Note that truncate is a DDL command, so it will commit any open transactions and it cannot be used on tables referenced by foreign keys, but in many situations, using a truncate is possible and it will keep you from reading a bunch of empty blocks below the high water mark.

PCTFREE

What do we mean when we say that a data block is full? You might think that this means we have used up every last byte in the block, putting the maximum of amount of data that we can into each and every block. Generally, though, this is not a good idea, so let's see why. Consider the following table on the slide that represents some data about some students in our students table. More than likely, over the period of time these students are enrolled at our university, we're going to have to update some data for any given student. For example, the following two update statements will both increase the number of bytes needed for the respective rows that they update. In the first example, we have a student's last name that is changing and getting longer, resulting in a net increase in the amount of space, and in the second example, we're updating a field that was previously null to have a value, again, which results in more space being needed to store the row. If we jammed our rows into each data block as tightly as possible, then whenever an update against a row resulted in a total size of the row increasing, we would have a problem. Since this row now takes up more space, it can't fit into its existing spot in the current data block. So what Oracle has to do is migrate or move the data for this row to another data block. We'll talk more about row migration later, but this results in an additional IO operation when we update this row and whenever we need to read this row as a result of an index lookup operation. As we know, we want to minimize IO in order achieve the best performance possible, so jamming as many rows as we can into a data block is a solution that doesn't usually work out very well. What Oracle does instead is to leave a percentage of the space in each block free so that when updates do occur to the rows in the block, there's space available for the rows to expand into this free space. We can control how much free space Oracle leaves in each data block in a table by setting the PCTFREE parameter for the table. For example, let's say that we set the value up PCTFREE to 20, which is 20%. That means that Oracle will insert new rows into the block until the block is 80% full. At that point, Oracle considers the block full and will not insert any additional rows into this block. The remaining space in the block, that 20% that we set in PCTFREE, is reserved as room for growth for any of the rows in the data block. By default in Oracle, PCTFREE is set to a value of 10 or 10%, so if you don't specify a PCT value in your create table statement, you get this default 10% value. If you want to use a different value, you specify the value that you want to use in the storage clause of your create table statement simply by saying PCTFREE and then the value you want to use. PCTFREE is a value that applies both when you are using automatic segment space management or manual segment space management. In fact, when you're using automatic segment space management, this is the one storage parameter that you have control over that's not managed by Oracle. We'll discuss this more in the coming segments of this module, but we want to understand the data in our tables and how the data is updated so we can correctly set PCTFREE. If we set PCTFREE too low, we will have row migrations occur which results in a performance penalty. If we set PCTFREE too high, we'll be wasting a lot of space in our database. This can also have performance implications because if we have to do a full table scan of the table, now we'll have more blocks to read off of disk. So we're going to talk about a couple of other related concepts and then we'll come back and revisit this discussion of how to properly set PCTFREE for your tables.

PCTUSED

A parameter that is often mentioned with PCTFREE is the PCTUSED parameter. Unlike PCTFREE which applies in tablespaces using either manual or automatic segment space management, the PCTUSED parameter only applies to tablespaces using manual segment space management. So what does this parameter control? As we've discussed, rows are inserted into a data block up to the limit established by the PCTFREE parameter. At this point, Oracle marks the blocks as full and no new rows will be added to this block. Over time though, after the block is marked as full, some rows may be deleted from the table. What the PCTUSED parameter controls is the threshold for when Oracle will no longer consider this block as full, but will again insert new rows into this block. Let's say we have a table where PCTFREE is set to 20 and PCTUSED is set to a default value of 40. What Oracle will do is insert rows until the block reaches 80% full. At this point, Oracle considers the block full and will not insert new rows into this block, but only use the remaining free space for updates to rows already in the block. Now we start deleting rows, such that the utilization of the block drops below 40%, below our value for PCTUSED. If this does happen, then Oracle will no longer consider the block as full and again allow new rows to be inserted into the block. So if we have a table that we want to specify a value for PCTUSED, that is very straightforward. We just use the PCTUSED keyword followed by the value we wish to set in our create table statement. Again, this only applies to tablespaces using manual segment space management. If you're using automatic segment space management, Oracle manages this entire process for you.

Row Migration

When Oracle needs to update a row and the resulting size of the row is too large to fit in the free space of the current data block the row is in, Oracle must undergo a process called row migration, where it will move the data for the row into a new data block. Let's understand in more detail what happens during a row migration. Let's say we need to update the last row in the table on the left and as a result of the update, the size of the row is going to increase by an amount greater that the free space available in the block. What Oracle will do is pick up this entire row and move it to a new data block. Then Oracle will create a pointer in the original data block that points from the old location of the row to the new location of the row. The reason why Oracle does this is because any indexes on the table that point to this row are going to have the original row ID, that is, the original location of the row. So when Oracle performs an index operation that matches the row, Oracle will come to the original data block to read the row, but the row isn't in the original data block anymore so the pointer acts as a forwarding address for the row, because Oracle can follow the pointer to find a new location of the row. If you didn't have this pointer, then any time a row is migrated, Oracle would have to update all the indexes on a table, so this is a design decision within Oracle about how to handle these situations when a row needs to be moved from its original location. The net result of a row migration is that if you perform a row lookup from an index operation, you now need to perform two IO operations instead of just one to find the actual row. Oracle will need to read the original block and when it sees that the row has been moved, it will need to go and read the new data block to get the actual row data. So if we have a lot of row migration, we can see how this can be a performance penalty, because now we have to read additional blocks to get the actual row data on a high percentage of our rows. Row migrations do not affect full table scans though. In a full table scan, Oracle knows it's going to have to read the entire table, so it just ignores the pointers and reads all the blocks anyway. So row migrations are just an issue when we're fetching rows subsequent to an index operation. Now you might ask yourself the question, What happens if a single row has to be moved multiple times? That is, a row is migrated once to a new data block. Then the new data block fills up and we need to update the row again, so Oracle has to migrate that same row a second time. Does this mean that for that row there will be a list of row pointers that Oracle will have to follow? The answer is no. Oracle will go and update the original pointer with the address of where the row is currently located, so even if a row is migrated multiple times, at most, you'll be following the pointer once to the current location of the row. There are two scenarios that can lead to row migration. First, we can have a value of PCTFREE set too low for a table. This means that our rows are jammed into our data blocks too tightly, so even in the course of natural updates to our rows, we're going to have to be migrating rows because there's no extra space in the data block to perform these updates. The result is that a relatively high percentage of the rows in our table will have to be migrated and this is the type of row migration that we want to avoid. The second scenario is that there will always be some level of row migration that occurs in a table in Oracle naturally. Even when we do leave a reasonable amount of space in our data blocks, over the course of time, multiple rows may be updated and grow in size such that at some point an update will occur to a row so that it can no longer fit in the original data block and has to be migrated. If this happens to a few hundred rows in your table, this is nothing to be concerned about, as it falls into the category of "Don't sweat the small stuff." This is natural and you should not spend a lot of time worrying about it. So how do we get some metrics to know if we should worry or not about row migration? One metric Oracle gives us is how many additional IOs it has had to perform due to following pointers in migrated rows. The parameter is called 'table fetch continued row' and you can get this from the v$sysstat view. You will probably need some additional permissions granted in order to read from this view, so discuss this with your DBA. You can compare this value to the table fetch row ID value and that will tell you what percent of your row fetches involve migrated rows. This is a point in time value, so you'll need to run this query multiple times to get a measurement over some interval. Also, the value you get is database-wide, not just for your schema, but this does give you a good idea at a broad level if row migrations are something that you need to be concerned about. At the table level, you can look at the chain_cnt (chain underscore count) value in the user_tables data dictionary view. We'll talk about data dictionary views in another module in this course, but they contain useful metadata and statistics about all of the objects in your database. Chain_cnt is a value that combines both the number of migrated rows and chain rows, so know that this is a combined value. Oracle doesn't give us separate values. Also, it is accurate as of the last time that stats were gathered on the table, which was given by the last analyze date. If you do look at this value, and it is an appreciable amount of rows in your table, you'll want to consider if you have a row chaining problem, which we'll discuss in a moment, or if you're experiencing row migration due to the PCTFREE value on the table being set too low.

Guidance on Setting PCTFREE

So let's come back to this question that we asked before and that is, What is the guidance we should follow when setting PCTFREE for our tables? We know that if we set PCTFREE too low and the rows in our table need to be updated such as they expand in size, we will run into issues with row migrations. On the other hand, if we just set PCTFREE to a high number, we risk having a lot of partially-filled blocks in our table and this will be a waste of space. So let's discuss when it's appropriate to use different values of PCTFREE. There are times when a low value of PCTFREE makes sense, even potentially setting the value to zero to pack data in as tightly as possible. There can be some tables in our database where only insert statements are performed. We never update the data, therefore we never need to worry about a row expanding in size. We could also have a table where the only update statements that are run against the table do not affect the size of the row. Perhaps we have an update that just changes a code column from one value to another, but the row size stays the same. Examples of such tables might be a table used for application logging or many tables in a data warehouse environment. Often times, these tables are effectively insert only. We don't ever update existing data in these tables and when it comes time to delete data, we do so in some sort of bulk operation like by a date range, not row by row. So in these cases, a low or even zero PCTFREE value makes sense because we don't need to leave any room for row expansion and we want to maximize the amount of data we can put in each block. On the other side of the coin, we sometimes have tables where data is added to a row in the table incrementally and each update against the row in the table increases the row in size. We'll look an example of this on the next slide, but you sometimes see applications where as soon as a process kicks off, the application will insert a basic shell of a row into the database and then, as the process continues, that same row gets updated over and over again with more data each time. In this case, we want to use a high value for PCTFREE because we know that the row is going to expand many times from its initial value, so we want to make sure to leave room in the data block for this expansion. Let's take a look at an example of this. Imagine a process that allows users to sign up for a website and in this process, the user will be guided through several different web pages to gather their information. On the first screen, we may gather just the bare information to get the process started, like their name and email address, and then on each of the subsequent screens, we'll gather more and more information from the user. What is important is that after the user completes each page, the data for that user is going to be saved to the database. Some of the reasons to do this is because if the user quits the process somewhere in the middle, we still have some information about the user and if they come back, we can restart the process from the point they quit and not make them start all over again. What is important to picture though is that for the row that stores the data about a user what the size of the row might be at the end of each step, and we can see from the example numbers on the screen, the size increases significantly. So this is an example of a table where we'd want to use a high PCTFREE value to make sure that we had sufficient room for these rows to expand as the user moved through this process. These are the types of considerations that you want to keep in mind when you are setting PCTFREE for the tables in your database. It is especially important to know how the applications that use your database will insert and update data in your tables. If you aren't sure what value to use, don't be afraid to set up a database and run a test by simulating the insert and update of several thousand rows in the table. After your test, you can gather stats on the table and see if any rows are reported in the chain_cnt column of the user_tables data dictionary view and this will tell you if any rows have been migrated or you can afford to use a lower value for PCTFREE.

Freelists

One of the tasks that Oracle has to perform is to keep track of what blocks in a table contain unused space and can be used to insert new rows into. A freelist is a list of blocks that Oracle can use when it needs to insert rows into a table. Each table will have at least one freelist. If a table is going to have a lot of concurrent insert and update activity going on, then it makes sense to have multiple freelists for the table so that each concurrent insert or update statement can readily acquire a freelist of blocks to use for its DML activity. If you have a tablespace using automatic segment space management, this process is entirely under the control of Oracle. In fact, this is one of the big advantages of using automatic segment space management as Oracle automatically determines how many freelists it should have for each table and adjust this level as needed. In the past, the number of freelists for a table was often set incorrectly and this turned out to be a barrier to performance. But if you use ASSM, this is something you do not have to worry about. In manual segment space management, by default the freelist for a table is set to one. If you do have multiple concurrent processes trying to do inserts for this table, this can cause a bottleneck, because these concurrent processes can block trying to access the one freelist on the table. So if you are using a tablespace with manual segment space management, what you want to do is think about how many concurrent processes will be inserting or updating to each particular table at once and set the freelist parameter to this value. This will allow each one of these concurrent processes to get its own freelist so you can effectively support parallel DML activity on the table. To set the freelist value for a table, you need to use the storage keyword and the freelist keyword together, with freelist in the value you want to use, enclosed in parentheses, as shown here. So in this case, I am specifying 12 freelists for the course enrollments table. What I'm really saying here is that I think at any time I'm going to have a maximum of 12 students that are actually registering for courses and inserting data to the course enrollments table. Note, this is different than saying how many students my website or overall system supports. I may very well have hundreds of students online at any given time, but in this case, I am only expecting 12 of those students to be actually inserting their registrations to this table at any one time. Finally, remember that this syntax applies only if you're in a tablespace using manual segment space management. If you include a freelist value in an automatic segment space management tablespace, this value will simply be ignored by Oracle. It is also possible to change the freelist for an existing table by use of the alter table statement as shown here. This can be useful in a couple of scenarios. First, you may find that the freelist value for a table is incorrect. Maybe a table was created with the default value of one, but you really need this table to support multiple concurrent inserts. Another scenario is that you want to do a bulk load with a tool like SQL loader into a table. Tools like SQL loader support the concept of parallel inserts, so you want to increase the number of freelists on the table to take full advantage of this and finish the data load as soon as possible. So in both of these cases, you can use the alter table statement to adjust freelists. Of course, this only applies if you're using manual segment space management.

Row Chaining

We briefly mentioned the term row chaining earlier in the module, so let's go ahead and formally define what this term means. Row chaining occurs when a row in Oracle is too big to fit into a single data block. So what Oracle has to do is to chain the row across two or more data blocks. As a consequence of this, when Oracle goes to read the row, it has to read multiple data blocks to read just that one row. Even if you aren't using all the columns in the row in your SQL statement, that doesn't matter. However many blocks the row is chained across, Oracle has to read all of those blocks in order to work with the row. So as you can imagine, row chaining is something we want to avoid for performance reasons, because any row that is chained, we've doubled the IO that we need to perform in order to work with this row. So what are the events that lead up to row chaining occurring? Remember that when a tablespace is defined, a block size for the tablespace is specified and this is a value between 2 and 32 KB. So let's say, for example, we have a tablespace that has a 4KB block size, and in our database we have a table definition that looks like the one you see on your screen. As you see, we have a couple of columns in this table that are defined to accept up to 4,000 bytes. Let's assume for a moment that we're going to use a Western European character set so that each character is a single byte, and we can see right away, for any row that we have a description and technical spec values that add up to more than 4,000 characters, this row's going to take more than 4KB to store. Consequently, those rows would have to be chained, meaning they're stored across multiple data blocks. How can we detect if we have chained rows in our database? Obviously, one thing we want to look out for is any tables with a lot of columns and especially tables that have CHAR or VARCHAR columns that are long in length, as in over 1,000 bytes. Those tables are going to be at risk for row chaining, so these tables are where we want to focus our efforts to look and make sure that we don't have chained rows. Also know that any table with more than 255 columns will automatically have chained rows, regardless of the actual length of the row and its relation to block size. So you really want to make sure that your tables don't contain more than 255 columns. We can get a count for the number of chained and migrated rows in a table first by gathering statistics on the table and then by querying the user_tables dictionary view. Unfortunately, Oracle does not break out chained and migrated rows separately, so if you have a nonzero value in the chain_cnt field, don't immediately assume you have chained rows, but if you see a large number here, you may wish to investigate further, as we'll show on the next slide. If we suspect we have chained rows in a table, we can get Oracle to list those rows for us so we can inspect the rows and determine what we should do. To do this, you will need to have a table called chain_rows in your user schema defined as is shown here. The definition of this table actually comes from the Oracle script utlchain.sql, which is located on the database server at the path that's shown. You can either run that script or you can just define the table using the SQL you see on your screen. It makes no difference as long as the table definition is what's shown here. Then we want to run the command ANALYZE TABLE with the table name and the option LIST CHAINED ROWS. What this will do is put the row ID of any chained row into that chain_rows table. Once this is done, we can query this table just like we would any other table, so we could get a count of chained rows in a table or we could query the actual row data by using the row IDs that get stored in the chain_rows table to look up those rows. In this way, we can actually view the specific rows that are chained and see what data is driving the storage requirements for those particular rows.

Avoiding Row Chaining

Knowing that row chaining is something that we want to avoid due to performance implications, how do we avoid row chaining in the databases we build? The first answer is to make sure that we're using a sufficiently large block size for the tables we're building and the data that they contain. What we can do is look at our logical data model and for each table determine the expected number of bytes a row will consume, based on the data we plan to store. We do this by looking at each column, its data type in understanding how many bytes will be consumed by each column, and then simply adding those numbers up, and then we can work with our DBA to make sure that we're in a tablespace with a sufficiently large block size based on this analysis. This is one of the places where we don't want to treat Oracle as a black box, but instead, use our knowledge of the data model and the tables we're building so we get the correct physical implementation that we need. What type of database you're building will drive the block size number that you arrive at. For OLTP databases, block sizes of 4 or 8 KB are often sufficient, but for data warehouses, 16 or 32 KB is often a more appropriate choice. What about the scenario where we have an existing table that has chained rows and the tablespace this table is in has a block size that is just too small for what this table needs? In this situation, again, we want to understand how long those rows really are in a table. Then what we could do is talk to our DBA about creating a new tablespace with a larger block size, one that is sufficient for this table and we could then move this table over to that new tablespace. So in this way, if we already have a table that has chained rows, we can solve this problem. The last option we can consider is to vertically partition a table so that it can avoid row chaining. When we say vertically partition a table, what we mean is to split that single table into two or more tables with the columns being distributed amongst the tables. Often time what you do is put the columns that are used most frequently by your application in a table that you designate the primary table, which in this case is the table on the left. Columns that are used less frequently are put into other tables, which are secondary tables. Notice that when we do this, we include the primary key column or columns in each table. We'll have a one-to-one relationship among the data in these tables, meaning for every row in our primary table, we'll have a corresponding row in our secondary table. We'll also most likely have a foreign key between the tables to enforce referential integrity. From a database perspective, all we are doing is splitting some of the columns out to be in a different table. This can though introduce some additional complexity into your application, because you'll need to know what columns are in what table and create separate SQL statements for each table. But in most cases, the performance benefits you receive from vertically partitioning the table are worth the added complexity that is introduced if you can avoid row chaining.

Summary

In this module, we've covered some of the most important aspects with regards to how your data is physically stored in tables in Oracle. Many people are tempted to treat the database as a black box, but by understanding the concepts about physical storage, you will have a better feel for how Oracle stores your data on disk and how this data is accessed. We've also talked about how database objects in Oracle are placed inside of tablespaces and what properties of a tablespace we need to pay attention to. We've discussed what it means for Oracle to consider a data block to be full, what the PCTFREE parameter means, and how we can avoid row migration in the tables that we build. We briefly discussed freelists, which is important if you're using a tablespace with manual segment space management, because incorrect setting of the freelist parameter can impact you when you're trying to perform multiple concurrent inserts to this table. Finally, we talked about row chaining, why this is an important phenomenon to avoid, and how to make sure that you don't have row chaining in the tables that you build. If you want to continue to learn more about Oracle internal and the physical details of how Oracle works with data, numerous books have been written on the subject. I would suggest though that first you take a look at the Oracle Database Concepts Guide. This guide is freely available from Oracle on the web in HTML, PDF, and eBook formats. It contains a lot of good information on how Oracle's architected and will point you to other Oracle documentation as necessary. So if you do wish to continue your studies, don't overlook this resource.

Managing Tables

Introduction

Hello. My name is David Berry. Welcome to this module on Managing Tables in Oracle. At some point, you're going to have to do something like add a column to a table, rename a column, or change a data type. That is what this module is all about, managing the tables in your Oracle database once you have them created. We'll start off with a discussion of the Oracle Data Dictionary where you could find information about the tables and indeed all of the objects in your database. We'll then introduce the concept of database statistics and then talk a little bit about what database statistics are, what they are used for, and how they're collected. Then we'll move into a discussion about some commands that allow you to manage tables, including how to drop a table and rename a table. And, finally, we'll discuss how to manage the columns in your table, including adding a column, dropping a column, renaming a column, and making changes to its data type.

Introducing the Oracle Data Dictionary

Internally, Oracle contains a series of views known as the data dictionary that contain information about all of the objects within an Oracle database. You have most likely used a tool like SQL Developer or Toad, and these tools often offer a GUI interface that allow you to see all of the tables in your database, the columns in each table, your indexes, and so on. What these tools are doing is querying the Oracle data dictionary and putting a nice GUI frontend around this information for you. I'm not going to go through the graphic user interface of any of these tools in this module. I have no way of knowing what tool you have and in any case, you'll be able to explore whatever tool you have on your own. What I want to do though is show you some of the data dictionary views that are available in Oracle and used by these tools so you're familiar with how to get this information yourself. GUI tools are great but there are many times you'll need to write a customized query against these views to search for a particular value or you might want to format the data a little bit differently than what a tool does. So it's good to know about these views and what information they contain. There are three sets of data dictionary views and the difference between the sets is the scope of the objects that are available in each set. First, we have a set of views that start with a dba_ prefix. These views will contain information about all objects in Oracle, meaning objects in every schema and also information about all of the tables that Oracle uses internally. The second set of views start with a user_ prefix and in these views will be information about the objects the current Oracle user owns. Finally, the third set of data dictionary views all start with the all_ prefix and they will contain information about all the database objects that the current logged-in user has permissions to see. This would include all the database objects that user owns plus any objects in other schemas that the user has access to. So for example, the dba_ tables' views will contain information for all tables in the database. User_ tables will contain a list of only the tables owned by the current user and all_ tables will be all of the tables that the login user has permission to see. You'll always have access to the user_ and all_ views but unless your DBA has granted permission to you, most likely you won't have permission to the dba_ views. For the rest of this segment, I'm going to focus on the user_ version of these views but know to get for the other version of any particular view, all you need to do is swap out the prefix.

Useful Data Dictionary Views

So let's dive into some of these the useful data dictionary views that you should know about. The first view to be aware of is the user_ objects view. You will have a row in this view for every schema object that you own, including tables, views, indexes, store procedures, and functions. On each of these slides, I'm going to put a bit.ly link to the Oracle 12c documentation for the data dictionary view, in case you need to go and look at all of the columns that are available in that view. One thing to make sure of here is that you're looking at the documentation for the version of Oracle that you are running. As Oracle adds new features, these views do change a little bit, so make sure you're looking at the documents for your version of Oracle. What are some of the important columns in the user objects view? First, we have a couple of columns created in last_ddl_time and they tell us when the object was created and the last time it was modified respectively. The last_ddl column is especially useful if you suspect something in your database may have changed, as you can quickly do an descending sort by this column and find out the last objects that were changed and when. Also important is the status column. We'll see in a couple of segments, when you do something like rename a table, rename a column, or drop a column, you can cause any objects like views or store procedures that are dependent on the original object to become invalid. When an object is invalid, you won't be able to use it in any SQL statements or call that store procedure, or so on, so this view provides a quick way to see what objects may be invalid so you can get those objects updated as needed. Let's run a quick query against the user_objects table so you can get a feel for what kind of information is out there and available. So there we go. This is against our university database and we can see we have all the object names over here. We can see the object types right here, the date that things were created. It looks like most of these items were last modified on the date that they were created, but there is one object here that has been modified since then, and it looks like that all these objects at least right now are valid. Another important view to be aware of is the user_tables view, which will contain one row for each table in your user schema. It also contains some statistics about your table, like the number of rows, the average row length, and the number of database blocks the table is using. What is important to know is that these stats are not updated on a continual basis, only when you gather stats on the table, and the last analyzed column will tell you when that was. We'll cover how to gather stats on a table here in a moment but for now, just know that these values are based on the last time that stats were run against the table, which is given in the last_analyzed column. We'll run a quick query again against the user_tables view so you can get an idea of what data is out there. So here we go. Here are all the tables that are in our database and we can see a variety of tables here. If we scroll out here to the right, then we see some of the storage information and we also can see all the parameters that this table uses are also available in this view, so if we have any questions about how this table is set up, we can come and look in this view and get that information. There is also a view called user_tab_cols and this will contain a row for each column that is defined in a table or view that is owned by the user. This is an important point to remember. This view does not just contain entries for columns in tables but also contains entries for columns in views, as well. One of the things that this view is useful for is if you need to search for a column with a particular name, it's very easy to write a query against this view and find out what table or view that column is in. We also see some statistics for the values in the column, like the number of distinct values and the number of rows in the table, which have null value for the column. These values are again based on the database statistics we talk about in the last slide, so these values are only as recent as the last time stats were gathered on the table. It is useful to know though that these views make this information readily available to you. If you need to know what constraints are present in your database or on one of your tables, you can look at the user_constraints view. This will list all types of constraints in your database, including primary keys, foreign keys, check constraints, and other unique keys that you may define. There will be one record for each constraint, so you can filter by table name and get all the constraints on a particular table. If you look in the Oracle documentation, it will list what code is used for each constraint type, so you can interpret the values in the constraint_type column. This view is useful for when you need to find all of the foreign keys on a table or when you have parent table that you want to know all of the tables that have foreign key references back to that parent table. You can easily answer these questions by writing a query against this data dictionary view. The last two data dictionary views we will look at, are related to indexes and they are closely related to each other. First, we have the user_indexes view and this will list all of the indexes that belong to the current user. It will also tell you what tables those indexes are on. We'll talk more about indexes later in this course, but what we will find is having a properly indexed database is the key to getting good performance out of your database. We do see that in this view, we have some other information that tends to be useful, as well, like the number of distinct keys in the index. Like the stats in the user_tables view, this number is updated whenever you gather stats on the index. So also be sure to look at the value of the last analyzed column to make sure you're looking at recent information. The final view we're going to look at is the user_ind_columns view. In this view we list all of the columns that are part of an index, as well as what position within the index the column is. This view is useful for joining to the user_indexes view to understand the indexing on a table and also allows you to quickly see if you have multiple indexes that are very similar in nature because if you do, you might want to reconsider if all of those indexes are needed. We've only touched the tip of the iceberg, as they say, as there are many more data dictionary views that are available in Oracle. You'll find it worthwhile if you invest some time over a couple of lunch hours just getting familiar with all of the data that is out there and writing some queries against these views. At the link on your screen, I put an abbreviated list on my blog of the data dictionary views that I tend to look at most often. As part of this list, I have links back to the Oracle documentation. So again, just take a few moments to see what is out there and you will find that in some situations, it's very useful to be able to go after this data directly.

Database Statistics

We've had the topic of database statistics come up a couple of times, so let's go ahead and define what we mean when we say database statistics. If you could imagine the life of a SQL statement in Oracle, it would look something like this. What is important to us in this diagram is the second step where Oracle determines how to most efficiently process your SQL statement. Unlike languages like C# or Java or C++, SQL is a declarative language. That means you say, This is what I want to happen; process this query with this where clause and return me these columns, and then the database, in this case Oracle, is responsible for figuring out how to most efficiently make that happen. To do that, Oracle contains a sophisticated piece of software called the Oracle optimizer. What the Oracle optimizer does is look at your SQL statement and consider all the different ways it could be processed, like reading entire tables, using an index to look up rows, or how to join different tables together, and what it comes up with is the execution plan, which is going to be most efficient for your statement. How does the Oracle optimizer determine the most efficient way to process your statement? It looks at database statistics. They're stored on every table, column, and index in your database. These statistics tell the optimizer things like how many rows a table has and how selective an index is. What this allows the optimizer to do is to estimate how many blocks it must read and how much processing Oracle must do for each option it considers, and then the optimizer will choose the lowest cost plan. So these database statistics are critical to this query optimization process, because if Oracle has incorrect data, there's a higher likelihood that Oracle will make a poor choice when it comes to choosing an execution plan. In the previous section, we saw some of the data Oracle collects as statistics on tables, columns, and indexes, but how do those statistics get there? There are two ways. First, the Oracle scheduler will automatically gather stats on a routine basis for objects in your database. What it will do is look periodically at all the objects in the database and the amount of activity against those objects to see if there's been enough changes to warrant running statistics on the object again. This generally does a very good job of keeping statistics up to date on all of your objects and is completely transparent to you. So generally, you don't need to worry about this. You can though instruct Oracle to gather stats manually by using the DBMS stats package. The reason you might want to do this is because you've just loaded a large amount of new data into a table, just deleted a large amount of data from a table, and you don't want to wait for the automated processes to run. Another reason could be that you're in a test environment and you want to try some things out or perhaps you just looked at the last analyzed date on a table and you saw that it was a fair bit in the past, so you want to make sure that things are up to date. On your screen, you see two of the most common functions that are used in the DBMS stats package to gather statistics. The first command will gather stats on a table and all of the indexes that are attached to that table, and the second command will gather stats for all objects in the specified user schema. Do know though that if you gather stats on every object in a schema, this could take quite a while, so you may not want to run this in your production environment, and if you do run this in a test environment, you might need to be prepared to wait some time if you have a database of any size. As you see, you can pass Oracle a value for the percentage of rows to sample in your table, and this is useful if you have a large table with a uniform distribution of data. Oracle doesn't have to read the whole table to get the statistics. This is an optional parameter and if you do not include this parameter, Oracle will compute statistics over the entire table. There are many more options and you can see these on the documentation page for the DBMS stats package, which you can get to using the provided link. Once you gather stats though, you'll know that the data in your data dictionary views will be up to date for those objects.

Dropping a Table

One of the tasks that you will need to accomplish if you work with Oracle for any length of time, is to drop or delete a table. To do so, the syntax is very simple. You just say DROP TABLE and then the name of that table. You do need to know though, that if you have tables that have foreign key dependencies on the table you're trying to drop, then running the above command will result in an error. So in this example, where both the degrees and the courses table depend on the departments table, running this statement on the slide would result in an error. We have two choices to address this problem. We could drop the dependent tables first and then drop our table. The problem we run into though, is that it's possible and perhaps even probable, that the dependent tables you need to drop have dependencies of their own, and then we will need to drop those dependent tables, as well. So we could end up dropping a sizeable portion of our database, which may not be what we really want to do. Our other choice is to include a cascade constraints clause in our dropped table statement. This will drop our table and also drop the foreign keys that depend on this table. The dependent tables will not be dropped, just their foreign keys to the parent table will be removed. So in this case, you could drop the parent table, recreate it, and then re-add the foreign keys to each of the child tables as required.

Making a Table Read Only

You may have the need to make a table in your database Read Only and you can do so with the following syntax of the alter table statement using the keywords READ ONLY in the command. When you put a table into read only mode, Oracle will not allow any DML statements like inserts or updates to run against the table. If you attempt to run a DML statement against the table, Oracle will give you an error. Also, you will not be able to truncate the table and you'll not be able to add or remove columns from the table. However, it is still allowed to do things like add an index to the table, because this does not affect the actual data in the table. If later you need to change the table back to where you can manipulate the data in the table, you again use the alter table syntax, this time with the READ WRITE keywords. So if you have a table that you want to make sure no one accidentally changes data in, you could make that table read only. If there is occasion where you do need to update the data in that table, you could change the mode back to read write, perform your updates to the table, and then flip the table back to read only status. Such a strategy would make sure that a table is only updated during a certain processing window, if that was a requirement that you had.

Renaming a Table

If the occasion arises that you need to rename a table in Oracle, you can do so using the rename command. What you do is simply say RENAME, the name of the object you wish to rename, the keyword TO, and then the new name of the object. So in this example, I am renaming the departments table to just d-e-p-t-s. The syntax you see here works not just for tables, but also for other object types like view, sequences, or private synonyms. When you rename a table like this, Oracle will automatically take care of all the table constraints and indexes on the table and point them to the new name. However, any views, store procedures, functions, or synonyms that reference this table, Oracle is not able to automatically fix these. Instead, what Oracle does is mark these objects are invalid, and then you need to go and update the definitions of these objects with the new name of the table. How do you know which objects are invalid? The easiest way is to query the user_objects data dictionary view and look at the status column for any object with a value of invalid, and then it's up to you to go and fix these objects. The other consideration, of course, is that if you have any SQL statements that are in languages like C# or Java, clearly Oracle will not be able to access and update that SQL, so again, this is something you'll need to undertake on your own to get all of these SQL statements updated. Otherwise, your data access code is going to fail. For this reason, you'll find that if you do rename a table, it's most often when you're just setting up your schema and trying to get things to work, not when you have a database running in production and lots of data access code already developed. In these cases, if there was a table name that you didn't like and wanted to rename, you'd probably be best off using either a view or a synonym just to provide an alias to the table. Let's do a brief demo of renaming a table.

Demo: Renaming a Table

Let's do a quick demonstration of renaming a table and evaluate some of the impacts of doing so. We have our usual two tables at this point, departments and courses, and as we recall, courses has a foreign key backup to the departments table. In addition, for this example, I've created this view called computer science courses and all it does is join these two tables together and filter the data so we're only going to see the computer science courses in this view. We haven't covered views yet in this course, but all a view really is is a database object that encapsulates a query for us. So to get started, let's go ahead and do a select from this view and see the data in it, and there we go. We can see that we have just two computer science courses in there, and now let's go ahead and rename our table, and there we go. We see that our rename command succeeded. We can verify this if we go and try to select from the old table name. We see that there's nothing there. That table doesn't exist anymore. But if we try to select from the new table name, there we go. We see our data. So our rename table has been successful. However, let's go back and try to select from our view again. Ah, and we see that we have a problem here. The issue is that when we renamed our table, we made this view invalid and we can verify that if we go and look at the user_objects data dictionary view. We see right here is our view in line number two, and I'll scroll out here to the right and we see that the status of that object is invalid and the problem here is that Oracle doesn't know how to handle this table rename command that's happened. That's something we manually have to do ourselves. So let's go ahead and do that, and the way we do that is we'll go back up here to our create view command, and we notice that this is create or replace view, and we need to come in here and we need to fix the name of the table to where it matches what exists now. We'll run this command. There we go. We see that it succeeded. We'll go and look in user objects once again, and scrolling out to the right, we see now that that is indeed valid, and if I go back to my view, there we go. We can see that the view works again and I see the data again. So what we draw from this is that you can rename tables if need be, but if you do, you need to be aware that you'll wind up invalidating any objects that are dependent upon that table, as well as causing problems for any SQL that you might have in your applications. So if you do this, you need to be careful and account for that and have a plan in place to get all those objects fixed.

Renaming Columns

Much like we could rename a table, we could also rename a column within a table. To do this, we use the alter table command. After the keywords RENAME COLUMN, we specify the current name of the column that we want to rename and the new name for the column. Again here though, if we're using the column in any views, stored procedures, or functions, Oracle is going to mark those objects as invalid, and we're going to need to go and adjust the definition of those objects before we can use them again. And again, as you would expect, any other SQL that we've developed in our application code, like C# or Java, we'll need to go an update that, as well. So this is a capability that Oracle has. There are some practical limitations that you will encounter when renaming columns, other than if you do it right when you're first creating your database and you don't have a lot of dependencies built up around your database.

Adding Columns

One of the most frequent tasks you will need to perform over the lifetime of your database is the need to add columns to the tables in your database. Inevitably, the application your database supports will need to be enhanced. This could mean adding additional tables to your schema, but often times means we need to add columns to some of our existing tables. So how do we accomplish this? We can use the alter table command to add one or more columns to a table at a time, and on your screen, you see the basic syntax of this command. We use the keyword ADD and then surround in parentheses, we have the definitions of the columns that we want to add to our table. And these definitions are exactly the same as we would use in a create table statement. So in this example we may have received a new requirement that we need to track some medical information about our students, and so we're adding columns, want to track if we've received an immunization form, and also the date that that form was received about each of our students. Now one interesting thing to note here is that we've defined the immunization_form_received column as not null, and with a default value of N, which will represent no or false. We understand how this is going to work for new rows. When they're added, they'll be given the default value for this column, but let's think for a moment. How's this going to work for all of our students who already have rows in the table? Is Oracle going to go back and update all of those rows and put a value of N in the new column that we've just created? If we have a table of any size, this could be quite expensive from a performance standpoint. The answer is no. Oracle won't go update all of the rows in the table, but it will remember that this column does have a default value of N, so that any time someone selects one of these existing rows in the table, Oracle will see this and include our default value in the results set for the table of that column. So to the user who's querying the table, it will appear that the column does indeed, contain a value of N or no, even though physically it doesn't. This has been a feature in Oracle since llg, and this makes it very nice, because now, we don't have to worry about doing a separate update against our table when we have default values like this, especially a large table where we want to minimize any performance impacts. Adding a column will not invalidate any views, store procedures, or functions, but obviously, if you want any of these items to use the new column or columns, you'll need to update those objects accordingly. There is one use case though that adding a column can break something in your applications. If you have an insert statement that looks like this where you do not specify the column names in the insert, just the values, when you add a column to the table, this insert statement will break because Oracle will not be able to figure out what values go where. Having an insert statement like this is something that most database professionals would consider an anti-pattern. But nonetheless, you may be dealing with the situation in legacy code or a vendor package that you don't have control over. What you can do in that case is to add the column as invisible and you do this just by including the invisible keyword in the alter table statement with the column definition. You can still access this column just like you normally would by name. However, it will not show up when you do a select star from the table and it will not affect insert statements that do not specify the column name, like the one shown on the screen. This is a new feature that was just added in Oracle 12c. This is probably something that you'll need very often, but when you do find yourself in one of these situations, this could be very helpful.

Demo: Adding Columns

Let's do a quick demonstration of adding some columns to a table. I'm going to run the alter table statement that you see on your screen and add these two columns, and notice again, for one of the columns I have a default value. So let's go ahead and run this statement, and we see that was successful, and now let's go ahead and query the data from the table in the database. And here we have some data back. What we're interested in though is those two new columns, so let's scroll out here to the right. In there out there on the right we see them, where we see the column for the date that the form was received is null, and that's exactly what we'd expect for this new column. Notice, however, that our immunization form received column has the default value of N that we specified for all of these rows, and these were rows that were already existing in the table when we ran our alter table statement just a moment ago. This is the feature we talked about that was introduced in Oracle 11g, where Oracle is storing the default value of N in the data dictionary and it knows when someone requests any of those rows that were existing in the table, it needs to pull out that default value and put it in the results set, such that even if you have an existing row on the table, they do get that default value. This is very useful because in the past when we added this column, we would've had to add this column as a nullable column and then go back and run the update statement to populate every row in the table and that could be quite time consuming. There is one other feature that I want to show you. I do have a view created over the students table called the_students, so let's query from that view and see what we get. We see here that we indeed can query from our view. It's not invalid, so that's good. However, let's go out and look for our new columns, and we see that our new columns are not there, so as we said, adding the new columns that doesn't invalidate objects like views or stored procedures, but if we want the new columns to show up or be used by the views or stored procedures, then we need to go ahead and update the definition of those objects so they can see those new columns.

Dropping Columns

Just like you can add a column to a table, you can also drop a column from a table. There are actually two ways to accomplish this-- a logical delete and a physical delete. We'll cover the physical delete first. To physically drop columns from a table, we again use the alter table statement, this time with the drop column clause and then the name of the columns to be dropped. This statement can be used both to drop a single column and to drop multiple columns at a time, as shown on the screen. As I am sure you expect by now, dropping a column will invalidate any views, stored procedures, or functions in Oracle that depend on that column. So you will want to query the all_objects view to find those objects and modify them as appropriate, and then you will also need to fix any SQL statements in your application that reference that column, as well. What you also want to be concerned about is that if you physically drop a column on a large table, that could have some performance impacts, as Oracle will go ahead and update all of the blocks for that table to reflect that the column has been dropped. So the syntax that you saw used on the previous slide is fine for small tables, but for large tables you might want to consider logically dropping the column. We'll look at that next. To logically drop a column or columns from a table, we again use the alter table command, but in this case, we'll use the keywords SET UNUSED and the names of our columns. Once we do this, our column is no longer part of the table and we're not able to access that data anymore. However, Oracle's not going to go and update all the database blocks and recover storage to reflect this, at this point. Instead, at a later time, maybe during off hours or a maintenance window, we would then issue the following command: ALTER TABLE table_name DROP UNUSED COLUMNS, and this would go ahead and drop those columns physically and update the data blocks for the table. Note that when you logically delete a column, this is a one-way trip. You can only then proceed to go ahead and physically delete the columns. There's not a way to bring the columns back. But what this does provide is that for a large table, you can control when the physical deletion occurs and so you can make sure that this occurs at a time when your Oracle server is not busy and minimize any performance side effects. One other item that you want to be aware of is that if the column you are trying to drop is part of a primary or foreign key constraint, Oracle will give you an error when you try to drop this column and you can specify cascade constraints in the alter table statement when you drop the column, and this will drop both the constraint and the column, similar to what we saw in the drop table statement. However, if you're dropping a column that's part of your primary or foreign key on a table, you probably want to stop for a moment and think about what you're actually trying to accomplish and if this is the right way to do it.

Changing a Column Data Type

There may be occasions when you need to modify the data type of a column. This is possible to do in Oracle, but there are some limitations. If you have a column that you want to increase the size of the column, that is, go from a VARCHAR2 field that's 30 characters in length to 50 characters or take a number column and increase its precision or scale, in these cases you're going to be okay and you'll be able to modify the data type, whether or not the column has values in it or not. If you want to go the other direction though and reduce the size of a column, things get a little trickier. If you have a VARCHAR2 field, say at a size 50, if you want to reduce this to 25, Oracle will allow you to do this, as long as no data in the column will be affected. If, however, there would be some values in that column that would be truncated, Oracle will give you an error. For numeric value types, it is generally not possible to reduce the precision or scale of the data type if there is any data in the column. You can make a change if the column is empty, but if there's any data in the column, Oracle will give you an error. What about the scenario where we want to change from one data type to another, so a VARCHAR field to a number field or a VARCHAR to a data field? In these cases, Oracle's going to require the column to be empty, because otherwise it would need to figure out how to convert the data inside to the new data type, and that just might not be possible. So what to draw from this is that if you want to increase the size of the data type for a column, you're probably going to be in good shape. But if you want to reduce the size of a data type for a column or change the data type altogether, your column is probably going to need to be empty, because the rules are much more restrictive in these cases. So if we do have a situation where we can modify the data type, how do we do this? We use the alter table command with the modify syntax and in the column definition area, we put the name of our column and the new data type we want the column to use. Again, where you will find this most useful is when you need to increase the size of an existing column, like expanding a VARCHAR field. Otherwise, as we just saw, the other scenarios are much more restrictive.

Summary

In this module, we've covered a variety of topics relating to managing tables in your Oracle database. We first discussed the Oracle data dictionary and went through some of the useful views in the data dictionary and talked about some of the information that is contained within those views. We then introduced the topic of database statistics, including a brief introduction into how Oracle uses database statistics and how they are collected. We then moved into a discussion of how you can manage tables in your database, including dropping a table and renaming a table, and then we wrapped up with a discussion of managing columns in your tables, including adding a column, dropping a column, renaming a column, and changing the data type of a column. And so, in summary, you've been introduced in how to perform many of the most common tasks that you will encounter in managing your database schema over the lifetime of your database.

Specialized Table Types

Introduction

Hello, my name is David Berry. Welcome to this module on Specialized Table Types in Oracle. So far the tables we have discussed are really for one purpose, persisting data in Oracle. This, of course, is the primary reason why you use a database like Oracle. However, there are a couple of specialized table types that aren't used for persisting data in Oracle, but help us solve some common problems we face when we're working with Oracle. The first type of these tables is a global Temporary Table. These are tables that you define in your database, but they only retain data for the duration of a transaction or a session, so they serve as a temporary holding area that we can use during a lengthy process. The second type of table that we'll talk about in this module in an External Table. Often times you're going to have the need to import some data into your Oracle database from a flat file. There are several ways to do this in Oracle, but what external tables provide is an interface that allows you to query that data in the flat file just like it was another table in your database. So let's dive right in and start talking about these specialized table types that are available in Oracle.

Global Temporary Tables

Like other databases, Oracle gives you the ability to create temporary tables that can serve as a work area during long and complex operations. In many databases like SQL Server, temporary tables are defined on an ad hoc basis when needed, usually within the body of a stored procedure that's performing a complex task. In Oracle, this is different. We define the structure of the temporary table statically, just like we would any other table in our database schema. However, any data in the temporary table is only available within the scope of a session. So while the definition of a temporary table is defined ahead of time, and multiple sessions can use a temporary table simultaneously, the data each session puts into a temporary table is private to that session. That is, the only data that you will see in a temporary table is the data that your session has put into the temporary table. You will not see data from other sessions in the temporary table, and they will not be able to see the data from your session. In this way, temporary tables in Oracle act as a sort of private workspace that you can use within the scope of a session. The syntax for creating a temporary table is very similar to creating a normal table in Oracle, with just a few slight modifications. First, we need to include the keywords GLOBAL TEMPORARY here in our CREATE TABLE clause, so this reads CREATE GLOBAL TEMPORARY TABLE. Note that the keyword GLOBAL is required here; however, there is no local temporary table or anything like that, this is just the syntax that Oracle uses. We then also have an optional clause to tell Oracle what to do with our rows in the temporary table when we commit a transaction. There are two options available to us, which we see here. ON COMMIT DELETE ROWS and ON COMMIT PRESERVE ROWS. The first option of ON COMMIT DELETE ROWS means that once you issue a commit, any rows in the temporary table will be cleared out. This is also the default option, so if you do not specify this clause, this is the behavior you will get. In this case, the data you store in a temporary table is really transaction level in scope, because once that transaction ends, so does the lifetime of that data. The second option is ON COMMIT PRESERVE ROWS, and that means any rows in you temporary table will persist across transactions in a session. If you want, you can explicitly delete rows from your temporary table, or when your session ends all of these rows will be removed from the temporary table automatically. In any case, though, know that once your session ends, all of the rows from your table will be removed no matter what. So the choice here is really if you need to load data into a temporary table just for use within a transaction, or if you want that data to be available across multiple transactions within your session. Now there are a couple of rules with temporary tables that you should be aware of. First of all, temporary tables cannot participate in any sort of foreign key relationship. That is, you cannot have any other table with a foreign key to a temporary table, and a temporary table cannot contain any foreign keys to other tables in your schema. This just isn't allowed. You can, however, create indexes on a temporary table. This includes creating a primary key on a table, a unique index if you want to enforce uniqueness on a column, or just a regular index. However, know that by default, a temporary table will not have any database statistics associated with it, meaning the Oracle optimizer will make its best guess about the amount and distribution of data in the temporary table. You, can, however, gather stats on a temporary table, and if you have some sort of process that loads a large amount of data into a temporary table, this is probably a good idea to make sure that Oracle generates an effective execution plan. In Oracle 11g and earlier, these stats are common to all sessions, but in Oracle 12c, these stats are specific to each individual session. Let's do a quick demonstration of a temporary table so you can see one in action.

Demo: Temporary Tables in Oracle

For this demonstration, I'm going to have two different Oracle sessions going at the same time. One is here in SQL Developer, and then I have a second session in SQL *Plus, which I can show you here. There's nothing special about one being in SQL Developer and one being SQL *Plus, I just want to make it easy for you to tell that indeed I do have two separate sessions active at the same time, and in both of these sessions, I'm logged in as the student user. I'm going to create the temporary table you see on your screen to hold a temporary list of courses that we might want to work with during some operation, so let's go ahead and do that. And now I'm going to go over to my other session in SQL *Plus, and indeed, we can see that temporary table over here in this session as well. This is an area where Oracle differs from a lot of other databases; the definition of the temporary table is global. It's not tied to only the session that created the temporary table. Even if I were to log out and log back in, the definition of this temporary table would still be there. Again, in Oracle, you define temporary tables up front, and then that definition can be used by any session that access to the temporary table. So let's go back to SQL Developer and let's get some data in this temporary table in that session. I'm going to run this INSERT statement, and this is going to insert the list of all the Computer Science courses into the temporary table. And there we go. Now let's query back out that list, just to see that we do have this data in there. And there we go, we see the list of all of our Computer Science courses in our university. Let's switch back to our SQL *Plus session and query our temporary table from this session and see what we have. And we see that we don't have any data in our temporary table in our session over here, and that's because the data in temporary tables is private to a session. So it doesn't matter what any other sessions may do in this temporary table, we're only going to see the data in the temporary table that our session has placed in that table. We can prove that this works the other way as well. I'll insert all the Electrical Engineering courses in this session here, and there we go. And I can query those out, so you see those are Electrical Engineering courses. I'll go back to SQL Developer, and if I run my select statement again, we can see that I still only see Computer Science courses over here. So indeed a temporary table does act like a private workspace per session. There is one last thing I'd like to demonstrate, and that's when we created our table, I didn't specify a clause about preserving my rows on a commit. So by default, the behavior in Oracle is when I issue a commit, Oracle is going to remove the rows from my temporary table. So I'm going to go ahead and issue a commit right now in this window. There we go. And now if I run my select statement, I'll see that I don't have any rows. And once again, the reason why is because the default behavior in Oracle is that the data in a temporary table is transaction in scope. When you issue a commit, that data is cleared out. When you define you temporary table, it is possible to use the ON COMMIT PRESERVE ROWS, and then that data would persist throughout the session. In any case though, once that session ends, all of the data is going to be removed from the temporary table. It's not going to be there when you log in next. So in summary, if you need a temporary workspace to store some results during a long or complex operation, you can make use of temporary tables. The definition of that table will be available to all sessions, but the data that you put into the table will be private, it'll be just for your session.

External Tables Introduction

One of the tasks that we frequently need to be able to perform, is to be able to import data from a flat file into an Oracle database. One of the ways to accomplish this is by using a feature in Oracle called external tables. What an external table allows you to do is to define a table structure in the database that describes a flat file that you'll want to import. You then place your data file in the appropriate location on the Oracle server, and you can access the data within the file directly from SQL in Oracle. So we can filter data with a where clause, we can join data in the file to other tables, or just use the external table as an entry point for our data so we can import that data into the database. All this turns out to be very useful, and best of all, it's extremely easy to accomplish without having to write some custom code in order to import a file like this. There are a few things that you should know about external tables up front. First of all, external tables are for loading data into Oracle, not exporting data out of Oracle. If you're looking to write a query and then dump the results out to something like a CSV file, this can be accomplished in SQL Developer. However, at the time of this recording, there is no command line tool that ships with Oracle that allows you to export data in this way, and this is not a feature of external tables. Second, you can use external tables to import both fixed width and delimited flat files, like a CSV file or a pipe-delimited file. We'll show examples of both in this module. Finally, to use external tables, the data file you are reading from needs to be up on your Oracle server. This is an important point. The file needs to be on the Oracle server itself, not just on a client machine that has access to Oracle. There are some organizations who prefer that their Oracle server be purely a database server and not perform any application type functions, including loading a file like this. If that is the case, then you will want to look at other solutions, like using Oracle SQL Loader utility, or possibly a third-party tool like Informatica to get your data into Oracle. Just know though, that if you are using external tables, you're going to have to get the file you want to import up to the Oracle server in some way.

Oracle Directory Objects

To use an external table, we must first have a Directory Object defined in Oracle. We can't just put a data file anywhere on our Oracle server and expect Oracle to be able to find it. We need to create a place on our Oracle server where these data files are going to be, and then tell Oracle about this location. If you're running Oracle on your own machine just as a development database, then you'll probably able to perform all of these tasks yourself. If you're accessing Oracle up on a server somewhere in your corporate environment, then you're most likely going to need help from your system administrator and DBA to get these steps completed, because a normal user just won't have the permissions to do some of the things that you need to do. The first step is to create the directory where the data files are going to be placed out in the operating system. If you're running Windows, you can use Windows Explorer, a Command Prompt, or PowerShell. If you're on UNIX, most likely you'll be at the command line of your favorite shell. Most likely, this step is going to involve your system administrator and DBA. They won't want files placed just anywhere out on your Oracle server, they'll have some sort of file layout that they want to adhere to. The second step is to make sure that you have operating system privileges setup correctly on this directory. First of all, the user that runs Oracle will need to have both read and write permission to this directory. Even though external files are only for reading data in, Oracle will generate some log files out in this directory, so that is why the Oracle server process needs to be able to write to this directory as well. Also, make sure whatever process is going to put the files into this directory also has the correct permissions to that directory. Getting the files into this directory is your responsibility. Whether you do this manually or through a script or batch job, but whatever process this is, will need to be able to copy your data files into that destination directory. Third, you'll need to create a directory object in Oracle. The directory object tells Oracle that this is a directory that can be used for data files, so this is the link between Oracle and the file system. Typically, the permission to create a directory object in Oracle is not given to a normal user, so this is a step that a DBA will perform. We'll look at the syntax how to perform this in a minute. Finally, you need to give permission to the Oracle user that is going to define and use the external table to read from the directory object. This again is a task that your DBA will most likely perform. What is happening here, is that on our Oracle server, you may have multiple directories that are used for importing data, and we don't want to allow any user to read from any directory, in case there's sensitive data in one of these directories. So we have to go through this step and have appropriate permissions assigned so Oracle knows that, yes, your Oracle user is authorized to read in data files from this directory. To create a directory object in Oracle, we do so by using the CREATE DIRECTORY command as shown here. What this is going to do is let Oracle know about a directory on the operating system that you intend to put data files in. When we create our external table, we'll give it the name of this directory object to where our files are, and then Oracle will know where on the operating system to go and look for these files. To perform this action, you're going to need to have the create any directory privilege assigned to the user that's executing this statement. This privilege is usually reserved for users with DBA privileges in Oracle, and not something that just gets granted to any user. One last thing to be aware of, is that if the directory on the file system doesn't exist or you don't have appropriate operating system permissions set up, you actually will not get an error at this point when you try to create this directory object, but you will get an error when you actually try to query from the external table. So know that just because the CREATE DIRECTORY command completed at this point, this doesn't indicate success, you still need to try to actually read from that file. Once you have your directory created, there's one last thing that you need to do with the directory object in Oracle, and that is to give re-permission on the directory object to the user who's going to be creating the external table. We do this with a simple GRANT command and the privilege READ ON DIRECTORY with the directory name, and then the user that we want to grant this privilege to. I'd like to share one last thought with you about data directories in Oracle. If you're going to be using external tables in multiple schemas, then I think it is prudent to create a separate data directory for every schema or application that will be importing data. The first reason to do this is security. Once an Oracle user has access to the directory object, you can create an external table to read any file in that directory. If we are importing payroll, human resources, or accounts receivable data, this data is obviously very sensitive in nature, and we don't want that read into another schema that doesn't have anything to do with those business functions. So having separate directories allows you to properly secure any data that you might have and make sure it only gets imported to the right place. The second point I would make is that it's just cleaner to use separate directories. Having data files and log files from different users in the same directory always seems to get messy, and you run the risk that one user may accidentally delete or otherwise affect the files from a different user. So it just makes sense to keep different schemas in different directories, if for no other reason than to keep things clean up on your server.

Using an External Table to Import a Fixed Width Data File

Once we have a directory object setup, which I've already done, we can go ahead and create an external table in Oracle. We're going to start off by creating an external table to import a fixed width data file, like the one you see in front of you. You can see in this file there aren't any delimiter characters, it's just the position the data is in in the file that's going to determine where the data goes. Most of the data in this file is simple strings, but if we scroll out to the right, we do notice that we have a date field and a numeric field that will be imported in this file. We also see that we have some values that are missing in this data file, so let's go ahead and see how we can get this data into Oracle using an external table. I have the syntax up on the screen in SQL Developer to create an external table, and the first thing that you're going to notice is that a lot of this syntax up at the top does look familiar. It's very similar to the CREATE TABLE statement. What differentiates an external table, is this section that is down below, the ORGANIZATION EXTERNAL section, so let's jump down here and see what this syntax is telling us. The first line, TYPE ORACLE_LOADER, tells Oracle that we're going to be importing some sort of flat file or text file. External tables also can be used to load data from Oracle data pump files, which are an Oracle specific file format usually used for moving data between Oracle databases. This is not what we're doing here, though, we're reading data from a flat file, so this is the option that we use. The next line here specifies the directory that our data will be located in. This references the directory object that I showed earlier in the slides, and prior to recording this, I did go ahead and already create this out in Oracle and granted the appropriate permissions. Next we get down to the access parameters, and this really goes to how our file is structured. We're importing a fixed width file, so the parameter that we need to give Oracle is this parameter here, where we say RECORDS FIXED, and then we give Oracle the length of each line in the file in bytes. This length also needs to include any new line characters that you might have at the end of the file. So for the file that we saw before, this is 149 bytes including those new line characters that are at the end of the file. Next we have the capability to specify some options about the files that Oracle is going to generate for us when we're reading this file. First, we can tell Oracle the name of the LOGFILE to generate. Also, notice we're specifying our directory object again in this line. If we wanted Oracle to place our LOGFILE into a different directory, we could do so here by specifying a different directory object that we had created in Oracle. The BADFILE specifies a file that Oracle will put any rejected records in that it can't import. So if we have a line in the file that has some bad data, that data is going to get kicked out to the BADFILE, so we can inspect those records later and try to determine what went wrong. Again, we can specify a name and a directory for this file. Now if we leave these two parameters out, Oracle will still generate a LOGFILE and a BADFILE for us, it's just going to use some default names and it's going to place those files in the same directory that you're importing data from. These parameters just give you some control over where these files go and how they're named. The next section is arguably the most important section of our external file specification, the FIELDS section. And this tells Oracle what data is in the file and where it's located at. For a fixed width file, the format is pretty simple. We put the field name and then a CHAR data type with the size of that field. So this is really my file specification. In this file, the first name is in positions 1 through 20, so we see a CHAR 20 here. Then we have a middle initial, so we see a CHAR 1, as it's just taking up 1 column in the file. Then the last name, which is 20 characters long in our file specification, so we see a CHAR 20 again. So as you see here, what we're really doing is we're specifying all of the fields in the file in the order they appear in the file, and we're specifying the length of each field. If we look at the date field that we have in our file, we'll notice that we're specifying a format for the date that is in this field. In this case, we don't just want Oracle to import this data as text. We actually want to be able to treat this column as a date. So to do this, we have to specify how the date is formatted in the file. And how we do this, is with the DATE_FORMAT DATE MASK keywords, and then the actual format that's being used. Now it's important to know that what we're doing in this section is telling Oracle how to read the data from the file. These are not the data types in our external table. Those were specified earlier up above in the column definition section of the create table statement. And what Oracle is going to do is it's going to match up the field definitions down here to the column definitions based on the name. So it's important that you have the names the same between these two sections so that Oracle can match up the fields it's reading in from the files with the columns that you want those values mapped to. Notice also here in the FIELDS section, I have a field name middle_init. But I've chosen not to include that in my table definition up above. Now I still need to include this down in my fields definition, because this field is in the data file, and Oracle is going to need to know about that field in order to read the data file. But in this case, I actually don't want that to be in my external table, so what I do then I simply just don't include that in the column definition section of the create table statement. If we move down to the bottom of this definition, we now see the LOCATION parameter, and this is what we'll use to give the actual name of the file that our data file is stored at. Again, this is going to have to be a file in the data directory that we defined earlier up in the DEFAULT DIRECTORY clause. You can't put an absolute path in here; this is just the name of the file. Finally, in this definition I've included a clause of REJECT LIMIT UNLIMITED. What this means is that no matter how many rows of bad data that the file may have, I'm telling Oracle to still go ahead and read what you can. Rather than unlimited, I could put a number in here, and then if Oracle found that number of lines in the file that didn't match our import specification, Oracle would stop trying to read the file and it would give us an error and we wouldn't get any rows back. What you want to think about here is that if you have some bad data in a file, how do you handle that? Do you want to abort the entire process and start over and not read any data in? Or do you want to read in the data that you can and then figure out how to deal with those rejects later by looking at the bad file that Oracle produced? So let's go ahead and create this external table and read some data in from our data file. There we go, our file was created. And now we can just use normal SQL to read data out of this file. And there we go, we can see the data that was in that file. If we want to, we could include a WHERE clause, and again, there we go. So what we can do with an external table like this is now we're treating that data file just like it's a table in Oracle and we can run select statements against that data file just like we would a normal table.

Using an External Table to Import a CSV File

We're not just limited to importing data from fixed width files when working with external tables, we can also import delimited files like CSV files. So you see on your screen the same data that we saw in the last segment, but now it's in the format of a CSV file. Notice as well in this version of the file, we have a header row that tells us the names of the columns in this file. And if you've worked with importing any sort of files like this, you know that this is pretty common that you'll have a header record that's one or perhaps multiple lines that include some administrative type information in the file. So we need to understand how we can deal with these when we're trying to import the data from a file like this into Oracle. So let's see what an external table definition would look like that would be able to import this CSV file that we have on our screen. The first section of this file is exactly like before, so let's go ahead and jump down to the ACCESS PARAMETERS section and see how we define an external table to read a CSV file like this. First we see the RECORDS keyword, and this time we see that it is followed by keywords DELIMITED BY NEWLINE. And this is what you're going to see most often, because in most flat files, each line in a file is one record in the file, and so typically you will see this DELIMITED BY NEWLINE. Now it is possible if you had a data file that had a different record delimiter that was some sort of string, you could specify that here rather than the NEWLINE keyword, but again, most files are going to have one record per line. Next we see an option of SKIP 1, and what this does, is tell Oracle that our data file contains a header row. So we want to skip this line in the file before we start reading and importing data. If our file had three header rows in it, then we would have a SKIP 3 here to tell Oracle to skip the first 3 lines of the file. If our data file didn't have any header rows in it, then we would just not include this clause in our external table definition. Next, we need to tell Oracle how the fields in our file are delimited. So we do this with the FIELDS TERMINATED BY keywords and then what the field separator string is. In our case, this is a comma character. You might have also seen files that use a pipe character or a colon character, these are common as well, and if you had one of these, this is the clause you would use to tell Oracle what that field separator character is. We also can tell Oracle about how our data is quoted. Often times, we might have a value in our file that contains a field separator character inside of the value, and what that's meant to be is part of the value not to separate fields. And so what we do to handle these situations is we end up quoting those fields in our data files, and then the program that's importing that data file can know if that field separator incurs inside of a quoted string, then treat that as part of the string rather than as a separator character. And so that's what we have to tell Oracle here, it's no different than any other data import program you may have used. So in this case, we're saying that the quoting of fields is optional, but if they are quoted, it will be the double quote character that's used. If we eliminated the OPTIONALLY keyword, then it would be required that the values in our file be quoted. We also could specify a different character to use to quote fields in our data file in case that's what our file contained. Next, we're going to tell Oracle that if there's a missing field, we should treat that as null, and if we have any records in our file that are all null, then don't bring those into our external table. Now we get to this section here where we specify the fields that are in our data file. And you'll notice that this section is organized a little bit differently than what we saw in the last segment with a fixed width data file. What we really need to do here is we need to specify all of the fields that occur in the file and the order that those fields occur, and this will give oracle enough information in order to read our data file. Now you'll also notice that most of these fields don't have data types associated with them. And what's happening here is that by default Oracle is going to read each field as a CHAR data type with a length of 255 characters to import it, and then it will try to convert it into the column definition. Now there's two situations where we would need to specify a data type that you should be aware of. The first situation is if we had a string field that was longer than 255 characters and we wanted to import that. In that case, we would need to specify a data type, so we would specify a CHAR data type, and then include within parentheses the length of that field. So if we had a string that was 1000 characters we were trying to import, we would have a CHAR 1000 that we would specify here, and that would let Oracle know that this was a longer column, and Oracle needed to import all those other characters. The other situation we need to specify a format for is a date field. And we see how to do this down here. We're telling Oracle that this is a date field, and we're providing the format immediately after the date. Again, we need to do this because Oracle isn't going to know how the dates formatted otherwise. At the very bottom of the definition, we again have the LOCATION keyword, and this is where we give Oracle what the name of our data file is that's out in our default directories that we defined earlier in the external table definition. So let's go ahead and create this external table so we can access the data that is out in our data files. And there we go, our table has been created. Let's run a couple of SQL statements against this so we can see our data. There we go. And we'll run a SQL statement with a WHERE clause like before and indeed we see our data again. So for the purposes of SQL, we can treat an external table just like it's a normal table. If we wanted to take this data and join it to another table, we could do that, we could run sub-queries that involve this table, any of those sorts of things. And that's the real power of external tables. Because without writing any custom code, we can access the data out in a flat file like this just like it was in a table in our Oracle database.

External Table Resources

As you are no doubt aware, the format of flat files varies widely. We've covered just a few of the options that are available with external tables, but there are many more options that are available to help in importing all of the different types of files that you may be faced with. The Oracle Utilities Guide is the definitive resource on external tables and the options available, and on your screen you see links to the two chapters that cover external tables. The second chapter on the Oracle Loader Access Driver is especially important, because this chapter lists all of the various options that you have available to you. As with many things, it is often easier if you can start from a sample definition and then modify this to meet your needs. For that reason, I put a few sample definitions of external tables on my blog at the link shown. Feel free to look through these and modify them for your own purposes as necessary. Also, a quick Google search will reveal many more examples that others have done, so there's a good chance you can find something close to what you need to do and just modify it rather than having to build a definition from scratch each time. Finally, when working with external tables, you are inevitably going to get some errors and the data will not import. The messages you'll receive in Oracle around external tables are actually pretty cryptic, and I have personally not ever found these of much use. But don't forget about the log file and discard file that get generated when you try to read from an external table. If you have not changed the location of these, they will be out there in the operating system directory next to your data file. And these do provide good detailed information about what went wrong. So be sure not to overlook these files as troubleshooting tools.

Summary

In this module, we have looked at two types of tables that aren't used for persisting data in Oracle, but help us solve some common problems we face when working with Oracle. First, we looked at temporary tables, including how they are defined, how they behave in Oracle somewhat differently than in other databases, and how they can be used as a private workspace for holding data during a session. And then we looked external tables, which are a tool that we can use when we need to get data from a flat file into Oracle. We looked at what you need to do to set up a directory object in Oracle, and then worked through an example of an external table to read both a fixed width data file and a CSV delimited data file. Knowing about these specialized types of tables gives you two more tools that you can use when you're working with Oracle.

Indexes

Overview

Hello, my name is David Berry. Welcome to this module on Indexes in Oracle. So far in this course, we have spent a lot of time talking about tables, but the purpose of using a database system like Oracle is not just to store data. What we really want is to be able to quickly locate and retrieve a subset of our data and bring it back into our application so we can work with it. And this is where indexes come in. We'll start off with a general discussion about what an index is, and how the most common type of index, a B-tree index, works. We'll then discuss how to create an index and some of the options that you may need to use. Then, we'll discuss unique indexes, which not only can speed up access to your data, but also serve as a constraint on the data in your table. We'll discuss function based indexes, which allow you to create an index over a derived value rather than just the raw data values present in your table. We'll then proceed into a discussion of bitmap indexes. And finally, we'll wrap up by talking about some tips for creating indexes in your database. So as you can tell, we have a lot to talk about, so let's get started.

What Is an Index?

The rows in a table in Oracle are stored in what is called a heap structure. When we say a heap structure, what we mean is that there is no implied order of the rows in the table. They just exist in the table in what is essentially a random order. So if you want to search for a particular piece of data in such a structure, this means that you have to scan through all of the rows in the table, looking for the row that matches the criteria you provided. The name for such an operation is a full table scan. If the number of rows in a table is relatively few, meaning on the order of a hundred to even a few thousand, scanning through all of the rows in a table still takes a relatively short period of time. As our table grows though, and we have tens of thousands, hundreds of thousands, or even millions of rows, the performance of performing a full table scan slows down dramatically. First of all, it takes time to read all of those records off of disk and scan through them, and this amount of time is likely longer than what your user really wants to wait. Second though, because we're having to read so many rows off of disk and perform comparisons against these rows, a full table scan against a table becomes very computationally expensive on the Oracle server. So we are using a lot of CPU and I/O resources for a particular SQL statement, and this in turn might slow down other SQL statements, because now they have to wait for sufficient CPU or I/O bandwidth to become available for those statements to run. To solve this problem, databases like Oracle allow you to create indexes on the tables in your database. An index is a separate data structure that you create specifically for the purpose of speeding up the process of finding data within your database. There are a couple of different types of indexes, but the most common type of index is the B-tree or balanced tree index. And this is the type that you'll use most frequently. If you have taken an algorithms course in Computer Science, you know that tree structures can be searched very quickly for a particular piece of data, and that's what's going on here with an index. For each index, you will define a key for the index, which is a subset of columns that will be used to search the tree structure of the index. Furthermore, the data in the index will be stored in sorted order by this key value. If you think of an old-fashioned telephone book, each entry contains a number of different fields, including the person's first and last name, their street address, their city, and finally, their phone number. So this is like the data you have in your table. However, this data is listed in alphabetical order, first by last name and then by first name. And this is what lets you quickly find the phone number or street address of the person you're looking for. In this example, the last name and the first name are like the index key for the data in the phone book. This is how the data is organized and this is how you search for data. If you visualize the tree structure of the index in Oracle, it would look something like this. Notice that our data is stored in sorted order of the index keys, which allows the tree structure to exist on top of the index keys. For any search, we'll start at the root note of the tree, and perform a comparison to know which child node we should move to next. We'll repeat this process until we get to the bottom of the index to these structures called leaf nodes. Since these leaf nodes contain the values for only a few hundred or few thousand index keys, Oracle can quickly just scan through these values in the leaf nodes to find the keys that match your search criteria. Associated with each of these keys is a Row ID, that universal row pointer that points to the row in the table that corresponds to the Index Key. So finding a value in a table using an index is a two-step process. First, you traverse the tree structure of the index to find the matching index keys and the ROWIDs. And then Oracle can use these ROWIDs to read only the blocks it needs from the table and ultimately go right to the location of the rows of interest. Even though this is a two-step process, it is typically much faster, because overall you are reading and comparing much less data than if you were to read the entire table and scan for rows that matched your search criteria. To give you an idea of how much more efficient it is to search for a value using an index rather than a full table scan, consider the efficiency of each algorithm. In Computer Science, we described the efficiency of an algorithm using the Big O notation. For a table scan, this is a linear search. So we have to perform as many comparisons as there are rows in the table. So if there are one million rows, we'll need to perform one million comparisons. For a B-tree structure though, the algorithm efficiency is the base two log of the number of values. So for the same one million records, we'll only need to perform 19 comparisons. What this is all pointing towards is that for a table of any size in our database, we always want to be accessing that table using an index. That is, we want the select criteria in the where clause of our select update or delete statement to match an index that we have defined on a table in our database, and make use of this tree structure to locate the rows of interest. This will make our SQL statements not just run faster, but also be more efficient in terms of their usage of resources on the Oracle server. In this course, I'm going to focus on how to create indexes in your database. If you want more information on how indexes work and what makes a good index that Oracle can use, then check out my Oracle Performance Tuning for Developers course, also here on Pluralsight.

Creating Standard B-Tree Indexes

To create an index on a table, we'll use the CREATE INDEX command like you see on this screen. And the first part of this is we specify a name for our index. We then follow that with the keyword ON and the name of the table that we're creating the index for. Then, enclosed in parentheses, we include the columns that will be the key for this index. You must include at least one column and the maximum number of columns that can be included is 32. In practice, you'll probably never have 32 columns in an index you create, with 5 or 6 columns usually being the most that your indexes will contain. The order of these columns is important, because for your index to be used in a SQL statement, the WHERE clause of the SQL statement needs to contain the leading edge or first column of the index. The index will be most effective for the SQL statement if the statement contains multiple consecutive columns in its WHERE clause that match the front of the index. Finally, you can create your index in a different tablespace by using the TABLESPACE keyword, and then specifying the name of the tablespace where you want the index to be created. If you do not include this option, then the index will be created in the default tablespace for the current user. When we create an index, Oracle will not allow any DML statements to be processed against the table we are creating the index for. However, if you have Oracle Enterprise Edition, you can include the keyword ONLINE as part of your CREATE INDEX statement, and then Oracle will allow DML statements to be processed against your table while the index is being created. Now there are some reports in the Oracle community that a small amount of locking still does occur for a brief period of time. But if you find yourself with the need to add an index to a large table during normal business hours, when users are trying to insert, update, and delete data from your table, this option will minimize any locking that does occur. If you're using Oracle Standard Edition, or you just can't risk any amount of locking to occur, then what you'll probably want to do is wait until off hours to create indexes on your large tables to make sure that any users are not impacted.

Unique Indexes

The CREATE INDEX syntax that we just saw will create a non-unique index, meaning that for each key in the index, Oracle will allow multiple values to exist. An index on a person's first and last name is a good example of this. We know that there can be multiple people with the same first and last name, so we need to allow for this in our index, and then we'll have to use some other criteria to figure out which individual records we really want in our query. There are cases, though, where you want to create a unique index, such that for any index key, only a single value is allowed. When you create a unique index, there's not only indexes that column or columns in the index, but also functions as a unique constraint on the data in these columns in the table. Think about a column like email address, which is usually a unique value. In many scenarios, no two people should have the same email address. So what we want to do is enforce this uniqueness of the value on our table. At the same time, it is a common scenario to be able to need to look up a user by their email address. If you've ever used a Forgot Password feature of a website, you're familiar with this sort of functionality. Creating a unique index on the email address column accomplishes both of these goals. It will index the column so we can rapidly search our table by email address, as well as enforcing the constraint that every row in the table will contain a different and distinct email address. To create a unique index, simply include the UNIQUE keyword in your CREATE INDEX statement. Once the unique index is created on the table, any attempt to insert a row with duplicate values for the columns in the index will produce an error. Also, you should know that if you already have data in your table, Oracle will ensure that the values for the columns in the index are unique when the index is created. If you have any duplicates, then the CREATE INDEX operation will fail, and you will need to resolve these before creating the index. Otherwise, the same options apply as before. If you're running Oracle Enterprise Edition, then you can use the ONLINE keyword to still allow DML against the table during the index creation process, and you can use the TABLESPACE option to select what tablespace the index will be created in. Let's go ahead and do a brief example of creating and using some indexes in our database.

Demo: Creating and Using B-Tree Indexes

In this demo, we'll briefly demonstrate both how to create an index and the usage of an index. What I'm going to do is first run this query that you see on your screen, and this is a query against the applications table, which represents students that have applied to our fictional university. This table has a little over 90,000 rows in it, so it is large enough to demonstrate the impact of using an index, although it's very likely that you'll have tables much larger than this in the databases that you work with, and in those tables using an index would be even more critical. Right now, I don't have an index on the last_name and first_name columns, so what this is going to do is to perform a full table scan where Oracle will read every row in the table in order to find rows that match our search criteria. We'll go ahead and run this query, and we see that it did indeed come back pretty quick, and I get back three rows from this query representing three different people named Anthony Morris. I'm going to rerun this query using the auto trace feature in Oracle, and what this is going to do is run the query, but rather than showing us the results, it's going to give us back some diagnostic information on how Oracle processed our query, as well as some statistics. So let's go ahead and do this, and we do this by hitting the fourth button in my version of SQL Developer. And here are our results. What this is telling us is that Oracle did indeed scan all of the rows in the table, which we can tell from this operation here, a table scan full. And then if we look at the LAST BUFFER GETS column, we see that in order to do this, Oracle had to process a little bit over 1700 data blocks from the table, which are all of the blocks in the table. So while this query came back fast, it was really not very efficient. If I had a larger table or I was on a system with more users other than just myself, this query would quickly become a performance issue. So let's create an index on this table that our query can use, and we'll see how this makes our query more efficient. So here is my syntax for the CREATE INDEX statement. And you can see here, this will be the name of my index, ix_applications_fullname, and we can also see that I'm creating this index on the applications table, and finally we see the columns that I'm using to create my index, last_name and then first_name. Also, we understand this needs to be a non-unique index, which is what my syntax is creating. Remember, we have three different rows representing three different people named Anthony Morris, which matches up with our expectation that just someone's name is generally not unique. So we've got to create our index as a non-unique index. So let's go ahead and create this index on the table. There we go, our index has been created. And now let's go ahead and rerun our query. And we see that we get those same three rows back, but where things get more interesting is when we run the autotrace version of running the query, so let's go ahead and do that. So we see now, Oracle is using an INDEX operation to find the rows that match the first and last name that we provided. In here, we see the two step process that we talked about in the slides. This first is the INDEX operation, where Oracle is traversing the tree structure of the index to find the matching keys in the index, the TABLE ACCESS BY ROW ID, and what Oracle is doing is taking the row IDs it got from those index keys, and then going directly to the specific blocks in the table to where it can load the data that we need for this query. The result of all of this is that the query is much more efficient. In this case, Oracle is only having to read and process data for 5 blocks, whereas before we were needing to read over 1700 blocks. So you can easily understand having the right index in place makes a query much less resource intensive and ultimately much faster, because Oracle's going to be able to take advantage of that tree structure to do a lot less work and get your results to you much quicker.

Function Based Indexes

In all of the indexes we have looked at so far, the value that Oracle's indexing is the actual value that is stored in the column. There are cases, though, where you want to create an index not over the actual value in a column, but on a derived value, and this is where function based indexes come in. The classic example of this is to create an index to perform a case insensitive search on a column in Oracle. As you know, Oracle is case sensitive, meaning that if we use a SQL statement like we see on our screen, this is the exact value that Oracle will search for and match in our table, including the case that the value is in. The problem is that we really want to do a case insensitive search, so it doesn't matter how the user typed in either the search criteria or the value in the table that we're searching for. What we can do is to rewrite our SQL statement and use the UPPER function, both on the table column and on the search criteria value. But now we have another problem. Oracle won't use any indexes that we've created on the last_name or first_name column of our table, because these are stored in mixed case, not the uppercase version, which is what this statement needs. So what will happen is that Oracle will do a full table scan against the table, reading each row, uppercasing the last_name and first_name values, and then performing the comparison. Obviously, for a table of any size, this is going to be quite slow and inefficient, because Oracle is performing this operation against every row in the table. Using a function based index though, we can instruct Oracle to index not the raw values in the last_name and first_name column, but instead the uppercased version of these values. We do this by specifying the UPPER function with the column in the column definition clause of our CREATE INDEX statement. And now our index will be created over these uppercased values. Subsequently, when we run a SQL statement like we saw on the last slide, Oracle will recognize that the function definition in the index and the function in the WHERE clauses match, and therefore, Oracle will be able to use the index when performing this query. Consequently, when this statement runs, rather than scanning every row in the table, Oracle can do an efficient index seek operation to find the rows that match the search criteria that we provided. There are some items that you need to keep in mind when using function based indexes, so let's run through those real quick. First of all, you can use either built in Oracle functions or your own functions, either is allowed. What must be true about the function that is used, is that it must be deterministic. That is, for any given set of inputs, it must always return the same value. If you are defining your own function, you need to declare that function with the deterministic keyword. Finally, you are allowed to mix and match derived values from functions with regular column values within the same index. So, for example, if you wanted to have an index that contained the uppercased last name as the first column, the uppercased first name as the second column, and the plain old zip code value as the third column, this is allowed. You can mix and match what columns and drive values you need in your index in any way that you see fit. Let's take a look at a quick example of a function based index so you can see how one works.

Demo: Creating and Using a Function Based Index

In this demo, we're going to look at how to use a function based index to do a case insensitive search. I have on my screen a query that is searching for a particular person, and I still have the index created from the last demo that I did earlier in the module. That is, just a standard index on the last_name and first_name columns in this table. So I'll go ahead and run this query, and we see that we get five rows back. What is of more interest to us is that if we run the autotrace for this query, we see indeed that we are using the index on the table like we expect. So let's change things up a bit here and see what happens when we change the casing of the values in our WHERE clause. There we go. And this might simulate how some users would type in the search criteria into an application. They might not be paying attention to the case of the characters, so this is a situation that we have to deal with. So let's run this query and see what we get. And we see that we get no rows back. This is because when Oracle does these comparisons, they're done in a case sensitive manner. And of course the values in our table are stored in mixed case, not in all uppercase, so we don't get any matches. Now as we saw in the slides, one way we can fix this problem is to use an UPPER function in our SQL statement, so let's go ahead and do that. And now let's run this query. Okay, this is good news. Our query is working again and we have the rows returned that we expect. Now unfortunately, a lot of people stop here, because the query is functionally correct, it returns the rows that it should. But this query has a performance problem, and if we look at the autotrace, we can see what's going on. We see that our query is no longer using our index, but instead is conducting a full table scan. Again, as our table grows and gets larger, or we have more and more users running this query at the same time on our system, then we're really going to start to impact performance, because this query is actually quite inefficient. We're reading and processing over 1700 data blocks just to get 5 rows back. So let's use a function based index to fix this. Here is the index that I'll create. Notice how I've wrapped both the last_name and first_name columns in the UPPER function. So what will happen is that Oracle will uppercase both of these values, and then store those derived values in the index. So let's go ahead and create this index. And now let's go ahead and run our SQL statement again. That's good, we get back the correct answer, the five rows that we should, so now let's look at the autotrace to understand the performance of this query with our function based index created. In here, we see that now Oracle is using the new index, the function based index we just created, to perform this query. And things are much more efficient. We see that Oracle is just having to read and process 7 blocks for our statement now, rather than the 1700 that we were doing a moment ago. And so you see, this is how you can use a function based index to create an index on a derived value for your tables, and this is going to help to make some of your SQL statements much more efficient.

Bitmap Indexes

There is a second type of index that you can create in Oracle that is designed for a very different use case than a B-tree index, and that is a bitmap index. Like the standard B-tree index we just talked about, a bitmap index is designed to help your queries quickly retrieve the rows of interest, but otherwise it works very differently. Whereas a B-tree index works best for a column or combination columns with a high number of distinct values, bitmap indexes are targeted at columns with only a few distinct values. Also, B-tree indexes are suitable to use in both transactional databases and data warehouse environments. However, because of the way bitmap indexes are stored in disk, they are really only appropriate for data warehouse environments where you are not doing any sort of transaction processing. So let's take a look at what a bitmap index is and how it works so we can understand when and where a bitmap index should be a consideration. In many tables, we have a number of columns with only a small number of distinct values. These are columns like gender, marital status, or a column like age range, where we separate individuals into different buckets based on an age range. Income level and ethnicity would be other examples of these types of columns. In each instance, we have just a few distinct values, perhaps as low as 2; perhaps 5 or 10. In these cases, a traditional B-tree index just doesn't work very well, because a B-tree index relies upon there being a high degree of selectivity or uniqueness amongst each of its keys. This, however, is exactly the problem that bitmap indexes are good at solving. What Oracle will do is create a bit array for each distinct value in the column. For this example, we'll use the column gender, which of course has two distinct values, male and female. So in this case, Oracle will construct one bit array for the value of female and one bit array for the value of male as you see here. Then, for each bit array, Oracle simply places a 1 or a 0 in the bit array, depending on if the value in the corresponding row matches the value that the bit array is for. So we can see here, customer 1001 is a female. So the bit array value for the female bit array gets a 1 for true, and the bit array for the male value gets a 0 for false. For customer 1003, we see just the opposite, because this row has a value of male. So Oracle will do this for every row in the table in order to construct these bit arrays. And it is this collection of bit arrays that will make up the bitmap index. We are not just limited to columns that only have two distinct values in them. Here, for the age range column, we have four distinct values. So in this case, Oracle will create four bit arrays. In this case, customer 1001 is in the 18-34 age range, so it is the 18-34 bit array which gets the value of 1 for true and all of the other bit arrays for this row have a value of 0 for false. For customer 1003, it is the 35-49 bit array that contains a value of 1, and all of the other bit arrays contain the value of 0 for false. There are two important attributes of a bitmap index that make it very efficient. First is the fact that these bit arrays can be highly compressed and stored very efficiently, meaning that the bitmap indexes can very quickly be read from disk when needed. Second, it is very efficient to perform bitwise operations, like a logical AND operation, between multiple bit arrays. And this leads us into the real power behind bitmap indexes. In combining multiple bitmap indexes together in a logical operation, we can see how a bitmap index can really be useful. Think of a question that a marketer might want to ask about some data. You might come up with something like wanting to know all of the males who are not married in between the ages of 35-49. So using the bit arrays from different bitmap indexes, we have a bit array for what customers are male, another bit array for what customers are not married, and finally, a bit array for the customers who are between 35-49 years of age. And now it is very straightforward and computationally inexpensive to AND all of these bit arrays together in order to find the records that match all of our criteria. It is this ability to perform these bitwise logical operations between different bitmap indexes that make bitmap indexes so useful. If we wanted to add income level to our criteria, that would be no problem. It would just be one more bitwise operation that would need to be performed. Bitmap indexes are suitable for columns that have a relatively few number of distinct values. Even columns that have a few hundred values are acceptable, assuming you have a very large table. If you start to get beyond a few hundred distinct values, then the number of bit arrays that need to be maintained keeps going up. And this makes the index inefficient to maintain and store on disk. So you'll want to limit your bitmap indexes to low cardinality columns. The reason why you should not use a bitmap index in a database if you have any sort of DML activity going on, is that when a row is updated on the table, Oracle can't go and simply replace the value in the bitmap index. Instead it has to rebuild all of the bit arrays. Because this process takes time, locking occurs, and no other transactions can occur against the table. In a data warehouse environment, typically you have one or maybe two transactions a day when data is loaded into the data warehouse. So as part of this load process, you are accepting the time it takes to take to rebuild the bitmap indexes on a table, and this is generally considered okay. But in a transactional environment, this is generally not acceptable, because you have transactions running against tables all of the time. The last thing you need to know about bitmap indexes is that they are only available in Oracle Enterprise Edition. For all of these reasons, you might consider bitmap indexes a little bit of a niche solution. They do solve a particular problem very well, but for most of us, we'll be using normal B-tree indexes most of the time. Still, it's good to know that bitmap indexes exist, what they are, and what they're used for. So let's take a look at the syntax that we would use to create one.

Defining Bitmap Indexes

Defining a bitmap index is very similar to defining a normal index. You just need to use the keyword BITMAP such that the statement reads CREATE BITMAP INDEX, like you see on your screen. When you do so, Oracle will determine all of the distinct values for the columns or combination of columns you have specified for the index, and create and populate a bit array for each one, as was shown in the slides just a moment ago. Since the bit arrays are created over the unique combinations of values, it is more flexible to create multiple single column bitmap indexes, rather than a multi-column bitmap index. A multi-column bitmap index would be more useful if you knew that all of the columns included in the index were always going to be included in queries against the table with a logical AND predicate in the WHERE clause. If this is not the case, though, multiple single column bitmap indexes better allow Oracle to mix and match the appropriate indexes as needed.

Advice to Consider When Creating Indexes

Let's take a few moments and talk about some tips that you should keep in mind when creating indexes in your database. There is much to say about this topic, and we are only going to hit a few of the most important points here. I'm also going to focus on tips that apply to standard B-tree indexes that you would be using in a typical application database, because that is the most common scenario that you will encounter. But this will give you a starting point for some things you want to keep in mind when creating indexes in your database. The first thing that you need to know is that column order in an index matters. The first column in the index key is what is known as the leading edge of the index. If this column in the index is not in the WHERE clause of your SQL statement, then Oracle will not be able to use your index except for a very few special cases. In fact, what you want to do is have as many consecutive columns from the front of your index present in your WHERE clause as possible. So in this case, having both the last_name and the first_name columns is better than having just the last_name column or the last_name and state column. Because by having both the last_name and first_name columns, we match the first two columns of the index, not just the first column alone. This makes it more likely that Oracle will use your index and allows Oracle to more efficiently use the tree structure to locate matching records in the index. So what you want to keep in mind is that the order of the columns in your index matter. Try to put the columns you use most often in your WHERE clauses at the front of your indexes, and then include as many of those columns as you can in your WHERE clauses. This will make sure that your index gets used, and Oracle can use the index as efficiently as possible. The second thing you want to keep in mind when defining an index is that we want our indexes to be as selective as possible. That is, we want the index to contain as many distinct values as possible. When using an index, what we are trying to do is quickly eliminate all of the rows that don't match our criteria so we can find the rows that do match the criteria we're looking for. If our index is not selective, meaning it matches a high percentage of the rows for any key value, then this is not going to help us find the rows of interest, because there will still be a lot of rows that we have to sort through in order to find the rows that we really want. Take, for example, an index on the gender of a person. There are only two distinct values, male and female. So the index would tell us that roughly half of the values in the table would match this criteria. So this doesn't really narrow things down that much, so we would almost certainly have to read the entire table, and then take additional steps to narrow down our result set further. Now, for example, take an index on an email address column. Email addresses are essentially unique, so having an index on email address, we can quickly traverse the tree structure to find the one row that corresponds to our search criteria. So you want to make sure that the indexes you define have as many unique values as possible. Unique or nearly unique values mean that only a few index keys will match, meaning Oracle will have to read and process a minimum amount of data and can very quickly locate the piece of data that your SQL statement is really interested in. The last piece of advice I want to offer you is to be careful not do overindex your database by creating more indexes than are really needed. Remember an index is a separate data structure that is maintained by Oracle. This means every index you create takes up disk space on the Oracle server. More importantly, it also means that Oracle must keep each and every index on the table in sync with the data in the table. That is, whenever there is a DML statement against the table, there is some overhead that Oracle must incur to keep all of the indexes on the table up to date. So regard an index as an investment. If you have a few indexes that are frequently used to speed up queries on the table, then the price you pay in overhead is a worthy investment. If, however, you have a lot of indexes on your table that are infrequently or even never used, then you are paying this overhead to maintain these indexes, but not getting any benefit out of them. So you want to make sure that the indexes you are creating are indexes that will actually be used by the SQL statements that you're running against your database. This makes sure that you get maximum benefit out of having an index, and you're only paying to maintain the indexes that are a net positive for your database and your applications.

Summary

In this module, we've provided an introduction to indexes in Oracle, which are the key to making sure that you are able to quickly and efficiently access the data in your database. We started off with a discussion about what an index is. We then covered how you create an index and some of the basic options that are available. We then discussed function based indexes and how they can be used to create an index over a derived value from a column, and how this can be very useful in some situations. We then discussed bitmap indexes, which are very useful in data warehouse environments for dealing with columns that have only a few distinct values. Finally, we wrapped up with a discussion of some important considerations that you should keep in mind when creating indexes for your database. Indexes are a very important topic in Oracle, and in this module, you've got a solid foundation of what indexes are and how they work. But I encourage you to continue to learn more about indexing in Oracle, either by reading some of the mini books that have been written about Oracle, or by checking out some of the other courses that we have available here on Pluralsight.

Privileges and Roles

The Need for Multiple Users

Hello, my name is David Berry. Welcome to this module on Privileges and Roles in Oracle. Let's take the fictional university database we've used as an example throughout this course and do a brief thought experiment on how this database might be used by various applications and users in a real life setting. We most likely would have a number of different applications that would need access to the data in our student schema. We'd probably have a Student Web Portal where students could register for courses, check their grades, and things like that. We'd probably also have a separate application for use by the faculty at our university, where they could get class rosters and enter grades for students in their courses when the term ends. In addition, we'd probably have an application for use by the administrative staff of our university, so they could maintain the course list, enter in the course schedule for each semester and do things of that nature, and finally, we might have batch process that logs into our database every night for the purpose of extracting data from the student schema and loading that data into a data warehouse for analysis purposes. So the question becomes what user should all these applications use to log into our database? While it would be possible for each of these applications to all use the student user, which owns our schema, there are some big downsides to this. First of all, as the schema owner, the student user has full access to every object in the schema. So that means it can query from any table and maybe more importantly, insert, update or delete from any table. And this is really not appropriate from a security point of view. Do we really want our student portal application that is used by students to be able to update grades in our database? While it is true that we would include security in the application layer to prevent this, we would still like to prevent this from happening at the database level to protect against a coding error in our application or a security breech. Another problem is that by logging in as the schema owner, any of these applications can perform DDL statements against the schema, like adding new tables, dropping tables, or adding and modifying columns. And again, this is something that really isn't appropriate for an application to be doing. The last issue is that if we some poorly written SQL statements that are impacting performance, we'd like to be able to easily track down which application these statements are coming from. Now it is possible to do this without having each application have its own separate user that it uses to log into the database, but it's much easier if each application does have its own separate user that it uses to log in to Oracle with. So what we really want to do is to create a separate user in Oracle for each of these applications to use, and then we will assign appropriate permissions to these users based on what actions the application needs to perform in our database. This way, we can be assured each application is performing tasks that it is allowed to do and not overstepping its bounds. How to create users in Oracle is a topic that's beyond the scope of this course, and in any case, this is going to be something that your DBA is responsible for. However, when one of these users is created, by default they're not going to have any access to any of the objects in our schema. For the remainder of this module, this is what we are going to focus on, is how to assign appropriate privileges to these users so they can accomplish the actions they need to, yet be prevented from performing actions that they should not be performing. We'll start by covering the GRANT and REVOKE commands, as these are the basic commands used to assign permissions on database objects in Oracle. We'll then talk about some of the privileges you can grant on objects like tables and views. Next, we'll discuss how privileges can be granted at a column level, which is useful for when you need fine grain control over what a user can see and do. Then, we'll talk about stored procedures and security. This is not a course on stored procedures, but there are some scenarios related to security around stored procedures that you should understand. We'll then talk about database roles, which is a way you can create groups of privileges so you don't have to individually assign privileges to users in your database. And finally, we'll wrap up by talking about some basic security principles to consider when securing your database.

GRANT and REVOKE

In the SQL language, as well as in Oracle, the commands to extend and remove privileges from users are the GRANT and REVOKE commands respectively. When you create a new user and you need to give this new user access to some objects, you will exercise a series of GRANT commands. If for some reason you need to remove some of those privileges at a later time, you will use the REVOKE command. Let's take a little closer look at each of these commands. The syntax of the GRANT command reads very naturally. You start with the keyword GRANT, then include the privileges you are granting, the keyword ON, followed by the object you are granting privileges on, then the keyword TO, and then who the privileges are being granted to. For both the list of privileges and for the list of users in this statement, that can be a single item or a comma separated list. Also, rather than just a user in this statement, this could be a single user or it could be a role, and we'll talk about what a role is in a moment. For the name of the database object though, this needs to be a single object. We can't use a list of objects here. So if we were look at a couple of examples, the first example grants the select privilege to both the students_web and faculty_web users on the table named courses. In the second example, we are granting both the select and update privileges on the students table to the user students_web. The REVOKE statement is very similar to the GRANT statement. All we do is replace the GRANT keyword with REVOKE, and the TO keyword with FROM. Again, we can include a comma separated list of values either in the privileges that we're granting, or the USERS clause of the statement. Let's move on to what privileges we can grant and revoke with these statements.

Object Privileges

What privileges are available on an object? This slide shows the list of privileges that are available on a table. Most of these are self explanatory, like SELECT, UPDATE, INSERT, and DELETE. And those are the four privileges that you'll work with most often. But let's take a look at a couple of others. In Oracle you can use a SELECT …FOR UPDATE statement to instruct Oracle to select a row and lock it in anticipation that you're going to update this row, and you don't want anyone else to manipulate the value in the meantime. This is known as pessimistic locking. If you want a user to be able to read a row, but not use pessimistic locking in this way, you can assign the READ permission rather than a SELECT permission, and a SELECT …FOR UPDATE will be disallowed. Another privilege of note is the REFERENCES privilege. If you have a table that you want to serve as the parent table in a primary foreign key relationship across schemas, then you will need to grant the REFERENCES privilege on that table to the schema that will contain the child table. Note also, the REFERENCES privilege can only be granted to a user and not to a role. The other privilege that I'll point out is the DEBUG privilege, and you'll want to use this when a user other than the schema owner needs to be able to debug through a PL/SQL trigger that's on a table. This is probably not something you would be granting to an application user, but to a person if they needed this sort of debug capability. Taking a look at the privileges you can grant on a view, you will notice that these are very similar to the privileges on a table. In fact, the only ones that are missing are the ALTER and the INDEX privileges. Otherwise, these work just the same as their counterparts on a table. You also want to remember when assigning these privileges to an object, you don't need a separate GRANT statement for each privilege. You can combine these privileges into a comma separated list and use that in your GRANT statement.

Column Level Privileges

Sometimes we run into a situation where we have a table that we need to give update privileges to a user on, but we want that user to be able to only update some of the columns in the table, not all of them. With the grant statements we have seen so far, when we give the update privilege to a user, that user can now update any of the columns in the table. Obviously, we perform code reviews of our application code to make sure that it's not updating columns that it shouldn't be, but if this is a login that's used by a person rather than an application, things get more difficult. In either case, ultimately we're on the honor system, that that Oracle login, in this example students_web, won't update the data that it's not supposed to. I don't know about the information security guides where you work, but the ones I work with, they don't think a whole lot of the honor system. So what we really want is a way that we can enforce some permissions through Oracle and only allow a user to update certain columns that we specify on a table and not all of the columns. What we can do in our GRANT statement, is we can include a list of columns right after the privilege, and then we will only grant this privilege on the columns that we include in our list. In this example, we are letting students_web update all of the columns that you see here related to contact information, but not any of the other columns on our table. What this does is it gives us a very fine grain control over what we will and will not allow this user to update on the table, rather than being an all or nothing affair. Now the ability to specify columns is not available for every privilege on a table. You can only do this for the insert, update, and references privileges. What if we want to restrict access to selecting some of the columns in a table in our database? How do we accomplish this? We just saw a column level permissions on the previous slide, but these are not available for the select privilege, so that doesn't work. What we can do, and this is the approach most database professionals take, is to create a view around our table that only includes the columns we want someone else to see. And then, we grant that user select access to this view rather than access to the underlying table, and in this way they can only see the columns that we want them to see, and we don't have to expose data in our table that they're not supposed to see. The typical example of this is that we're creating an employee phone book, so our web page, or whatever we're creating needs to access the employees table, and we have a sample table here. Now admittedly, this example is somewhat contrived, but we can see in this table we would want to include things like employee first and last name, title, department, phone number, and email address. But under no circumstances would we want to risk exposing the employee's salary or date of birth in the phonebook. So we want to restrict access to these columns and make sure that there's no way that our phonebook application can even see these columns. So right away, we rule out giving select access to this table, because then the application would be able to see every column in the table, and that's not what we want. What we would do in this case is create a view, and we would only include in this view the columns that we wanted the application to have access to. And then, we would grant select access on this view to the user that was displaying the company phone directory on our web page, or whatever it was displaying it on. And in this way, we've limited the data the user can see, and effectively eliminated the risk of accidental data disclosure. This is actually a technique that you will end up using quite frequently, so it's a good one to know.

Demo: Assigning Object Privileges

Let's demonstrate some of the concepts we've been talking about with regards to assigning privileges to different users. What I'm going to do in this demo is to be logged in in two different windows as two different users. Here in SQL Developer, I'm going to be logged in as the STUDENTS_WEB, and this would be an application or some other user that does not own the schema objects that we want to access. I'll show you here by running this query and making use of the SYS_CONTEXT function that I am indeed logged in as this STUDENTS_WEB user. Over here, I'm logged in SQL Plus, and in this window I'm going to be logged in as the STUDENT_USER, and this is the user that owns all the tables, and it is the STUDENT_USER that will need to grant access to these tables so that our STUDENTS_WEB user in the other window can see them. And I'll go ahead and run this query again here, so you can see I am indeed logged in as a student user. So let's return to SQL Developer, and the first thing that I want to try is I'm going to issue a query against the courses table that's over in the student schema. So there's my query, and I'll go ahead and try to run this. And we can see that that fails. In fact, Oracle comes back here, it doesn't even tell us that table exists, that's because we don't have permissions to it, it's not even going to disclose that that table does exist. We don't have permissions so STUDENTS_WEB cannot see that. So let's go back to our student schema and we'll issue a GRANT command so that we can access this table. There's our command, and we see that our grant succeeded. So now we'll go back to SQL Developer, where again we're STUDENTS_WEB, and we should be able to see that we can query from this table now, and indeed we can. There is all of our data. Now one thing also to notice here is because this table is in another schema, we had to prefix the name of the table with the name of the schema where the table is, and so that's why we have this student dot on the front here, because this table is actually located over in the student schema, not in STUDENTS_WEB, which is the user we are logged in here as. Let's move on and talk about some column level security. What I'm going to do is I'm going to go back to the SQL Plus window, and I'm going to grant selected update access on the students table to the students_web user. So there we go, there's our syntax to grant this access, and I'll go ahead and do this, and we see that that grant was successful. Now remember, by doing this here in this way, we've now given the students_web user the rights to update any column on the students table. So let's go ahead and verify that we can indeed do that. First I'm going to select a particular student out of the database, and there we go, there is our target student that we're going to update. And now I'm going to try to update this student's major from number 8, which happens to be Civil Engineering, to number 10, which is Mechanical Engineering. And we see indeed I could do that here. Now that's something that maybe I have a use case where I really don't want that to happen here, I only want the students_web user to be able to update some of the columns, maybe if you want to change your major you have to fill out some paperwork at our university and that's a different application that ultimately makes that change in the database, and so how do we address this here, that's the question that's in front of us. So let's go ahead and let's rollback this change first. And so now I'm going to return to SQL Plus and I'm going to revoke the UPDATE privilege, so now the students_web user wouldn't be able to update the table at all, and I'm going to re-grant that just to the columns that I want the students_web user to be able to update. So there we go, there's my GRANT command, and you can see I only have these columns here related to contact information. So I'll go ahead and do that. So now let's go back to SQL Developer and I'm going to try to run this UPDATE statement again right here that I just ran previously. And so if I run this statement, we can see here, now this statement fails, I'm getting an ORA-01031 error: insufficient privileges, because I don't have rights to update that column. So let's see though if I can update some of those contact information columns. So I'll try to update this student's telephone number and I'll clean this up before we do this so it's a little bit easier to see. And indeed we do see that I can update the contact information, which is one of those columns that I specified this user should be able to update. So as we've seen in this demo, this is how we can grant and revoke permissions on our database objects, and we see that we can indeed go down to the column level if that's something that we need in our applications to enforce the appropriate security.

Privileges on Stored Procedures

Let's take a moment and discuss how privileges work on stored procedures and functions in Oracle, because these are a little bit different than tables and views. First of all, there are two privileges that you can grant on a stored procedure or function, and they are EXECUTE and DEBUG. The most common privilege you're going to grant is EXECUTE, as this allows another user to run the stored procedure or function. The DEBUG privilege is for the cases where you want that user to be able to debug through the PL/SQL code in a debugger. And while there are times where this is important, generally it is the EXECUTE privilege that you are interested in granting, because that's what lets the user run the procedure. One of the important things to understand is that when you give a user execute access to a procedure or function, this is all the permission that they need. They do not need access to the underlying tables or views that that procedure or function may access. So in this diagram, all the user needs is the execute permission on the UpdateGrade procedure, they do not need to have the update privilege on the course_enrollments table, and in fact, they may not have any privileges at all on the course_enrollments table. That is okay as long as they have execute permission on the procedure. What is happening here is that when the procedure executes, it is effectively executing with the permissions of the user who owns the procedure, not the user who is executing the procedure. So in this case, the user student owns the procedure, so the procedure is able to access any object in the student schema, so it makes no difference what permissions our user is assigned, as long as they can execute the UpdateGrade procedure as shown here. There is always a lot of debate in the development and database communities about whether you should use SQL in your application or put all of that SQL into stored procedures and then call those stored procedures to get your data. This topic has been debated multiple times, and we're not here to debate it again. One thing I will say, though, is if you need to tightly secure your data, then stored procedures do offer some advantages in this area. Let's take the example of a login process. And we need to validate a username and password against some credentials we have stored in our database. To do so, we're going to have to issue some sort of query against our users table to either compare credentials to have to what's stored in the database, or to get those credentials back so we can compare them in application code. The problem is though, that if we're using SQL directly from our application, then the login process will have full select privileges on the user's table. Meaning the login process can perform any select against that user's table. So if somehow this process was compromised in a security breach, an attacker could query all of our users and their personal details out of the user's table, and that would be a very bad thing. First of all, they would get all of our users' contact info, but second, they would get their hash passwords as well, which even though the passwords are hashed, an attacker could still attempt to use something like a brute force for a dictionary attack to try to crack these. If you're not a security expert, don't worry. But you do want to understand is that anytime you have sensitive data, it might be prudent to put an additional layer in to prevent a process from being able to select or update all the data in a table, because this isn't really a use case that that process should be performing. So how would a stored procedure or function help in this scenario? Let's say we write a function called check_password that takes in the username and hash password. And now we have our login process called this stored procedure. This means that our login process does not have direct access to our users table, just execute permissions on the check_password function. And we've now restricted any queries by the login process to this one legitimate use case, checking user passwords. I will not tell that we've completely thwarted any attacks like this, because after all, the bad guys are getting more creative all the time. But by removing direct access to the table, we put another barrier in place where now it's much harder for someone to dump all the data out of our table and use that for some illegitimate purposes. So to wrap up the discussion about store procedures and functions, know that security around stored procedures is a little bit different. The basic privilege around a stored procedure is the EXECUTE privilege, which just like the name implies indicates whether or not that user is authorized to run that stored procedure. When a user runs a stored procedure or function, they do not need access to any of the underlying tables, views, or even other stored procedures that the original stored procedure may call. As effectively, the procedure is running with the permissions of the procedure owner, not the user who called the procedure. This turns out to be rather useful, because in some scenarios, it may make sense to expose a stored procedure to a user and not give direct access to a table. This helps make sure that the user is only able to execute specific use cases we define, and not stray outside of these bounds. If you have sensitive information, restricting access in this way may be something that is of particular interest to you. Even by implementing simple stored procedures that are really just wrappers around BASIC, SELECT, INSERT, and UPDATE statements, you can gain yourself some additional security around your data by restricting access to only certain use cases.

Database Roles

One of the tasks we might need to perform is to grab access to our technology staff so they can monitor and maintain our tables in our production database. And so we would grant all the appropriate privileges we need to to John, and then we would do the same thing for Erica, and then we would do the same thing for Robert, and so on. If you're thinking that this looks like a lot of repetitive work and there has to be a better way, you are correct. The better way is to make use of database roles. A database role serves as a container for a set of privileges that you define. If you are familiar with groups in Active Directory, then you will be familiar with the concept of a database role. What you do is create a database role and then grant privileges on the objects to the role. Then you can give this role to users in your system, and they get all of the privileges that that role contains. In this way, the administrative burden of maintaining security permissions can be reduced, because you don't have to grant the same set of permissions over and over again to different users. You just grant the permissions to the role and add users to the role as appropriate. If you add new tables to your schema and need to add privileges to these tables, you can just grant the appropriate privileges to the role, and you don't have to remember all the users who should get the new privilege. So in this way, it makes the administrative aspect of security much easier. So if we return to our example of needing to grant permissions to our technology staff, this is what we would do instead. First, we would create the role. From a command point of view, this is very easy to do as you see. We just say CREATE ROLE and the name of the role. However, this is something you will probably not have permission to do yourself, so you'll need to get a DBA to perform this task for you. Once that role is created though, you can assign privileges to the role simply be being the schema owner. We do this using the GRANT statement just like we would to a user, but instead we use the name of the role instead of an individual user as we see here. Finally, we need to associate users to this role, so again, we do that with the GRANT command. This is a task though that's going to need to be run by a DBA. A role could contain other privileges, like privileges in other schemas or system level privileges. So assigning a role to a user is restricted to DBA users to make sure that a user doesn't accidentally get some privileges that they shouldn't have. What you can do, though, is work with your DBA to setup and define some roles for your application, and in the long run this is going to save everyone some time and effort. So you'll find anytime that you're managing a group of users, and this could be a group of users who are people or applications that have similar permissions, you'll want to favor using roles over granting privileges to individual users, because roles reduce that administrative burden.

Basic Security Practices

Let's briefly summarize our discussion of database privileges. This has been a short introduction into how you can secure your schema objects in your database, and some of the considerations around securing those objects. As with most things, the syntax is easy to master. The hard work comes in thinking about what levels of access different users and applications should have. When thinking about these topics, there are two principles you should keep in mind. The first is the Principle of Least Privilege. This states that we only want to give a user or process just as much access as they need to complete the job they need to do. If there is a piece of data or functionality this user should not have access to, then we should not grant it to them, as this represents a risk from a security point of view. The second principle to keep in mind is the principle of Defense in Depth. When done correctly, security is enforced at many levels throughout a system. Defense in depth means that even if one security mechanism fails or is compromised, your system as a whole is not immediately compromised. We have other security mechanisms that can still limit access. So we want to try to implement a defense in depth wherever possible. So what are some good practices that you can put into place to support these principles? First of all, setup a different user in Oracle for your applications to use to access you data other than the schema owner. As we saw, the schema owner has full rights to every object in your schema, and can also execute DDL statements. Most of the time, we don't want an application to have that level of access. So it is best if we can define a separate Oracle user for an application to use so that we can assign appropriate privileges to this user. Right along with this, it is best to assign a separate user for each application that needs to access your database. Typically applications will have different requirements in terms of what data they need to access and modify. Having a separate user for each application means that we can match the privileges for each user to exactly what the application needs to do and not over-privilege a user. As a side benefit, this also makes it easier to tell what application is running what SQL, and this makes managing your database a little bit easier. Finally, take time to think about what amount of access you should be granting to your database, and how to put the appropriate access controls in place. I'm always amazed that corporations spend a lot of time on assigning appropriate permissions to file servers in the organization, and then turn around and share a single database login among multiple applications and even multiple people that can access every piece of data in the database. This just doesn't make any sense. So think about what those access levels should be and take the time to set them up and properly assign them to your users. In this module, we started off by giving an example of why you really need to set up multiple users so you can effectively control access to your data. We then took a look at the GRANT and REVOKE commands, which are the basic SQL commands used to control access in Oracle. We continued with a discussion of what privileges you could grant on an object, and then moved into a discussion of how you can grant column level permissions in Oracle. Next, we talked about stored procedures and how security works with regards to stored procedures and functions. We also looked at how a stored procedure can be used to limit a user to only running a select set of use cases and eliminate the need for direct access to a table. We then had a brief discussion on database roles and how you can use these to simplify the assignments of your security privileges, and finally, we wrapped up by discussing some security principles that you should keep in mind. This has been just a brief introduction, but I hope you will continue to seek out other resources to learn about security and how to build secure systems and secure your data. Almost every week now, we hear about a major security breach in the news. So all of us in the technology community need to further our knowledge in this area, so we can build more secure systems and keep the data that our customers entrust to us safe from unauthorized access.

Good Practices

Introduction

Hello, my name is David Berry. Welcome to this module on Good Practices in Oracle. In this module, we're going to talk about some of the good practices that you should adopt as you create your databases in Oracle. We'll start out by talking about naming conventions, how they make your database easier to use and understand, and what are some conventions that you might want to adopt in your work. Next, we'll talk about how to create comments on our tables and columns in Oracle. As much as we strive to have databases which are self documenting, there are still some times where we need to explain things a little bit more in depth with a comment, and Oracle gives you a way to do this right in the database. Finally, we'll talk about the single responsibility principle and how it applies to databases. If you are a software developer, you may have already heard about the single responsibility principle and how it applies to the code that you write. I believe this principle applies not just to software we write, but indeed throughout technology, so you will want to keep this in mind as you develop your database.

Naming Conventions

One of the practices I urge you to adopt is to come up with some naming conventions and standards to use throughout you database. Many organizations already have such standards in place, and if yours does, you should learn and adopt those standards. If you don't have standards in place, I encourage you to work with your colleagues to develop a set of standards to use in your organization. Having standards makes your database easier to use, because people know what to expect in terms of how objects are named and how your objects are organized. This allows everyone to put their mental energy into understanding the data in your database and the business functions it performs, not trying to decipher what a cryptic column name means. Following consistent standards also adds an element of professionalism to your work. Databases and applications that we build for our customers are important assets for our business, and we want our work to reflect the professionals that we are as software and database engineers. What I'm going to present to you in this section are the conventions that I like to use when I am naming my objects in an Oracle database. You are free to disagree with some or even all of the conventions that I use. However, what I do encourage you to do is to work to make sure that you have standards of your own in place at your organization and that you closely follow these standards. I realize that this is not the fun part of the job, and no one gets excited about putting together a document on standards and conventions. But it does pay off in the long run when your database is easier to use and everyone on your team has a clear understanding of what the purpose of each structure in your database is. For naming tables and columns, I always want the name to be descriptive of the data that is contained in the table or column. For tables, the names are almost always nouns, because the data represents some object or someone, like a student, a course, or a department. I also name tables as plural, because ultimately a table represents a collection of these objects, like students or courses. Many people will disagree with this standard and name their tables in singular form. This is fine, too, but whatever you do, be consistent in your table names to always use the singular or the plural form of the name across your database. For columns, these are again most often nouns that represent the attribute of an object being stored in the table. I try to be very specific with my column names, so it is clear what type of data should be stored in that particular column. I encourage you to use full words in the names of your tables and columns and avoid abbreviations. Full words are more descriptive, and it eliminates any chance of misinterpretation as to what an abbreviation means. It is also important to remember that today many of us work in global companies with staff located around the world. So an abbreviation that is commonly used and understood here in the United States may seem very foreign to someone from another part of the world. Spelling out the entire word eliminates any chance of ambiguity, and this really should not be a problem because Oracle does give us 30 characters for each identifier in our database. Since I use full words in naming tables, columns, and other objects in Oracle, I separate each word in an identifier with an underscore character to improve the readability of the name. Unless you are using quoted identifiers, which I recommend against, Oracle will show the names of tables or columns to you in all uppercase. To me, I find it easier to read these names if you separate out the words with the underscore character. As I indicated earlier in this course, I always explicitly name my primary keys, foreign keys, and check constraints in the tables I create. If you don't, Oracle will assign a system generated name to these constraints, but this name will just be letters SYS followed by a sequential number. By naming these constraints with a meaningful name, when you have a SQL statement fail one of these constraints, you will immediately know which constraint was not met. For naming indexes, I use a prefix to indicate the index type. Follow that with the table name, and then finally what columns the index is over. As you work more with Oracle, you will have the need to look at execution plans of your SQL statements in order to performance tune those statements. By having a descriptive index name, you can immediately recognize the index and what purpose it is intended to serve. And once again, this is a little time saver that adds up over the life of you database. Index names, like all identifiers in Oracle, have a 30 character limit. Because of this, index names are the one place that I will end up using abbreviations, simply to stay under this 30 character limit. Even with this limit though, it is still possible to create descriptive index names that let you very quickly know how an index is composed. The most important rule you want to keep in mind for any names in your database, is to be expressive. Whether you're naming a table or column or an index, you want to clearly communicate what type of data is being stored or what the purpose of the structure is. We don't want to have any confusion or miscommunication among our colleagues about what a table or column is for. Part of the test here is that everyone should be able to look at the names in your database and immediately recognize what data in your business is represented in that structure. If you create a database where everyone can do that, you are a long way towards your goal of creating a database that will be easy to work with for everyone on your team.

Creating Comments for Tables and Columns

We would all like to think that the designs we create and the names that we choose make our software and databases completely self explanatory, but we also know better than that. So we often have a need to include comments with the software we create. If you are a C# or Java developer, you're probably familiar with the XML or Java. type comments that you can place directly on classes and methods in your code. The big advantage of these is that they're right within the code. We can do something very similar in Oracle in that we can document our tables and columns right in Oracle with these comments, and those are going to be held in the Oracle dictionary for us. This is a lot of times more effective, because when someone needs the information about a table or a column, it's going to be right there in the database where they're already working, not off in a separate document that they have to go and find. To put a comment on a table, we say COMMENT ON TABLE, followed by the table name, the keyword IS, and then our comment text enclosed in single quotes. For columns, the syntax is very similar. We say COMMENT ON COLUMN, and then the table name the column is in, dot, and then column name. Again, we finish up with the keyword IS, and the text of the comment. If we want to remove a comment, we'll use this same syntax, but we'll just include the comment text as an empty string. One last thing, comments can be up to 4000 bytes in length, so this should be more than sufficient to describe any tables or columns that you have. The comments that we enter will be held in two data dictionary views, user_tab_comments, and user_col_comments. You can join these views to other data dictionary views to bring in more information, and that is especially useful when using the user_col_comments views, to join that over to the _____user_tab_columns view to get a complete picture of the columns in a table. You can query these views from your SQL editor, or many tools today will actually read this views and show you the comments that are saved in them as part of their graphical user interface. Again, the nice thing about this is that these comments are right here in Oracle at our fingertips, and they're not stored off in some long-forgotten design document somewhere else. Let's take a look at a quick demonstration of putting some comments on a table and its column.

Demo: Creating Comments for Tables and Columns

I'm going to add some comments to the courses table, and I have the description of that table up here in the lower pane, just to remind us what the table looks like. So let's go ahead and look at the statements that will add the comments to this table. Now you'll notice here that I'm only adding comments to the table itself in the first statement, and some of the columns. This is fine. Each one of these statements is independent, so you can comment just on the table, or just on a single column or two, and this is very useful when you're dealing with a legacy database and you might be building up your documentation in an incremental fashion. So let's go ahead and run these statements. And there we go, we've added some comments to our table and to these columns. Now we can query these comments out of the data dictionary views that we saw earlier, so let's go ahead and do that. This will get us the table comments, and there we see indeed this is our comment. And now let's get some comments for some columns on this table. So in this case, you notice that I'm joining the user_col_comments table to the user_tab_columns table, so I can get a full definition of what all the columns are on the table, so I'll go ahead and run this. And we see here in this result set, we have both the definition of our columns, and then as we scroll out here, we have the comments that we just added to this table. The nice thing about both of these situations is we have this information right at our fingertips in our SQL Editor window. If we're in the middle of writing some SQL for our application, we can easily access this information and we don't have to interrupt our work flow by going and looking in some separate document. Now the last thing that I want to show you is that many tools make this information available to you also in the GUI, so let's go ahead and bring up the table information in SQL Developer. And so to do that, we'll go over here to the Connections tab, and you can see that the tables are already expanded here, and we will find the Courses table, it's right here, and I just double-clicked on that. And we can see here is a list of columns that are on the table, and you see indeed the comments are populated in this view of the information. This is something that's built into SQL Developer, this is not anything that I did, but you're seeing this more and more, where these tools are building in this information, and again, that's an advantage of storing these comments, storing your documentation right there in the database is that tooling is being developed around this. So to wrap up, you're not going to need to put comments on your tables or columns in all situations, but when you do, understand that that feature is built into Oracle, and that's usually a good way to approach solving that problem.

The Single Responsibility Principle for Tables and Columns

One of the most important rules to follow when creating tables and defining columns in your database, is to make sure to follow the Single Responsibility Principle. Simply put, every structure in your database should do exactly one job, and it should do that job very well. When we start to have any structure, whether a table or column, having multiple responsibilities, then that structure becomes much more difficult to use and more difficult to understand. So let's understand what it means to apply the single responsibility principle within the databases that we create. Every table in your database should hold data for one type of entity. The key here is focus. This means all of the rows in your table should represent the same type of object or business concept in your application. What are some of the signs that you might have more than one type of object stored in a table? Take a look at the columns and rows of this table, which represent a universal persons table that will contain both students and faculty members. We see that some columns will apply to both students and faculty, like name and email address. But we have other columns that we know will only apply to one type of row or the other. Only students should have data for the degree they are pursuing and what their current enrollment status is. These columns should always be null for faculty members because they don't apply to faculty members. The reverse is true for columns like title and academic department for students. These attributes only apply to faculty members and not students. The problem here is that from just looking at the table definition, we can't tell what columns are supposed to apply to what type of entity stored in the table. This makes our table harder to understand, and it also makes it harder to use, because in many cases when we use this table, we'll only want one type of data, so we'll have to filter out the other types of data we don't want. So when you start seeing a lot of columns like this where the column is only populated for one type of row in a table, but not others, this is an indication that each row may indeed represent a separate type of entity that really should be housed within its own table. Another test is when you go to establish foreign keys to one of your tables. Take, for example, the table that contains the generic people for our university that we just talked about. Elsewhere in our database, we will have another table called COURSE_SECTIONS, which represents a section of a course that meets at a certain time in a particular semester. As part of the data for this table, we'll want to have a column that keeps track of the faculty member that is teaching this section. And for this column, we'll want to have a foreign key back to our PERSONS table. We'll also have a second table, let's call it COURSE_ENROLLMENTS, that keeps track of what students are enrolled in this particular section of the course. For this table as well, we will want to have a foreign key back to our PERSONS table, but this time to enforce referential integrity on the student ID. With both of these foreign keys, we see a problem though. Both of these keys point back to the PERSONS table, so each foreign key can only require that we have a valid person. What we really want is one foreign key that requires a faculty member and a second foreign key to constrain us only to students. But this isn't possible with our table design. So if you start to see situations like this, where you have a foreign key that points back to a table, but you really only want one type of row in the foreign key, then this is probably an indication that you have a table storing multiple types of data, and you want to go back and rethink that design. The single responsibility principle applies to columns as well. Columns should store the data for a single attribute. You want to avoid the situation where a column or a value in a column means one thing in one case, but something different in another case. Let's take the example of a simple orders table that you see on your screen, where we have an order ID, a status column, and a ship date column. In this example, our status column will represent the state of the order, with the value of P for an order that has been placed, but not shipped, and a value of S for an order that has been shipped. Let's say we want to keep track of the target or expected shipping date for orders that have been placed. Something I have seen done too often is that people will put this value in the ship date column. When the order ships, then we store the real ship date in this column. So obviously, the ship date column can mean two different things depending on the status of the row. This is something that is not obvious to someone who's just looking at the data in the table, and this could create confusion for someone who isn't aware of the dual use of this column. We will also have to write some decode logic when extracting data from this column into our application to account for the dual use of this column. And finally, we aren't keeping the target ship date after the order has actually shipped. So you can see, we would really be better off having a separate column called TARGET_SHIP_DATE that was focused solely on keeping this data. This much more clearly reveals our intent, and keeps each column focused on one task. So in summary, I urge you to apply the single responsibility principle to your tables and columns. This will make your tables much easier to understand and use, and it is much easier to come up with a good design when each structure is clearly focused on one goal, rather than being diluted down by trying to accomplish too many different objectives.

Summary

In this module, we've covered why you should establish some conventions around naming in your database, and what some conventions are that you might want to adopt. We then talked about how you can comment your tables and columns in Oracle, and have these comments stored right in Oracle itself. And finally, we wrapped up by talking about the single responsibility principle, and how it applies to tables and columns so we can follow this principle in the databases that we create.

Course author

    
David Berry
David Berry is a software engineer with over 15 years of experience developing applications in languages such as Java and C#. Throughout his career, he has worked extensively with enterprise...
Course info

LevelIntermediate
Rating
(113)
My rating
Duration5h 10m
Released28 Jan 2015
Share course

